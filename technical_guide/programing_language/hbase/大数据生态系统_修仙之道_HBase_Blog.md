# å¤§æ•°æ®ç”Ÿæ€ç³»ç»Ÿ ä¿®ä»™ä¹‹é“ HBase Blog

@(2019-04-10)[ Docs Language:ç®€ä½“ä¸­æ–‡ & English|Programing Language:HBase|Website:[www.geekparkhub.com](https://www.geekparkhub.com/)|![OpenSource](https://img.shields.io/badge/Open%20Source-%E2%9D%A4-brightgreen.svg) | ![GitHub repo size in bytes](https://img.shields.io/github/repo-size/geekparkhub/geekparkhub.github.io.svg) | GeekDeveloper:[JEEP-711](https://github.com/jeep711)|Github:[github.com/geekparkhub](https://github.com/geekparkhub)|Gitee:[gitee.com/geekparkhub](https://gitee.com/geekparkhub) ]

##  ğŸ˜ HBase Technology ä¿®ä»™ä¹‹é“ åˆ»è‹¦ä¿®æŒ ğŸ˜

![Alt text](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hbase/hbase.jpg)

- **æå®¢å®éªŒå®¤æ˜¯æå®¢å›½é™…å…¬å›­æ——ä¸‹ä¸ºæœªæ¥è€Œæ„å»ºçš„æå®¢ç¤¾åŒº;**
- **æˆ‘ä»¬æ­£åœ¨æ„å»ºä¸€ä¸ªæ´»è·ƒçš„å°ä¼—ç¤¾åŒº,æ±‡èšä¼—å¤šä¼˜ç§€å¼€å‘è€…ä¸è®¾è®¡å¸ˆ;**
- **å…³æ³¨æå…·åˆ›æ–°ç²¾ç¥çš„å‰æ²¿æŠ€æœ¯&åˆ†äº«äº¤æµ&é¡¹ç›®åˆä½œæœºä¼šç­‰äº’è”ç½‘è¡Œä¸šæœåŠ¡;**
- **Openå¼€æ”¾ `Â·` Creationåˆ›æƒ³ `|` OpenSourceå¼€æ”¾æˆå°±æ¢¦æƒ³ GeekParkHubå…±å»ºå‰æ‰€æœªè§!**
- **Future Vision : Establishment of the Geek Foundation;**
- **GeekParkHub GithubHome:**<https://github.com/geekparkhub>
- **GeekParkHub GiteeHome:**<https://gitee.com/geekparkhub>
- **æ¬¢è¿è´¡çŒ®`å„é¢†åŸŸå¼€æºé‡ç”ŸBlog`&`ç¬”è®°`&`æ–‡ç« `&`ç‰‡æ®µ`&`åˆ†äº«`&`åˆ›æƒ³`&`OpenSource Project`&`Code`&`Code Review`**
- ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ issues: [geekparkhub.github.io/issues](https://github.com/geekparkhub/geekparkhub.github.io/issues) ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ
- **`Official Public Email`**
- Group Emailï¼š<geekparkhub@outlook.com> â€”â€” <hackerparkhub@outlook.com> â€”â€” <hackerpark@hotmail.com>
- User Emailï¼š<jeep711.home.@gmail.com> â€”â€” <jeep-711@outlook.com>
- System Emailï¼š<systemhub-711@outlook.com>
- Service Emailï¼š<servicehub-711@outlook.com>


-------------------


[TOC]



## 1. HBase æ¦‚è¿°

### 1.1 HBase ç®€ä»‹
> HBaseæ˜¯åŸºäºè°·æ­Œå…¬å¸BigTableå¼€å‘çš„å¼€æºåˆ†å¸ƒå¼æ•°æ®åº“,å…·æœ‰`é«˜å¯é `/`é«˜æ€§èƒ½`/`é¢å‘åˆ—`/`å¯ä¼¸ç¼©ç­‰ç‰¹ç‚¹`.
> 
> HBaseè¿è¡Œåœ¨HDFSä¹‹ä¸Š,ä¸»è¦ç”¨æ¥å­˜å‚¨`éç»“æ„åŒ–æ•°æ®`å’Œ`åŠç»“æ„åŒ–æ•°æ®`.
> 
> HBaseé€šè¿‡æ°´å¹³æ‰©å±•çš„æ–¹å¼å®ç°äºå­˜å‚¨å¤§è¡¨æ•°æ®(è¡¨è§„æ¨¡å¯ä»¥è¾¾åˆ°æ•°åäº¿è¡Œä»¥åŠæ•°ç™¾åˆ—),å¹¶ä¸”å¯¹å¤§è¡¨æ•°æ®è¯»å†™è®¿é—®å¯è¾¾åˆ°å®æ—¶çº§åˆ«.

- HBaseç”±Powersetå…¬å¸åœ¨2007å¹´å‘èµ·,æœ€åˆæ˜¯Hadoopçš„ä¸€éƒ¨åˆ†,åœ¨æ­¤ä¹‹å,HBaseé¡¹ç›®é€æ¸å‘å±•æˆä¸ºApacheè½¯ä»¶åŸºé‡‘ä¼šæ——ä¸‹é¡¶çº§é¡¹ç›®.
- HBaseå‘å±•é‡Œç¨‹ç¢‘ç®€è¿° : 
- 2006å¹´11æœˆ Googleå‘å¸ƒBigTableè®ºæ–‡.
- 2007å¹´2æœˆ HBaseä½œä¸ºHadoopé¡¹ç›®çš„å­é¡¹ç›®æˆç«‹.
- 2007å¹´10æœˆ HBaseç¬¬ä¸€ä¸ªå¯ç”¨ç‰ˆæœ¬å‘å¸ƒ(Hadoop 0.15.0).
- 2010å¹´5æœˆ HBaseæˆä¸ºApacheè½¯ä»¶åŸºé‡‘ä¼šé¡¶çº§é¡¹ç›®.
- 2011å¹´1æœˆ HBase0.90.0å‘å¸ƒ,è¯¥ç‰ˆæœ¬ä¸ºé¢å‘æ‰€æœ‰ç”¨æˆ·çš„ç¨³å®šç‰ˆæœ¬.
- 2017å¹´2æœˆ HBase 1.2.xç‰ˆæœ¬å‘å¸ƒ.


### 1.2 HBase ç‰¹ç‚¹
#### 1.2.1 æµ·é‡å­˜å‚¨
> HBaseé€‚åˆå­˜å‚¨PBçº§åˆ«æµ·é‡æ•°æ®,åœ¨PBçº§åˆ«æ•°æ®ä»¥åŠé‡‡ç”¨å»‰ä»·PCå­˜å‚¨æƒ…å†µä¸‹,èƒ½åœ¨å‡ ååˆ°ç™¾æ¯«ç§’å†…è¿”å›æ•°æ®,è¿™ä¸HBaseææ˜“æ‰©å±•æ€§æ¯æ¯ç›¸å…³,æ­£å¼å› ä¸ºHBaseè‰¯å¥½çš„æ‰©å±•æ€§,æ‰ä¸ºæµ·é‡æ•°æ®å­˜å‚¨æä¾›äº†ä¾¿åˆ©.

#### 1.2.2 åˆ—å¼å­˜å‚¨
> åˆ—å¼å­˜å‚¨ä¹Ÿå°±æ˜¯åˆ—æ—å­˜å‚¨,HBaseæ˜¯æ ¹æ®åˆ—æ—æ¥å­˜å‚¨æ•°æ®,åˆ—æ—ä¸‹é¢å¯ä»¥æœ‰éå¸¸ä¹‹å¤šçš„åˆ—,åˆ—æ—åœ¨åˆ›å»ºè¡¨ç¤ºå°±å¿…é¡»æŒ‡å®š.

#### 1.2.3 ææ˜“æ‰©å±•
> HBaseæ‰©å±•æ€§ä¸»è¦ä½“ç°åœ¨ : 
> åŸºäºä¸Šå±‚å¤„ç†èƒ½åŠ›(RegionServer)çš„æ‰©å±•
> åŸºäºå­˜å‚¨æ‰©å±•(HDFS)
> é€šè¿‡æ¨ªå‘æ·»åŠ RegionServeræœºå™¨,è¿›è¡Œæ°´å¹³æ‰©å±•,æå‡HBaseä¸Šå±‚å¤„ç†èƒ½åŠ›,æå‡HBaseæœåŠ¡æ›´å¤šRegionèƒ½åŠ›.

#### 1.2.4 é«˜å¹¶å‘
> ç”±äºå¤§éƒ¨åˆ†ä½¿ç”¨HBaseæ¶æ„,éƒ½æ˜¯é‡‡ç”¨å»‰ä»·PC,å› æ­¤å•ä¸ªI/Oå»¶è¿Ÿå…¶å®å¹¶ä¸å°,ä¸€èˆ¬åœ¨å‡ ååˆ°å‡ ç™¾æ¯«ç§’ä¹‹é—´,é«˜å¹¶å‘å…¶å®æ˜¯åœ¨å¹¶å‘æƒ…å†µä¸‹,HBaseå•ä¸ªI/Oå»¶è¿Ÿä¸‹é™å¹¶ä¸å¤š,èƒ½è·å¾—é«˜å¹¶å‘,ä½å»¶æ—¶æœåŠ¡.

#### 1.2.5 ç¨€ç–
> ç¨€ç–ä¸»è¦é’ˆå¯¹HBaseåˆ—çš„çµæ´»æ€§,åœ¨åˆ—æ—ä¸­,å¯ä»¥æŒ‡å®šä»»æ„åˆ—,åœ¨åˆ—æ•°æ®ä¸ºç©ºçš„æƒ…å†µä¸‹,æ˜¯ä¸ä¼šå ç”¨å­˜å‚¨ç©ºé—´.

### 1.3 HBase åº”ç”¨åœºæ™¯
- é«˜ååé‡.
- æ€§èƒ½å¯ä¼¸ç¼©.
- æµ·é‡æ•°æ®(TB/PB).
- èƒ½å¤ŸåŒæ—¶å¤„ç†ç»“æ„åŒ–å’Œéç»“æ„åŒ–æ•°æ®.
- éœ€è¦åœ¨æµ·é‡æ•°æ®ä¸­å®ç°é«˜æ•ˆéšæœºè¯»å–.
- ä¸éœ€è¦å®Œå…¨æ‹¥æœ‰ä¼ ç»Ÿå…³ç³»å‹æ•°æ®åº“æ‰€å…·å¤‡(åŸå­æ€§/ä¸€è‡´æ€§/ç‹¬ç«‹æ€§/æŒä¹…æ€§)ACIDç‰¹æ€§.

### 1.4 HBase æ¶æ„
![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hbase/start_001.jpg)
- HBaseä¸€ç§æ˜¯ä½œä¸ºå­˜å‚¨åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ,å¦ä¸€ç§æ˜¯ä½œä¸ºæ•°æ®å¤„ç†æ¨¡å‹çš„MRæ¡†æ¶,å› ä¸ºæ—¥å¸¸å¼€å‘äººå‘˜æ¯”è¾ƒç†Ÿç»ƒçš„æ˜¯ç»“æ„åŒ–çš„æ•°æ®è¿›è¡Œå¤„ç†,ä½†æ˜¯åœ¨HDFSç›´æ¥å­˜å‚¨çš„æ–‡ä»¶å¾€å¾€ä¸å…·æœ‰ç»“æ„åŒ–,æ‰€ä»¥å‚¬ç”Ÿå‡ºäº†HBaseåœ¨HDFSä¸Šæ“ä½œ,å¦‚æœéœ€è¦æŸ¥è¯¢æ•°æ®,åªéœ€è¦é€šè¿‡é”®å€¼ä¾¿å¯ä»¥æˆåŠŸè®¿é—®.
- HBaseé‡‡ç”¨Master/Slaveæ¶æ„,ä¸»è¦è§’è‰²åŒ…æ‹¬(HMaster,ç®¡ç†èŠ‚ç‚¹)MasteræœåŠ¡å™¨,(HRegionServer,æ•°æ®èŠ‚ç‚¹)RegionæœåŠ¡å™¨,ZookeeperæœåŠ¡å™¨ä»¥åŠå®¢æˆ·ç«¯,HBaseä»¥HDFSä½œä¸ºå…¶åº•å±‚å­˜å‚¨æ¥å®ç°æ•°æ®é«˜å¯ç”¨,å…¶æœ¬èº«ä¸å…·å¤‡æ•°æ®å¤åˆ¶åŠŸèƒ½.

### 1.5 HBase è§’è‰²

#### 1.5.1 HMaster
> `HMaster ä¸»èŠ‚ç‚¹`, HMasterä¸»è¦è´Ÿè´£ : HRegionServerç®¡ç†ä»¥åŠå…ƒæ•°æ®æ›´æ”¹,åŒ…æ‹¬ä»¥ä¸‹å†…å®¹(æ–°HRegionServeræ³¨å†Œ / è¡¨çš„å¢åˆ æ”¹æŸ¥ / HRegionServerè´Ÿè½½å‡è¡¡ / Regionè¡¨åˆ†åŒº / åˆ†å¸ƒè°ƒæ•´ / Regionåˆ†è£‚ / è£‚å˜ååˆ†é…ä»¥åŠè¿ç§»).
> 
> HMasteré‡‡ç”¨ä¸»å¤‡æ¨¡å¼éƒ¨ç½²,é›†ç¾¤å¯åŠ¨æ—¶,é€šè¿‡ç«äº‰è·å¾—ä¸»HMasterè§’è‰²,ä¸»HMasteråªèƒ½æœ‰ä¸€ä¸ª,å¤‡HMasterè¿›ç¨‹åœ¨é›†ç¾¤è¿è¡ŒæœŸé—´å¤„äºä¼‘çœ çŠ¶æ€,ä¸å¹²æ¶‰ä»»ä½•é›†ç¾¤äº‹åŠ¡,å½“ä¸»HMasteræ•…éšœæ—¶,å¤‡ç”¨HMasterå°†å–ä»£ä¸»ç”¨HMasterå¯¹å¤–æä¾›æœåŠ¡.
- `HMaster åŠŸèƒ½`
- ç›‘æ§ RegionServer
- å¤„ç† RegionServeræ•…éšœè½¬ç§»
- ç»´æŠ¤é›†ç¾¤è´Ÿè½½å‡è¡¡
- ç»´æŠ¤é›†ç¾¤å…ƒæ•°æ®ä¿¡æ¯
- å¤„ç†Regionåˆ†é…æˆ–ç§»é™¤
- é€šè¿‡Zookeeperå‘å¸ƒè‡ªèº«ä½ç½®ç»™å®¢æˆ·ç«¯

#### 1.5.2 HRegionServer
> HRegionServeræ˜¯HBaseä»èŠ‚ç‚¹,HRegionServerè´Ÿè´£æä¾›è¡¨æ•°æ®è¯»å†™æœåŠ¡,æ˜¯æ•°æ®å­˜å‚¨å’Œå’Œè®¡ç®—å•å…ƒ,HRegionServerä¸HDFSé›†ç¾¤çš„DataNodeéƒ¨ç½²åœ¨ä¸€èµ·,å®ç°æ•°æ®å­˜å‚¨åŠŸèƒ½.
- `HRegionServer åŠŸèƒ½`
- å¤„ç†å®¢æˆ·ç«¯è¯»å†™è¯·æ±‚
- è´Ÿè´£å­˜å‚¨HBaseå®é™…æ•°æ®
- å¤„ç†åˆ†é…ç»™Region
- åˆ·æ–°ç¼“å­˜åˆ°HDFS
- ç»´æŠ¤HLog
- æ‰§è¡Œå‹ç¼©

#### 1.5.3 HDFS
> HDFSä¸ºHBaseæä¾›æœ€ç»ˆåº•å±‚æ•°æ®å­˜å‚¨æœåŠ¡,åŒæ—¶ä¸ºHBaseæä¾›é«˜å¯ç”¨.
> HDFSæä¾›å…ƒæ•°æ®å’Œè¡¨æ•°æ®çš„åº•å±‚åˆ†å¸ƒå¼å­˜å‚¨æœåŠ¡.
> HDFSæ•°æ®å‰¯æœ¬,ä¿è¯é«˜å¯é æ€§å’Œé«˜å¯ç”¨æ€§.

#### 1.5.4 Zookeeper
> Zookeeperä¸ºHBaseé›†ç¾¤å„è¿›ç¨‹æä¾›åˆ†å¸ƒå¼åä½œæœåŠ¡,å„HRegionServerå°†è‡ªèº«ä¿¡æ¯æ³¨å†Œåˆ°Zookeeperä¸­,HMasteræ®æ­¤æ„ŸçŸ¥å„ä¸ªHRegionServerå¥åº·çŠ¶æ€.
> 
> HBaseé€šè¿‡Zookeeperæ¥ä½œä¸ºmasteré«˜å¯ç”¨ / HRegionServerç›‘æ§ / å…ƒæ•°æ®å…¥å£ / é›†ç¾¤é…ç½®ç»´æŠ¤ç­‰.
> 
> é€šè¿‡Zookeeperæ¥ä¿è¯é›†ç¾¤ä¸­åªæœ‰1ä¸ªmasterè¿è¡Œ,å¦‚masterå¼‚å¸¸,ä¼šé€šè¿‡ç«äº‰æœºåˆ¶äº§ç”Ÿæ–°çš„masterå¯¹å¤–æä¾›æœåŠ¡.
> 
> é€šè¿‡Zookeeperæ¥ç›‘æ§HRegionServerçŠ¶æ€,å½“HRegionServeræœ‰å¼‚å¸¸æ—¶,é€šè¿‡å›è°ƒå½¢å¼é€šçŸ¥MasterHRegionServerä¸Šä¸‹çº¿ä¿¡æ¯.
> 
> é€šè¿‡Zookeeperå­˜å‚¨å…ƒæ•°æ®ä¿¡æ¯ç»Ÿä¸€å…¥å£åœ°å€.

#### 1.5.5 Client
> ClientåŒ…æ‹¬è®¿é—®HBaseæ¥å£,å¦å¤–Clientè¿˜ç»´æŠ¤å¯¹åº”çš„Cacheæ¥åŠ é€ŸHBaseè®¿é—®.

#### 1.5.6 å…¶ä»–ç»„ä»¶
##### 1.5.6.1 Write-Ahead logs
> HBaseä¿®æ”¹è®°å½•,å½“å¯¹HBaseè¯»å†™æ•°æ®æ—¶,æ•°æ®ä¸æ˜¯ç›´æ¥å†™è¿›ç£ç›˜,å®ƒä¼šåœ¨å†…å­˜ä¸­ä¿ç•™ä¸€æ®µæ—¶é—´(æ—¶é—´ä»¥åŠæ•°æ®é‡é˜ˆå€¼å¯ä»¥è®¾å®š),ä½†æŠŠæ•°æ®ä¿å­˜åœ¨å†…å­˜ä¸­å¯èƒ½æœ‰æ›´é«˜çš„æ¦‚ç‡å¼•èµ·æ•°æ®ä¸¢å¤±,ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜,æ•°æ®ä¼šå…ˆå†™åœ¨ä¸€ä¸ªå«åšWrite-Ahead logfileæ–‡ä»¶ä¸­,ç„¶åå†å†™å…¥å†…å­˜ä¸­,æ‰€ä»¥åœ¨ç³»ç»Ÿå‡ºç°æ•…éšœæ—¶,æ•°æ®å¯ä»¥é€šè¿‡è¿™ä¸ªæ—¥å¿—æ–‡ä»¶é‡å»º.
##### 1.5.6.2 HFile
> åœ¨ç£ç›˜ä¸Šä¿å­˜åŸå§‹æ•°æ®å®é™…çš„ç‰©ç†æ–‡ä»¶,æ˜¯å®é™…å­˜å‚¨æ–‡ä»¶.
##### 1.5.6.3 Store
> HFileå­˜å‚¨åœ¨Storeä¸­,ä¸€ä¸ªStoreå¯¹åº”HBaseè¡¨ä¸­ä¸€ä¸ªåˆ—æ—.
##### 1.5.6.4 MemStore
> å†…å­˜å­˜å‚¨ä½äºå†…å­˜ä¸­,ç”¨æ¥ä¿å­˜å½“å‰æ•°æ®æ“ä½œ,æ‰€ä»¥å½“æ•°æ®ä¿å­˜åœ¨WALä¸­ä¹‹å,RegsionServerä¼šåœ¨å†…å­˜ä¸­å­˜å‚¨é”®å€¼å¯¹.
##### 1.5.6.5 Region
> Hbaseè¡¨åˆ†ç‰‡,HBaseè¡¨ä¼šæ ¹æ®RowKeyå€¼è¢«åˆ‡åˆ†æˆä¸åŒRegionå­˜å‚¨åœ¨RegionServerä¸­,åœ¨ä¸€ä¸ªRegionServerä¸­å¯ä»¥æœ‰å¤šä¸ªä¸åŒçš„Region.

## 2. HBase éƒ¨ç½²
### 2.1 Zookeeper æœåŠ¡
- ä¿è¯Zookeeperé›†ç¾¤æœåŠ¡æ­£å¸¸è¿è¡Œ
```
[root@systemhub511 zookeeper]$ bin/zkServer.sh start
```
```
[root@systemhub611 zookeeper]$ bin/zkServer.sh start
```
```
[root@systemhub711 zookeeper]$ bin/zkServer.sh start
```
### 2.2 Hadoop æœåŠ¡
- ä¿è¯Hadoopé›†ç¾¤æœåŠ¡æ­£å¸¸è¿è¡Œ
```
[root@systemhub511 hadoop]$ sbin/start-dfs.sh
```
```
[root@systemhub611 hadoop]$ sbin/start-yarn.sh
```
### 2.3 HBase æœåŠ¡
- è§£å‹HBaseåˆ°æŒ‡å®šç›®å½•
```
[root@systemhub511 software]# tar -zxvf hbase-1.3.1-bin.tar.gz -C /opt/module/
```
- é‡å‘½ååŒ…åç§°
```
[root@systemhub511 module]# mv hbase-1.3.1 hbase
```
- æŸ¥çœ‹HBaseç›®å½•ç»“æ„
```
[root@systemhub511 hbase]# ll
total 348
drwxr-xr-x.  4 root root   4096 Apr  5  2017 bin
-rw-r--r--.  1 root root 148959 Apr  7  2017 CHANGES.txt
drwxr-xr-x.  2 root root   4096 Apr  5  2017 conf
drwxr-xr-x. 12 root root   4096 Apr  7  2017 docs
drwxr-xr-x.  7 root root   4096 Apr  7  2017 hbase-webapps
-rw-r--r--.  1 root root    261 Apr  7  2017 LEGAL
drwxr-xr-x.  3 root root   4096 Apr 26 14:43 lib
-rw-r--r--.  1 root root 130696 Apr  7  2017 LICENSE.txt
-rw-r--r--.  1 root root  43258 Apr  7  2017 NOTICE.txt
-rw-r--r--.  1 root root   1477 Sep 21  2016 README.txt
[root@systemhub511 hbase]# 
```
- é…ç½®HBase
- vim `hbase-env.sh`é…ç½®æ–‡ä»¶
```
[root@systemhub511 hbase]# echo $JAVA_HOME
/opt/module/jdk1.8.0_162
[root@systemhub511 hbase]# cd conf/
[root@systemhub511 conf]# vim hbase-env.sh
```
```
# The java implementation to use.  Java 1.7+ required.
export JAVA_HOME=/opt/module/jdk1.8.0_162
export HBASE_MANAGES_ZK=false
```
- vim `hbase-site.xml`é…ç½®æ–‡ä»¶
```
<configuration>
  <property>
   <name>hbase.rootdir</name>   
   <value>hdfs://systemhub511:9000/hbase</value>     
  </property>
  <property>             
    <name>hbase.cluster.distributed</name>
    <value>true</value>
  </property>
  <!--0.98åçš„æ–°å˜åŠ¨,ä¹‹å‰ç‰ˆæœ¬æ²¡æœ‰.port,é»˜è®¤ç«¯å£ä¸º60000 -->
  <property>
    <name>hbase.master.port</name>
    <value>16000</value>
  </property>          
  <property>            
    <name>hbase.zookeeper.quorum</name>
    <value>systemhub511:2181,systemhub611:2181,systemhub711:2181</value>
  </property>
  <property>                        
    <name>hbase.zookeeper.property.dataDir</name>
    <value>/opt/module/zookeeper/zkData</value>
  </property>
</configuration>
```

- vim `regionservers`é…ç½®æ–‡ä»¶
```
systemhub511
systemhub611
systemhub711
```
- åœ¨/usr/local/binç›®å½•ä¸‹åˆ›å»ºè„šæœ¬
- å¯åŠ¨æ‰€æœ‰é›†ç¾¤èŠ‚ç‚¹
- vim `start-cluster.sh`
```
#!/bin/bash
echo "================          Start All Node Services         ==========="
echo "================================================================"
echo "================          Starting Zookeeper              ==========="
echo "================================================================"

for i in root@systemhub511 root@systemhub611 root@systemhub711
do
    ssh $i 'source /etc/profile;/opt/module/zookeeper/bin/zkServer.sh start'
done

echo "================          Starting HDFS           ==========="
ssh root@systemhub511 '/opt/module/hadoop/sbin/start-dfs.sh'

echo "================          Starting YARN           ==========="
ssh root@systemhub611 '/opt/module/hadoop/sbin/start-yarn.sh'

echo "================          Starting JobHistoryServer       ==========="
ssh root@systemhub511 '/opt/module/hadoop/sbin/mr-jobhistory-daemon.sh start historyserver'
```
- å…³é—­æ‰€æœ‰é›†ç¾¤èŠ‚ç‚¹
- vim `stop-cluster.sh`
```
#!/bin/bash
echo "================          Stopping All Node Services      ==========="
echo "================          Stopping JobHistoryServer       ==========="
ssh root@systemhub511 '/opt/module/hadoop/sbin/mr-jobhistory-daemon.sh stop historyserver'

echo "================          Stopping YARN           ==========="
ssh root@systemhub611 '/opt/module/hadoop/sbin/stop-yarn.sh'

echo "================          Stopping HDFS           ==========="
ssh root@systemhub511 '/opt/module/hadoop/sbin/stop-dfs.sh'

echo "================          Stopping Zookeeper      ==========="
for i in root@systemhub511 root@systemhub611 root@systemhub711
do
    ssh $i 'source /etc/profile;/opt/module/zookeeper/bin/zkServer.sh stop'
done
```
- æŸ¥çœ‹æ‰€æœ‰é›†ç¾¤èŠ‚ç‚¹çŠ¶æ€
- vim `jps.sh`
```
 #!/bin/bash
for host in root@systemhub511 root@systemhub611 root@systemhub711
do
    echo "================      $host All Processes             ==========="
    ssh $host '/opt/module/jdk1.8.0_162/bin/jps'
done
```
- HBaseè½¯è¿æ¥Hadoopé…ç½®
```
[root@systemhub511 ~]# ln -s /opt/module/hadoop/etc/hadoop/core-site.xml /opt/module/hbase/conf/core-site.xml
[root@systemhub511 ~]#
[root@systemhub511 ~]# ln -s /opt/module/hadoop/etc/hadoop/hdfs-site.xml /opt/module/hbase/conf/hdfs-site.xml
[root@systemhub511 ~]#
```
- HBaseè¿œç¨‹åˆ†å‘å…¶ä»–é›†ç¾¤
```
[root@systemhub511 ~]# scp -r /opt/module/hbase/ systemhub611:/opt/module/hbase/
[root@systemhub511 ~]# scp -r /opt/module/hbase/ systemhub711:/opt/module/hbase/
```
- å¯åŠ¨HBaseæœåŠ¡
- æ–¹å¼ä¸€
```
[root@systemhub511 hbase]# bin/hbase-daemon.sh start master
[root@systemhub511 hbase]# bin/hbase-daemon.sh start regionserver
```
- æ–¹å¼äºŒ
```
[root@systemhub511 hbase]# bin/start-hbase.sh
starting master, logging to /opt/module/hbase/bin/../logs/hbase-root-master-systemhub511.out
systemhub711: starting regionserver, logging to /opt/module/hbase/bin/../logs/hbase-root-regionserver-systemhub711.out
systemhub611: starting regionserver, logging to /opt/module/hbase/bin/../logs/hbase-root-regionserver-systemhub611.out
systemhub511: starting regionserver, logging to /opt/module/hbase/bin/../logs/hbase-root-regionserver-systemhub511.out
```
- å¦‚æœé›†ç¾¤ä¹‹é—´çš„èŠ‚ç‚¹æ—¶é—´ä¸åŒæ­¥,ä¼šå¯¼è‡´regionserveræ— æ³•å¯åŠ¨,æŠ›å‡º`ClockOutOfSyncException`å¼‚å¸¸
- æ–¹å¼ä¸€:ä¿®æ”¹é›†ç¾¤åŒæ­¥æ—¶é—´æœåŠ¡ - [å¿«é€Ÿå›é¡¾é€šé“](https://geekparkhub.github.io/technical_guide/programing_language/hadoop/hadoop.html#é›†ç¾¤æ—¶é—´åŒæ­¥)
- æ–¹å¼äºŒ:åœ¨é…ç½®æ–‡ä»¶ä¸­è¿½åŠ  `hbase.master.maxclockskew`å±æ€§å€¼ä¸ºæœ€å¤§å€¼å³å¯
```
<property>
  <name>hbase.master.maxclockskew</name>
  <value>180000</value>
  <description>Time difference of regionserver from master</description>
</property>
```
- å¯åŠ¨æœåŠ¡å,æŸ¥çœ‹è¿è¡Œç»“æœ
- å¯ä»¥é€šè¿‡`host:port`æ–¹å¼è®¿é—®HBaseç®¡ç†é¡µ
![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hbase/start_002.jpg)

## 3. HBase Shell
### 3.1 åŸºæœ¬æ“ä½œ
#### 3.1.1 è¿›å…¥HBaseå®¢æˆ·ç«¯å‘½ä»¤è¡Œçª—å£
- `bin/hbase shell`
``` powershell
[root@systemhub511 hbase]# bin/hbase shell
hbase(main):001:0> 
```
#### 3.1.2 æŸ¥çœ‹å¸®åŠ©å‘½ä»¤
- `help`
```
hbase(main):001:0> help
HBase Shell, version 1.3.1, r930b9a55528fe45d8edce7af42fef2d35e77677a, Thu Apr  6 19:36:54 PDT 2017
Type 'help "COMMAND"', (e.g. 'help "get"' -- the quotes are necessary) for help on a specific command.
Commands are grouped. Type 'help "COMMAND_GROUP"', (e.g. 'help "general"') for help on a command group.

COMMAND GROUPS:
  Group name: general
  Commands: status, table_help, version, whoami

  Group name: ddl
  Commands: alter, alter_async, alter_status, create, describe, disable, disable_all, drop, drop_all, enable, enable_all, exists, get_table, is_disabled, is_enabled, list, locate_region, show_filters

The HBase shell is the (J)Ruby IRB with the above HBase-specific commands added.
For more on the HBase Shell, see http://hbase.apache.org/book.html
hbase(main):002:0> 
```
#### 3.1.3 æŸ¥çœ‹å½“å‰æ•°æ®åº“ä¸­æœ‰å“ªäº›è¡¨
- `list`
```
hbase(main):002:0> list
TABLE        
0 row(s) in 0.4020 seconds
=> []
hbase(main):003:0>
```

### 3.2 è¡¨æ“ä½œ
#### 3.2.1 åˆ›å»ºè¡¨
- `create 'è¡¨å','åˆ—æ—å'`
```
hbase(main):003:0> create 'test','info'
0 row(s) in 2.8000 seconds

=> Hbase::Table - test
hbase(main):004:0>
```
#### 3.2.2 æ’å…¥æ•°æ®åˆ°è¡¨
- `put 'è¡¨å','ä¸»é”®ID','åˆ—æ—å:åˆ—åç§°','value'`
```
hbase(main):004:0> put 'test','0001','info:name','testuser001'
0 row(s) in 0.3590 seconds

hbase(main):005:0>
```
#### 3.2.3 æ‰«ææŸ¥çœ‹è¡¨æ•°æ®
- `scan 'è¡¨å'`
```
hbase(main):008:0> scan 'test'
ROW                        COLUMN+CELL                                                                 
 0001                      column=info:age, timestamp=1556459945452, value=60                          
 0001                      column=info:name, timestamp=1556459442613, value=testuser001                
 0002                      column=info:age, timestamp=1556459962770, value=70                          
 0002                      column=info:name, timestamp=1556459836540, value=testuser002                
2 row(s) in 0.0450 seconds

hbase(main):009:0> 
hbase(main):012:0> scan 'test',{STARTROW => '0001',STOPROW => '0002'}
ROW                        COLUMN+CELL
 0001                      column=info:age, timestamp=1556459945452, value=60                          
 0001                      column=info:name, timestamp=1556459442613, value=testuser001                
1 row(s) in 0.0310 seconds

hbase(main):013:0> 
```
#### 3.2.4 æŸ¥çœ‹ æŒ‡å®šè¡Œæˆ–æŒ‡å®šåˆ—æ—:åˆ—æ•°æ®
- `get 'è¡¨å','ä¸»é”®ID'`
```
hbase(main):009:0> get 'test','0001'
COLUMN                     CELL         
 info:age                  timestamp=1556459945452, value=60   
 info:name                 timestamp=1556459442613, value=testuser001
1 row(s) in 0.0460 seconds
hbase(main):010:0> get 'test','0001','info:name'
COLUMN                     CELL                                                                        
 info:name                 timestamp=1556459442613, value=testuser001
1 row(s) in 0.0260 seconds
hbase(main):011:0> 
```
#### 3.2.5 æŸ¥çœ‹è¡¨ç»“æ„
```
hbase(main):011:0> describe 'test'
Table test is ENABLED
test                                                                                                   
COLUMN FAMILIES DESCRIPTION
{NAME => 'info', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FA
LSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOC
KCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0'}                                      
1 row(s) in 0.1010 seconds
hbase(main):012:0> 
```
#### 3.2.6 å˜æ›´è¡¨ä¿¡æ¯
- å°†infoåˆ—æ—ä¸­çš„æ•°æ®å­˜æ”¾3ä¸ªç‰ˆæœ¬
```
hbase(main):014:0> alter 'test',{NAME=>'info',VERSIONS=>3}
Updating all regions with the new schema...
0/1 regions updated.
1/1 regions updated.
Done.
0 row(s) in 3.0960 seconds
hbase(main):015:0> 
hbase(main):015:0> get 'test','0001',{COLUMN=>'info:name',VERSIONS=>3}
COLUMN                     CELL
 info:name                 timestamp=1556459442613, value=testuser001                                  
1 row(s) in 0.0260 seconds
hbase(main):016:0>
```
#### 3.2.7 æ›´æ–°æŒ‡å®šå­—æ®µæ•°æ®
```
hbase(main):004:0> put 'test','0001','info:name','testuser003'
0 row(s) in 0.3590 seconds

hbase(main):005:0>
```
#### 3.2.8 ç»Ÿè®¡è¡¨æ•°æ®è¡Œæ•°
```
hbase(main):016:0> count 'test'
2 row(s) in 0.1140 seconds
=> 2
hbase(main):017:0> 
```
#### 3.2.9 åˆ é™¤æ•°æ®
- åˆ é™¤æŸrowkeyæŸä¸€åˆ—æ•°æ®
```
hbase(main):017:0> delete 'test','0002','info:age'
```
- åˆ é™¤æŸrowkeyå…¨éƒ¨æ•°æ®
```
hbase(main):016:0> deleteall 'test','0001'
```
#### 3.2.10 æ¸…ç©ºè¡¨æ•°æ®
- æ¸…ç©ºè¡¨æ“ä½œé¡ºåºä¸ºå…ˆdisable,ç„¶åå†truncate
```
hbase(main):018:0> truncate 'test'
```
#### 3.2.11 åˆ é™¤è¡¨
- éœ€è¦å…ˆè®©è¯¥è¡¨ä¸ºdisableçŠ¶æ€,ç„¶åæ‰èƒ½åˆ é™¤è¡¨
- å¦‚æœç›´æ¥dropè¡¨,ä¼šæŠ›å‡ºå¼‚å¸¸ï¼š`Drop the named table. Table must first be disabledERROR: Table test is enabled. Disable it first.`
```
hbase(main):019:0> disable 'test'
```
```
hbase(main):020:0> drop 'test'
```

## 4. HBase æ•°æ®ç»“æ„
### 4.1 Row Key
> ä¸nosqlæ•°æ®åº“ä»¬ä¸€æ ·,`row key`æ˜¯ç”¨æ¥æ£€ç´¢è®°å½•ä¸»é”®,è®¿é—®HBASEè¡¨ä¸­çš„è¡Œ,åªæœ‰ä¸‰ç§æ–¹å¼ :
- 1.é€šè¿‡å•ä¸ª`row key`è®¿é—®
- 2.é€šè¿‡`row key`çš„range(æ­£åˆ™)
- 3.å…¨è¡¨æ‰«æ
> `Row key`è¡Œé”®(Row key)å¯ä»¥æ˜¯ä»»æ„å­—ç¬¦ä¸²(æœ€å¤§é•¿åº¦æ˜¯`64KB`,å®é™…åº”ç”¨ä¸­é•¿åº¦ä¸€èˆ¬ä¸º10-100bytes),åœ¨HBASEå†…éƒ¨,`row key`ä¿å­˜ä¸ºå­—èŠ‚æ•°ç»„, å­˜å‚¨æ—¶æ•°æ®æŒ‰ç…§`Row key`çš„å­—å…¸åº(byte order)æ’åºå­˜å‚¨,è®¾è®¡keyæ—¶,è¦å……åˆ†æ’åºå­˜å‚¨è¿™ä¸ªç‰¹æ€§,å°†ç»å¸¸ä¸€èµ·è¯»å–çš„è¡Œå­˜å‚¨æ”¾åˆ°ä¸€èµ·(ä½ç½®ç›¸å…³æ€§).

### 4.2 Columns Family
> åˆ—æ— : HBASEè¡¨ä¸­æ¯ä¸ªåˆ—éƒ½å½’å±äºæŸä¸ªåˆ—æ—,åˆ—æ—æ˜¯è¡¨çš„schemaçš„ä¸€éƒ¨åˆ†(è€Œåˆ—ä¸æ˜¯),å¿…é¡»åœ¨ä½¿ç”¨è¡¨ä¹‹å‰å®šä¹‰,åˆ—åéƒ½ä»¥åˆ—æ—ä½œä¸ºå‰ç¼€,ä¾‹å¦‚`courses:history,courses:math`éƒ½å±äº`courses`è¿™ä¸ªåˆ—æ—.

### 4.3 Cell
> ç”±`{row key, columnFamily, version}` å”¯ä¸€ç¡®å®šå•å…ƒ,cellä¸­æ•°æ®æ˜¯æ²¡æœ‰ç±»å‹çš„,å…¨éƒ¨æ˜¯å­—èŠ‚ç å½¢å¼å­˜è´®,å…³é”®å­— : æ— ç±»å‹/å­—èŠ‚ç .

### 4.4 Time Stamp
> HBASEä¸­é€šè¿‡`rowkey`å’Œ`columns`ç¡®å®šä¸ºä¸€ä¸ªå­˜è´®å•å…ƒç§°ä¸ºcell,æ¯ä¸ªcelléƒ½ä¿å­˜ç€åŒä¸€ä»½æ•°æ®çš„å¤šä¸ªç‰ˆæœ¬,ç‰ˆæœ¬é€šè¿‡æ—¶é—´æˆ³æ¥ç´¢å¼•,`æ—¶é—´æˆ³ç±»å‹`æ˜¯`64ä½æ•´å‹`,æ—¶é—´æˆ³å¯ä»¥ç”±HBASE(åœ¨æ•°æ®å†™å…¥æ—¶è‡ªåŠ¨)èµ‹å€¼,æ­¤æ—¶æ—¶é—´æˆ³æ˜¯ç²¾ç¡®åˆ°æ¯«ç§’çš„å½“å‰ç³»ç»Ÿæ—¶é—´,æ—¶é—´æˆ³ä¹Ÿå¯ä»¥ç”±å¼€å‘è€…æ˜¾å¼èµ‹å€¼,å¦‚æœåº”ç”¨ç¨‹åºè¦é¿å…æ•°æ®ç‰ˆæœ¬å†²çª,å°±å¿…é¡»è‡ªå·±ç”Ÿæˆå…·æœ‰å”¯ä¸€æ€§çš„æ—¶é—´æˆ³,æ¯ä¸ªcellä¸­,ä¸åŒç‰ˆæœ¬çš„æ•°æ®æŒ‰ç…§æ—¶é—´å€’åºæ’åº,å³æœ€æ–°çš„æ•°æ®æ’åœ¨æœ€å‰é¢.
> 
> ä¸ºäº†é¿å…æ•°æ®å­˜åœ¨è¿‡å¤šç‰ˆæœ¬é€ æˆç®¡ç†(åŒ…æ‹¬å­˜è´®å’Œç´¢å¼•)è´Ÿæ‹…,HBASEæä¾›äº†ä¸¤ç§æ•°æ®ç‰ˆæœ¬å›æ”¶æ–¹å¼.
> ä¸€æ˜¯ä¿å­˜æ•°æ®çš„æœ€ånä¸ªç‰ˆæœ¬.
> äºŒæ˜¯ä¿å­˜æœ€è¿‘ä¸€æ®µæ—¶é—´å†…çš„ç‰ˆæœ¬(æ¯”å¦‚æœ€è¿‘ä¸ƒå¤©),ç”¨æˆ·å¯ä»¥é’ˆå¯¹æ¯ä¸ªåˆ—æ—è¿›è¡Œè®¾ç½®.

### 4.5 å‘½åç©ºé—´
![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hbase/start_003.jpg)

> 1.`Table` : è¡¨ , æ‰€ä»¥çš„è¡¨éƒ½æ˜¯å‘½åç©ºé—´çš„æˆå‘˜,æ—¢è¡¨å¿…å±äºæŸä¸ªå‘½åç©ºé—´,å¦‚æœæ²¡æœ‰æŒ‡å®š,åˆ™åœ¨defaulté»˜è®¤å‘½åç©ºé—´ä¸­.
> 
> 2.`RegionServerGroup` : ä¸€ä¸ªå‘½åç©ºé—´åŒ…å«äº†é»˜è®¤çš„RegionServerGroup.
> 
> 3.`Permission` : æƒé™ , å‘½åç©ºé—´èƒ½å¤Ÿè®©å¼€å‘è€…æ¥å®šä¹‰è®¿é—®æ§åˆ¶è¡¨ACL(Access Control List). ä¾‹å¦‚ : åˆ›å»ºè¡¨ / è¯»å–è¡¨ / åˆ é™¤ / æ›´æ–°ç­‰æ“ä½œ. 
> 
> 4.`Quota` : é™é¢ , å¯ä»¥å¼ºåˆ¶ä¸€ä¸ªå‘½åç©ºé—´å¯åŒ…å«çš„regionæ•°æ®.


## 5. HBase åŸç†

### 5.1 HBase è¯»æ•°æ®æµç¨‹

![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hbase/start_005.jpg)
- 1.Clientå…ˆè®¿é—®Zookeeper,ä»metaè¡¨è¯»å–regionä½ç½®,ç„¶åè¯»å–metaè¡¨ä¸­æ•°æ®,metaä¸­åˆå­˜å‚¨äº†ç”¨æˆ·è¡¨çš„regionä¿¡æ¯.
- 2.æ ¹æ®namespaceã€è¡¨åå’Œrowkeyåœ¨metaè¡¨ä¸­æ‰¾åˆ°å¯¹åº”çš„regionä¿¡æ¯.
- 3.æ‰¾åˆ°regionå¯¹åº”çš„RegionServer.
- 4.æŸ¥æ‰¾å¯¹åº”çš„region.
- 5.å…ˆä»MemStoreæ‰¾æ•°æ®,å¦‚æœæ²¡æœ‰,å†åˆ°StoreFileä¸Šè¯»(ä¸ºäº†è¯»å–æ•ˆç‡).
![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hbase/start_008.jpg)

- æŸ¥çœ‹HBaseå…ƒæ•°æ®å†…å®¹
![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hbase/start_004.jpg)
- æŸ¥çœ‹Zookeeperå­˜å‚¨æ•°æ®å†…å®¹
```
[zk: localhost:2181(CONNECTED) 0] ls /
[cluster, controller_epoch, controller, brokers, zookeeper, admin, isr_change_notification, consumers, latest_producer_id_block, config, hbase]
```
- æŸ¥çœ‹Zookeeperå­˜å‚¨HBaseæ•°æ®å†…å®¹
```
[zk: localhost:2181(CONNECTED) 1] ls /hbase
[replication, meta-region-server, rs, splitWAL, backup-masters, table-lock, flush-table-proc, region-in-transition, online-snapshot, switch, master, running, recovering-regions, draining, namespace, hbaseid, table]
[zk: localhost:2181(CONNECTED) 2] 
```
- æŸ¥çœ‹Zookeeperå­˜å‚¨HBase meta-region-server
```
[zk: localhost:2181(CONNECTED) 4] get /hbase/meta-region-server
ï¿½regionserver:16020eï¿½ï¿½;0Zï¿½PBUF
â½â‰¤â½â”œâŠâ””â¤â”¤â‰711ï¿½Â£ï¿½ï¿½ï¿½ï¿½ï¿½-
âŒZâ”‚â‹â = 0â”‚1âŠ00000051
âŒâ”œâ‹â””âŠ = Mâºâ”¼ Aâ»â¼ 29 01:37:37 CST 2019
â””Zâ”‚â‹â = 0â”‚1âŠ00000051
â””â”œâ‹â””âŠ = Mâºâ”¼ Aâ»â¼ 29 01:37:37 CST 2019
â»Zâ”‚â‹â = 0â”‚1âŠ00000051
âŒâ”´âŠâ¼â½â‹âºâ”¼ = 0
ââ–’â”œâ–’VâŠâ¼â½â‹âºâ”¼ = 0
â–’âŒâ”ŒVâŠâ¼â½â‹âºâ”¼ = 0
âŠâ»â¤âŠâ””âŠâ¼â–’â”ŒOâ”¬â”¼âŠâ¼ = 0â”‚0
ââ–’â”œâ–’LâŠâ”¼Â±â”œâ¤ = 65
â”¼â”¤â””Câ¤â‹â”Œââ¼âŠâ”¼ = 0
[â‰¥â”: â”ŒâºâŒâ–’â”Œâ¤âºâ½â”œ:2181(CONNECTED) 5] 
```
- æŸ¥çœ‹hbase:metaå…ƒæ•°æ®ä¿¡æ¯è¡¨
```
hbase(main):002:0> scan 'hbase:meta'
ROW                        COLUMN+CELL                                                                 
 hbase:namespace,,15562836 column=info:regioninfo, timestamp=1556473360414, value={ENCODED => d89184e0b
 52968.d89184e0b0e8bf9782b 0e8bf9782b86edf991f56d2, NAME => 'hbase:namespace,,1556283652968.d89184e0b0e
 86edf991f56d2.            8bf9782b86edf991f56d2.', STARTKEY => '', ENDKEY => ''}                      
 hbase:namespace,,15562836 column=info:seqnumDuringOpen, timestamp=1556473360414, value=\x00\x00\x00\x0
 52968.d89184e0b0e8bf9782b 0\x00\x00\x00\x14                                                           
 86edf991f56d2.                                                                                        
 hbase:namespace,,15562836 column=info:server, timestamp=1556473360414, value=systemhub511:16020       
 52968.d89184e0b0e8bf9782b                                                                             
 86edf991f56d2.                                                                                        
 hbase:namespace,,15562836 column=info:serverstartcode, timestamp=1556473360414, value=1556473045363   
 52968.d89184e0b0e8bf9782b                                                                             
 86edf991f56d2.                                                                                        
 test,,1556459101215.6b00f column=info:regioninfo, timestamp=1556473359938, value={ENCODED => 6b00fc62a
 c62ac627c675022a7fafb6fbf c627c675022a7fafb6fbfa0, NAME => 'test,,1556459101215.6b00fc62ac627c675022a7
 a0.                       fafb6fbfa0.', STARTKEY => '', ENDKEY => ''}                                 
 test,,1556459101215.6b00f column=info:seqnumDuringOpen, timestamp=1556473359938, value=\x00\x00\x00\x0
 c62ac627c675022a7fafb6fbf 0\x00\x00\x00\x13                                                           
 a0.                                                                                                   
 test,,1556459101215.6b00f column=info:server, timestamp=1556473359938, value=systemhub611:16020       
 c62ac627c675022a7fafb6fbf                                                                             
 a0.                                                                                                   
 test,,1556459101215.6b00f column=info:serverstartcode, timestamp=1556473359938, value=1556473042292   
 c62ac627c675022a7fafb6fbf                                                                             
 a0.                                                                                                   
2 row(s) in 0.0530 seconds

hbase(main):003:0> 
```

### 5.2 HBase å†™æ•°æ®æµç¨‹
![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hbase/start_007.jpg)
- 1.Clientå‘HregionServerå‘é€å†™è¯·æ±‚
- 2.HregionServerå°†æ•°æ®å†™åˆ°HLog(write ahead log),ä¸ºäº†æ•°æ®æŒä¹…åŒ–å’Œæ¢å¤.
- 3.HregionServerå°†æ•°æ®å†™åˆ°å†…å­˜(MemStore)
- 4.åé¦ˆClientå†™å…¥æˆåŠŸ.
![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hbase/start_006.jpg)

### 5.3 HBase æ•°æ®Flushè¿‡ç¨‹
- 1.å½“MemStoreæ•°æ®è¾¾åˆ°é˜ˆå€¼(é»˜è®¤æ˜¯128M,è€ç‰ˆæœ¬æ˜¯64M),å°†æ•°æ®åˆ·åˆ°ç¡¬ç›˜,å°†å†…å­˜ä¸­æ•°æ®åˆ é™¤,åŒæ—¶åˆ é™¤HLogä¸­å†å²æ•°æ®.
- 2.å¹¶å°†æ•°æ®å­˜å‚¨åˆ°HDFSä¸­.
- 3.åœ¨HLogä¸­åšæ ‡è®°ç‚¹.

### 5.4 HBase æ•°æ®Compactè¿‡ç¨‹
- 1.å½“æ•°æ®å—è¾¾åˆ°4å—,Hmasterå°†æ•°æ®å—åŠ è½½åˆ°æœ¬åœ°è¿›è¡Œåˆå¹¶.
- 2.å½“åˆå¹¶æ•°æ®è¶…è¿‡256M,è¿›è¡Œæ‹†åˆ†,å°†æ‹†åˆ†åçš„Regionåˆ†é…ç»™ä¸åŒçš„HregionServerç®¡ç†.
- 3.å½“HregionServerå®•æœºå,å°†HregionServerä¸Šçš„hlogæ‹†åˆ†,ç„¶ååˆ†é…ç»™ä¸åŒHregionServeråŠ è½½,ä¿®æ”¹.META
- 4.æ³¨æ„ : HLogä¼šåŒæ­¥åˆ°HDFS.

### 5.5 Hmaster èŒè´£
- 1.ç®¡ç†ç”¨æˆ·å¯¹Tableå¢ã€åˆ ã€æ”¹ã€æŸ¥æ“ä½œ.
- 2.è®°å½•Regionåœ¨å“ªä¸€å°HRegion ServeræœåŠ¡å™¨ä¸Š.
- 3.åœ¨Region Splitå,è´Ÿè´£æ–°Regionåˆ†é….
- 4.æ–°æœºå™¨åŠ å…¥æ—¶,ç®¡ç†HRegion Serverè´Ÿè½½å‡è¡¡,è°ƒæ•´Regionåˆ†å¸ƒ.
- 5.åœ¨HRegion Serverå®•æœºå,è´Ÿè´£å¤±æ•ˆHRegion Serverä¸Šçš„Regionsè¿ç§».

### 5.6 HRegionServer èŒè´£
- 1.HRegion Serverä¸»è¦è´Ÿè´£å“åº”ç”¨æˆ·I/Oè¯·æ±‚.å‘HDFSæ–‡ä»¶ç³»ç»Ÿä¸­è¯»å†™æ•°æ®.æ˜¯HBASEä¸­æœ€æ ¸å¿ƒæ¨¡å—.
- 2.HRegion Serverç®¡ç†äº†å¾ˆå¤štableåˆ†åŒº,ä¹Ÿå°±æ˜¯region.

### 5.7 Client èŒè´£
- 1.HBASE Clientä½¿ç”¨HBASEçš„RPCæœºåˆ¶ä¸HMasterå’ŒRegionServerè¿›è¡Œé€šä¿¡.
- 2.ç®¡ç†ç±»æ“ä½œ : Clientä¸HMasterè¿›è¡ŒRPC.
- 3.æ•°æ®è¯»å†™ç±»æ“ä½œ : Clientä¸HRegionServerè¿›è¡ŒRPC.

## 6. HBase New API
### 6.1 ç¯å¢ƒå‡†å¤‡
- JetBrains IntelliJ IDEA New Maven Project | æ­¤è¿‡ç¨‹çœç•¥
- Add pom.xml
``` xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <groupId>com.geekparkhub.core.hbase.api</groupId>
    <artifactId>hbase_server</artifactId>
    <version>1.0-SNAPSHOT</version>
    <dependencies>
        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-server</artifactId>
            <version>1.3.1</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-client</artifactId>
            <version>1.3.1</version>
        </dependency>
        <dependency>
            <groupId>jdk.tools</groupId>
            <artifactId>jdk.tools</artifactId>
            <version>1.8</version>
            <scope>system</scope>
            <systemPath>/Library/Java/JavaVirtualMachines/jdk1.8.0_201.jdk/Contents/Home/lib/tools.jar</systemPath>
        </dependency>
    </dependencies>
</project>
```

### 6.2 åˆ¤æ–­æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
``` java
package com.geekparkhub.core.hbase.api.producehub;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.*;
import org.apache.hadoop.hbase.client.*;
import org.apache.hadoop.hbase.util.Bytes;

import java.io.IOException;

/**
 * Geek International Park | æå®¢å›½é™…å…¬å›­
 * GeekParkHub | æå®¢å®éªŒå®¤
 * Website | https://www.geekparkhub.com/
 * Description | Openå¼€æ”¾ Â· Creationåˆ›æƒ³ | OpenSourceå¼€æ”¾æˆå°±æ¢¦æƒ³ GeekParkHubå…±å»ºå‰æ‰€æœªè§
 * HackerParkHub | é»‘å®¢å…¬å›­æ¢çº½
 * Website | https://www.hackerparkhub.com/
 * Description | ä»¥æ— æ‰€ç•æƒ§çš„æ¢ç´¢ç²¾ç¥ å¼€åˆ›æœªçŸ¥æŠ€æœ¯ä¸å¯¹æŠ€æœ¯çš„å´‡æ‹œ
 * GeekDeveloper : JEEP-711
 *
 * @author system
 * <p>
 * HbaseHub
 * <p>
 */

public class HbaseHub {

    /**
     * Public Configuration information
     * å…¬å…±é…ç½®ä¿¡æ¯
     */
    private static Admin admin = null;
    private static Connection connection = null;
    private static Configuration configuration;

    static {
        /**
         * HBase ConfigurationFile
         * HBase é…ç½®æ–‡ä»¶
         */
        configuration = HBaseConfiguration.create();
        configuration.set("hbase.zookeeper.quorum", "172.16.168.130");
        configuration.set("hbase.zookeeper.property.clientPort", "2181");
        try {
            /**
             * Get Connected
             * è·å–è¿æ¥
             */
            connection = ConnectionFactory.createConnection(configuration);

            /**
             * Get HBase Administrator Object
             * è·å–HBaseç®¡ç†å‘˜å¯¹è±¡
             */
            admin = connection.getAdmin();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    /**
     * Close Resource
     * å…³é—­èµ„æº
     *
     * @param conf
     * @param admin
     */
    private static void close(Connection conf, Admin admin) {
        if (conf != null) {
            try {
                conf.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
        if (admin != null) {
            try {
                admin.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }

    /**
     * Determine if DataTable Exists
     * åˆ¤æ–­æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
     *
     * @param tableName
     */
    public static boolean isTableExist(String tableName) throws IOException {

        /**
         * Execution Method
         * æ‰§è¡Œæ–¹æ³•
         */
        boolean tableExists = admin.tableExists(TableName.valueOf(tableName));

        return tableExists;
    }

    public static void main(String[] args) throws IOException {

        /**
         * isTableExist Result
         */
        System.out.printf("test isTableExist Result is = " + String.valueOf(isTableExist("test")) + "\n");
        System.out.printf("test001 isTableExist Result is = " + String.valueOf(isTableExist("test001")) + "\n");
        System.out.printf("test002 isTableExist Result is = " + String.valueOf(isTableExist("test002")) + "\n");
        System.out.printf("test003 isTableExist Result is = " + String.valueOf(isTableExist("test003")) + "\n");

        /**
         * Close Resource
         * å…³é—­èµ„æº
         */
        close(connection, admin);
    }
}
```
- æ‰§è¡Œè¿”å›ç»“æœ
``` prolog
test isTableExist Result is = true
test001 isTableExist Result is = true
test002 isTableExist Result is = false
test003 isTableExist Result is = false
```


### 6.3 åˆ›å»ºæ•°æ®è¡¨
``` java
package com.geekparkhub.core.hbase.api.producehub;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.*;
import org.apache.hadoop.hbase.client.*;
import org.apache.hadoop.hbase.util.Bytes;

import java.io.IOException;

/**
 * Geek International Park | æå®¢å›½é™…å…¬å›­
 * GeekParkHub | æå®¢å®éªŒå®¤
 * Website | https://www.geekparkhub.com/
 * Description | Openå¼€æ”¾ Â· Creationåˆ›æƒ³ | OpenSourceå¼€æ”¾æˆå°±æ¢¦æƒ³ GeekParkHubå…±å»ºå‰æ‰€æœªè§
 * HackerParkHub | é»‘å®¢å…¬å›­æ¢çº½
 * Website | https://www.hackerparkhub.com/
 * Description | ä»¥æ— æ‰€ç•æƒ§çš„æ¢ç´¢ç²¾ç¥ å¼€åˆ›æœªçŸ¥æŠ€æœ¯ä¸å¯¹æŠ€æœ¯çš„å´‡æ‹œ
 * GeekDeveloper : JEEP-711
 *
 * @author system
 * <p>
 * HbaseHub
 * <p>
 */

public class HbaseHub {

    /**
     * Public Configuration information
     * å…¬å…±é…ç½®ä¿¡æ¯
     */
    private static Admin admin = null;
    private static Connection connection = null;
    private static Configuration configuration;

    static {

        /**
         * HBase ConfigurationFile
         * HBase é…ç½®æ–‡ä»¶
         */
        configuration = HBaseConfiguration.create();
        configuration.set("hbase.zookeeper.quorum", "172.16.168.130");
        configuration.set("hbase.zookeeper.property.clientPort", "2181");
        try {
            /**
             * Get Connected
             * è·å–è¿æ¥
             */
            connection = ConnectionFactory.createConnection(configuration);

            /**
             * Get HBase Administrator Object
             * è·å–HBaseç®¡ç†å‘˜å¯¹è±¡
             */
            admin = connection.getAdmin();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    /**
     * Close Resource
     * å…³é—­èµ„æº
     *
     * @param conf
     * @param admin
     */
    private static void close(Connection conf, Admin admin) {
        if (conf != null) {
            try {
                conf.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
        if (admin != null) {
            try {
                admin.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }

    /**
     * Determine if DataTable Exists
     * åˆ¤æ–­æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
     *
     * @param tableName
     */
    public static boolean isTableExist(String tableName) throws IOException {

        /**
         * Execution Method
         * æ‰§è¡Œæ–¹æ³•
         */
        boolean tableExists = admin.tableExists(TableName.valueOf(tableName));

        return tableExists;
    }

    /**
     * Create DataTable
     * åˆ›å»ºæ•°æ®è¡¨
     *
     * @param tableName
     * @param columnFamily
     * @throws IOException
     */
    public static void createTable(String tableName, String... columnFamily) throws IOException {

        /**
         * Verify that the DataTable Exists Before Creating the DataTable
         * åˆ›å»ºæ•°æ®è¡¨å‰,éªŒè¯æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
         */
        if (isTableExist(tableName)) {
            System.out.printf(tableName + " Data table creation failed , " + tableName + " Data table already exists!" + "\n");
            return;
        }

        /**
         * Instantiation Table Description information
         * å®ä¾‹åŒ– è¡¨æè¿°ä¿¡æ¯
         */
        HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(tableName));

        /**
         * Add Multiple Column Families
         * æ·»åŠ å¤šä¸ªåˆ—æ—
         */
        for (String cn : columnFamily) {
            /**
             * Instantiation Column Name Description information
             * å®ä¾‹åŒ– åˆ—åæè¿°ä¿¡æ¯
             */
            HColumnDescriptor columnDescriptor = new HColumnDescriptor(String.valueOf(cn));
            tableDescriptor.addFamily(columnDescriptor);
        }
        /**
         * Execution Method
         * æ‰§è¡Œæ–¹æ³•
         */
        admin.createTable(tableDescriptor);

        /**
         * Logger INFO
         */
        System.out.printf(tableName + " Data Sheet Was Created Successfully!" + "\n");
    }

    public static void main(String[] args) throws IOException {

        /**
         * CreateTable Result
         */
        createTable("test001", "info");
        createTable("test_factory", "factorymode", "factoryinfo");
        System.out.printf("factory TableExist Result is = " + String.valueOf(isTableExist("factory")) + "\n");
        System.out.printf("test_factory TableExist Result is = " + String.valueOf(isTableExist("test_factory")) + "\n");

        /**
         * Close Resource
         * å…³é—­èµ„æº
         */
        close(connection, admin);
    }
}
```
- æ‰§è¡Œè¿”å›ç»“æœ
``` prolog
test001 Data sheet was created successfully!
test_factory Data sheet was created successfully!
test_factory TableExist Result is = true
factory TableExist Result is = false
```


### 6.4 åˆ é™¤æ•°æ®è¡¨
``` java
package com.geekparkhub.core.hbase.api.producehub;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.*;
import org.apache.hadoop.hbase.client.*;
import org.apache.hadoop.hbase.util.Bytes;

import java.io.IOException;

/**
 * Geek International Park | æå®¢å›½é™…å…¬å›­
 * GeekParkHub | æå®¢å®éªŒå®¤
 * Website | https://www.geekparkhub.com/
 * Description | Openå¼€æ”¾ Â· Creationåˆ›æƒ³ | OpenSourceå¼€æ”¾æˆå°±æ¢¦æƒ³ GeekParkHubå…±å»ºå‰æ‰€æœªè§
 * HackerParkHub | é»‘å®¢å…¬å›­æ¢çº½
 * Website | https://www.hackerparkhub.com/
 * Description | ä»¥æ— æ‰€ç•æƒ§çš„æ¢ç´¢ç²¾ç¥ å¼€åˆ›æœªçŸ¥æŠ€æœ¯ä¸å¯¹æŠ€æœ¯çš„å´‡æ‹œ
 * GeekDeveloper : JEEP-711
 *
 * @author system
 * <p>
 * HbaseHub
 * <p>
 */

public class HbaseHub {

    /**
     * Public Configuration information
     * å…¬å…±é…ç½®ä¿¡æ¯
     */
    private static Admin admin = null;
    private static Connection connection = null;
    private static Configuration configuration;

    static {

        /**
         * HBase ConfigurationFile
         * HBase é…ç½®æ–‡ä»¶
         */
        configuration = HBaseConfiguration.create();
        configuration.set("hbase.zookeeper.quorum", "172.16.168.130");
        configuration.set("hbase.zookeeper.property.clientPort", "2181");
        try {
        
            /**
             * Get Connected
             * è·å–è¿æ¥
             */
            connection = ConnectionFactory.createConnection(configuration);

            /**
             * Get HBase Administrator Object
             * è·å–HBaseç®¡ç†å‘˜å¯¹è±¡
             */
            admin = connection.getAdmin();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    /**
     * Close Resource
     * å…³é—­èµ„æº
     *
     * @param conf
     * @param admin
     */
    private static void close(Connection conf, Admin admin) {
        if (conf != null) {
            try {
                conf.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
        if (admin != null) {
            try {
                admin.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }

    /**
     * Determine if DataTable Exists
     * åˆ¤æ–­æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
     *
     * @param tableName
     */
    public static boolean isTableExist(String tableName) throws IOException {

        /**
         * Execution Method
         * æ‰§è¡Œæ–¹æ³•
         */
        boolean tableExists = admin.tableExists(TableName.valueOf(tableName));

        return tableExists;
    }

    /**
     * Delete Data Table
     * åˆ é™¤æ•°æ®è¡¨
     *
     * @param tableName
     * @throws IOException
     */
    public static void deleteTable(String tableName) throws IOException {

        /**
         * Before Deleting the Data Table, Verify that the Data Table Exists.
         */
        if (!isTableExist(tableName)) {
            System.out.println("Data Table Deletion Failed , Reason : The Data Table Does Not Exist !");
            return;
        }

        /**
         * Data Table Offline
         * æ•°æ®è¡¨ä¸‹çº¿
         */
        admin.disableTable(TableName.valueOf(tableName));

        /**
         * Delete Data Table
         * åˆ é™¤æ•°æ®è¡¨
         */
        admin.deleteTable(TableName.valueOf(tableName));

        /**
         * Logger INFO
         */
        System.out.println("Data Table Has Been Deleted Successfully!");
    }

    public static void main(String[] args) throws IOException {

        /**
         * Delete Data Table
         */
        deleteTable("test_factory");

        /**
         * Close Resource
         * å…³é—­èµ„æº
         */
        close(connection, admin);
    }
}
```
- æ‰§è¡Œè¿”å›ç»“æœ
```
INFO [org.apache.hadoop.hbase.client.HBaseAdmin] - Disabled test_factory
INFO [org.apache.hadoop.hbase.client.HBaseAdmin] - Deleted test_factory
Data Table Has Been Deleted Successfully!
```


### 6.5 æ·»åŠ æ•°æ®
``` java
package com.geekparkhub.core.hbase.api.producehub;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.*;
import org.apache.hadoop.hbase.client.*;
import org.apache.hadoop.hbase.util.Bytes;

import java.io.IOException;

/**
 * Geek International Park | æå®¢å›½é™…å…¬å›­
 * GeekParkHub | æå®¢å®éªŒå®¤
 * Website | https://www.geekparkhub.com/
 * Description | Openå¼€æ”¾ Â· Creationåˆ›æƒ³ | OpenSourceå¼€æ”¾æˆå°±æ¢¦æƒ³ GeekParkHubå…±å»ºå‰æ‰€æœªè§
 * HackerParkHub | é»‘å®¢å…¬å›­æ¢çº½
 * Website | https://www.hackerparkhub.com/
 * Description | ä»¥æ— æ‰€ç•æƒ§çš„æ¢ç´¢ç²¾ç¥ å¼€åˆ›æœªçŸ¥æŠ€æœ¯ä¸å¯¹æŠ€æœ¯çš„å´‡æ‹œ
 * GeekDeveloper : JEEP-711
 *
 * @author system
 * <p>
 * HbaseHub
 * <p>
 */

public class HbaseHub {

    /**
     * Public Configuration information
     * å…¬å…±é…ç½®ä¿¡æ¯
     */
    private static Admin admin = null;
    private static Connection connection = null;
    private static Configuration configuration;

    static {

        /**
         * HBase ConfigurationFile
         * HBase é…ç½®æ–‡ä»¶
         */
        configuration = HBaseConfiguration.create();
        configuration.set("hbase.zookeeper.quorum", "172.16.168.130");
        configuration.set("hbase.zookeeper.property.clientPort", "2181");
        try {
            
            /**
             * Get Connected
             * è·å–è¿æ¥
             */
            connection = ConnectionFactory.createConnection(configuration);

            /**
             * Get HBase Administrator Object
             * è·å–HBaseç®¡ç†å‘˜å¯¹è±¡
             */
            admin = connection.getAdmin();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
    
    /**
     * Close Resource
     * å…³é—­èµ„æº
     *
     * @param conf
     * @param admin
     */
    private static void close(Connection conf, Admin admin) {
        if (conf != null) {
            try {
                conf.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
        if (admin != null) {
            try {
                admin.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }
    
    /**
     * Determine if DataTable Exists
     * åˆ¤æ–­æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
     *
     * @param tableName
     */
    public static boolean isTableExist(String tableName) throws IOException {

        /**
         * Execution Method
         * æ‰§è¡Œæ–¹æ³•
         */
        boolean tableExists = admin.tableExists(TableName.valueOf(tableName));

        return tableExists;
    }
    
    /**
     * Adding Data
     * æ·»åŠ æ•°æ®
     *
     * @param tableName
     * @param rowKey
     * @param columnFamily
     * @param columnName
     * @param value
     * @throws IOException
     */
    public static void addData(String tableName, String rowKey, String columnFamily, String columnName, String value) throws IOException {

        /**
         * Instantiated Table Object
         * å®ä¾‹åŒ– è¡¨å¯¹è±¡
         */
        Table table = connection.getTable(TableName.valueOf(tableName));

        /**
         * Verify that the data table exists before adding data
         * æ·»åŠ æ•°æ®å‰,éªŒè¯æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
         */
        if (!isTableExist(String.valueOf(TableName.valueOf(tableName)))) {
            System.out.println("Adding Data Failed, Reason: " + table + "DataTable Does Not Exist !");
            return;
        }

        /**
         * Instantiate Put Object
         * å®ä¾‹åŒ– Putå¯¹è±¡
         *
         * Convert String type primary key ID to byte data
         * å°†Stringç±»å‹ä¸»é”®IDè½¬æ¢å­—èŠ‚æ•°æ®
         */
        Put put = new Put(Bytes.toBytes(rowKey));

        /**
         * Add data (column family/column name/numeric) and convert the String type to a byte array
         * æ·»åŠ æ•°æ® (åˆ—æ—/ åˆ—å / æ•°å€¼)å¹¶å°†Stringç±»å‹è½¬æ¢ä¸ºå­—èŠ‚æ•°ç»„
         */
        put.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes(columnName), Bytes.toBytes(value));

        /**
         * Execution method
         * æ‰§è¡Œæ–¹æ³•
         */
        table.put(put);

        System.out.println(table.toString() + " Data added Successfully !");

        /**
         * Close resource
         * å…³é—­èµ„æº
         */
        table.close();
    }
    
    public static void main(String[] args) throws IOException {

        /**
         * Adding Data
         */
        addData("test001", "0003", "info", "name", "testUser003");

        /**
         * Close Resource
         * å…³é—­èµ„æº
         */
        close(connection, admin);
    }
}
```
- æ‰§è¡Œè¿”å›ç»“æœ
```
test001;hconnection-0x281e3708 Data added Successfully
```

### 6.6 ä¿®æ”¹æ•°æ®
``` java
package com.geekparkhub.core.hbase.api.producehub;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.*;
import org.apache.hadoop.hbase.client.*;
import org.apache.hadoop.hbase.util.Bytes;

import java.io.IOException;

/**
 * Geek International Park | æå®¢å›½é™…å…¬å›­
 * GeekParkHub | æå®¢å®éªŒå®¤
 * Website | https://www.geekparkhub.com/
 * Description | Openå¼€æ”¾ Â· Creationåˆ›æƒ³ | OpenSourceå¼€æ”¾æˆå°±æ¢¦æƒ³ GeekParkHubå…±å»ºå‰æ‰€æœªè§
 * HackerParkHub | é»‘å®¢å…¬å›­æ¢çº½
 * Website | https://www.hackerparkhub.com/
 * Description | ä»¥æ— æ‰€ç•æƒ§çš„æ¢ç´¢ç²¾ç¥ å¼€åˆ›æœªçŸ¥æŠ€æœ¯ä¸å¯¹æŠ€æœ¯çš„å´‡æ‹œ
 * GeekDeveloper : JEEP-711
 *
 * @author system
 * <p>
 * HbaseHub
 * <p>
 */

public class HbaseHub {

    /**
     * Public Configuration information
     * å…¬å…±é…ç½®ä¿¡æ¯
     */
    private static Admin admin = null;
    private static Connection connection = null;
    private static Configuration configuration;

    static {

        /**
         * HBase ConfigurationFile
         * HBase é…ç½®æ–‡ä»¶
         */
        configuration = HBaseConfiguration.create();
        configuration.set("hbase.zookeeper.quorum", "172.16.168.130");
        configuration.set("hbase.zookeeper.property.clientPort", "2181");
        try {

            /**
             * Get Connected
             * è·å–è¿æ¥
             */
            connection = ConnectionFactory.createConnection(configuration);

            /**
             * Get HBase Administrator Object
             * è·å–HBaseç®¡ç†å‘˜å¯¹è±¡
             */
            admin = connection.getAdmin();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    /**
     * Close Resource
     * å…³é—­èµ„æº
     *
     * @param conf
     * @param admin
     */
    private static void close(Connection conf, Admin admin) {
        if (conf != null) {
            try {
                conf.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
        if (admin != null) {
            try {
                admin.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }

    /**
     * Determine if DataTable Exists
     * åˆ¤æ–­æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
     *
     * @param tableName
     */
    public static boolean isTableExist(String tableName) throws IOException {

        /**
         * Execution Method
         * æ‰§è¡Œæ–¹æ³•
         */
        boolean tableExists = admin.tableExists(TableName.valueOf(tableName));

        return tableExists;
    }

    /**
     * Change Data
     * ä¿®æ”¹æ•°æ®
     *
     * @param tableName
     * @param rowKey
     * @param columnFamily
     * @param columnName
     * @param value
     */
    public static void changeData(String tableName, String rowKey, String columnFamily, String columnName, String value) throws IOException {

        /**
         * Instantiated Table Object
         * å®ä¾‹åŒ– è¡¨å¯¹è±¡
         */
        Table table = connection.getTable(TableName.valueOf(tableName));

        /**
         * Verify that the data table exists before modifying the data
         * ä¿®æ”¹æ•°æ®å‰,éªŒè¯æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
         */
        if (!isTableExist(String.valueOf(TableName.valueOf(tableName)))) {
            System.out.println("Change Data Failed, Reason: " + table + "DataTable Does Not Exist !");
            return;
        }

        /**
         * Instantiate Put Object
         * å®ä¾‹åŒ– Putå¯¹è±¡
         *
         * Convert String type primary key ID to byte data
         * å°†Stringç±»å‹ä¸»é”®IDè½¬æ¢å­—èŠ‚æ•°æ®
         */
        Put put = new Put(Bytes.toBytes(rowKey));

        /**
         * Change data (column family/column name/numeric) and convert the String type to a byte array
         * ä¿®æ”¹æ•°æ® (åˆ—æ—/ åˆ—å / æ•°å€¼)å¹¶å°†Stringç±»å‹è½¬æ¢ä¸ºå­—èŠ‚æ•°ç»„
         */
        put.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes(columnName), Bytes.toBytes(value));

        /**
         * Execution method
         * æ‰§è¡Œæ–¹æ³•
         */
        table.put(put);

        System.out.println(table.toString() + " Data Change Successfully !");

        /**
         * Close resource
         * å…³é—­èµ„æº
         */
        table.close();
    }

    public static void main(String[] args) throws IOException {

        /**
         * Change Data
         */
        changeData("test001", "0003", "info", "name", "testUser004");

        /**
         * Close Resource
         * å…³é—­èµ„æº
         */
        close(connection, admin);
    }
}
```
- æ‰§è¡Œè¿”å›ç»“æœ
```
test001;hconnection-0x281e3708 Data Change Successfully!
```


### 6.7 æŸ¥è¯¢æ•°æ®
#### 6.7.1 å…¨è¡¨æ‰«æ
``` java
package com.geekparkhub.core.hbase.api.producehub;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.*;
import org.apache.hadoop.hbase.client.*;
import org.apache.hadoop.hbase.util.Bytes;

import java.io.IOException;

/**
 * Geek International Park | æå®¢å›½é™…å…¬å›­
 * GeekParkHub | æå®¢å®éªŒå®¤
 * Website | https://www.geekparkhub.com/
 * Description | Openå¼€æ”¾ Â· Creationåˆ›æƒ³ | OpenSourceå¼€æ”¾æˆå°±æ¢¦æƒ³ GeekParkHubå…±å»ºå‰æ‰€æœªè§
 * HackerParkHub | é»‘å®¢å…¬å›­æ¢çº½
 * Website | https://www.hackerparkhub.com/
 * Description | ä»¥æ— æ‰€ç•æƒ§çš„æ¢ç´¢ç²¾ç¥ å¼€åˆ›æœªçŸ¥æŠ€æœ¯ä¸å¯¹æŠ€æœ¯çš„å´‡æ‹œ
 * GeekDeveloper : JEEP-711
 *
 * @author system
 * <p>
 * HbaseHub
 * <p>
 */

public class HbaseHub {

    /**
     * Public Configuration information
     * å…¬å…±é…ç½®ä¿¡æ¯
     */
    private static Admin admin = null;
    private static Connection connection = null;
    private static Configuration configuration;

    static {

        /**
         * HBase ConfigurationFile
         * HBase é…ç½®æ–‡ä»¶
         */
        configuration = HBaseConfiguration.create();
        configuration.set("hbase.zookeeper.quorum", "172.16.168.130");
        configuration.set("hbase.zookeeper.property.clientPort", "2181");
        try {

            /**
             * Get Connected
             * è·å–è¿æ¥
             */
            connection = ConnectionFactory.createConnection(configuration);

            /**
             * Get HBase Administrator Object
             * è·å–HBaseç®¡ç†å‘˜å¯¹è±¡
             */
            admin = connection.getAdmin();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    /**
     * Close Resource
     * å…³é—­èµ„æº
     *
     * @param conf
     * @param admin
     */
    private static void close(Connection conf, Admin admin) {
        if (conf != null) {
            try {
                conf.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
        if (admin != null) {
            try {
                admin.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }

    /**
     * Determine if DataTable Exists
     * åˆ¤æ–­æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
     *
     * @param tableName
     */
    public static boolean isTableExist(String tableName) throws IOException {

        /**
         * Execution Method
         * æ‰§è¡Œæ–¹æ³•
         */
        boolean tableExists = admin.tableExists(TableName.valueOf(tableName));

        return tableExists;
    }

    /**
     * Full Table Scan - Query Data
     * å…¨è¡¨æ‰«æ - æŸ¥è¯¢æ•°æ®
     *
     * @param tableName
     */
    public static void scanTable(String tableName) throws IOException {

        /**
         * Instantiated Table Object
         * å®ä¾‹åŒ– è¡¨å¯¹è±¡
         */
        Table table = connection.getTable(TableName.valueOf(tableName));

        /**
         * Verify that the data table exists before modifying the data
         * æŸ¥è¯¢æ•°æ®å‰,éªŒè¯æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
         */
        if (!isTableExist(String.valueOf(TableName.valueOf(tableName)))) {
            System.out.println("Inquire Data Failed, Reason: " + table + "DataTable Does Not Exist !");
            return;
        }

        /**
         * Instantiation Scanner
         * å®ä¾‹åŒ– æ‰«æå™¨
         */
        Scan scan = new Scan();

        /**
         * Execution Method
         * æ‰§è¡Œæ–¹æ³•
         */
        ResultScanner results = table.getScanner(scan);

        /**
         * Traversing RowKey data
         * éå†RowKeyæ•°æ®
         */
        for (Result result : results) {
            Cell[] cells = result.rawCells();
            /**
             * Traversing the Row Key collection data
             * éå†RowKeyé›†åˆæ•°æ®
             */
            for (Cell cell : cells) {
                System.out.println("RowKey is = " + Bytes.toString(CellUtil.cloneRow(cell))
                        + " & " + "ColumnFamily is = " + Bytes.toString(CellUtil.cloneFamily(cell))
                        + " & " + "ColumnName is = " + Bytes.toString(CellUtil.cloneQualifier(cell))
                        + " & " + "Value is = " + Bytes.toString(CellUtil.cloneValue(cell))
                        + "\n" + ("===========================================================================")
                );
            }
        }

        /**
         * Logger INFO
         */
        System.out.println("FullTable Data Query Success !");

        /**
         * Close resource
         * å…³é—­èµ„æº
         */
        table.close();
    }

    public static void main(String[] args) throws IOException {

        /**
         * Full Table Scan - Query Data
         */
        scanTable("test");

        /**
         * Close Resource
         * å…³é—­èµ„æº
         */
        close(connection, admin);
    }
}
```
- å…¨è¡¨æ‰«æ æ‰§è¡Œè¿”å›ç»“æœ
```
RowKey is = 0001 & ColumnFamily is = info & ColumnName is = age & Value is = 60
===========================================================================
RowKey is = 0001 & ColumnFamily is = info & ColumnName is = name & Value is = testuser001
===========================================================================
RowKey is = 0002 & ColumnFamily is = info & ColumnName is = age & Value is = 70
===========================================================================
RowKey is = 0002 & ColumnFamily is = info & ColumnName is = name & Value is = testuser002
===========================================================================
FullTable Data Query Success !
```

#### 6.7.2 æŒ‡å®šå‚æ•°æŸ¥è¯¢æ•°æ®
``` java
package com.geekparkhub.core.hbase.api.producehub;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.*;
import org.apache.hadoop.hbase.client.*;
import org.apache.hadoop.hbase.util.Bytes;

import java.io.IOException;

/**
 * Geek International Park | æå®¢å›½é™…å…¬å›­
 * GeekParkHub | æå®¢å®éªŒå®¤
 * Website | https://www.geekparkhub.com/
 * Description | Openå¼€æ”¾ Â· Creationåˆ›æƒ³ | OpenSourceå¼€æ”¾æˆå°±æ¢¦æƒ³ GeekParkHubå…±å»ºå‰æ‰€æœªè§
 * HackerParkHub | é»‘å®¢å…¬å›­æ¢çº½
 * Website | https://www.hackerparkhub.com/
 * Description | ä»¥æ— æ‰€ç•æƒ§çš„æ¢ç´¢ç²¾ç¥ å¼€åˆ›æœªçŸ¥æŠ€æœ¯ä¸å¯¹æŠ€æœ¯çš„å´‡æ‹œ
 * GeekDeveloper : JEEP-711
 *
 * @author system
 * <p>
 * HbaseHub
 * <p>
 */

public class HbaseHub {

    /**
     * Public Configuration information
     * å…¬å…±é…ç½®ä¿¡æ¯
     */
    private static Admin admin = null;
    private static Connection connection = null;
    private static Configuration configuration;

    static {

        /**
         * HBase ConfigurationFile
         * HBase é…ç½®æ–‡ä»¶
         */
        configuration = HBaseConfiguration.create();
        configuration.set("hbase.zookeeper.quorum", "172.16.168.130");
        configuration.set("hbase.zookeeper.property.clientPort", "2181");
        try {

            /**
             * Get Connected
             * è·å–è¿æ¥
             */
            connection = ConnectionFactory.createConnection(configuration);

            /**
             * Get HBase Administrator Object
             * è·å–HBaseç®¡ç†å‘˜å¯¹è±¡
             */
            admin = connection.getAdmin();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    /**
     * Close Resource
     * å…³é—­èµ„æº
     *
     * @param conf
     * @param admin
     */
    private static void close(Connection conf, Admin admin) {
        if (conf != null) {
            try {
                conf.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
        if (admin != null) {
            try {
                admin.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }

    /**
     * Determine if DataTable Exists
     * åˆ¤æ–­æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
     *
     * @param tableName
     */
    public static boolean isTableExist(String tableName) throws IOException {

        /**
         * Execution Method
         * æ‰§è¡Œæ–¹æ³•
         */
        boolean tableExists = admin.tableExists(TableName.valueOf(tableName));

        return tableExists;
    }

    /**
     * Specified Parameter - Query Data
     * æŒ‡å®šå‚æ•° - æŸ¥è¯¢æ•°æ®
     *
     * @param tableName
     * @param rowKey
     * @param columnFamily
     * @param columnName
     * @throws IOException
     */
    public static void getData(String tableName, String rowKey, String columnFamily, String columnName) throws IOException {

        /**
         * Instantiated Table Object
         * å®ä¾‹åŒ– è¡¨å¯¹è±¡
         */
        Table table = connection.getTable(TableName.valueOf(tableName));

        /**
         * Verify that the data table exists before modifying the data
         * æŸ¥è¯¢æ•°æ®å‰,éªŒè¯æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
         */
        if (!isTableExist(String.valueOf(TableName.valueOf(tableName)))) {
            System.out.println("Inquire Data Failed, Reason: " + table + "DataTable Does Not Exist !");
            return;
        }

        /**
         * Instantiate the Get object
         * å®ä¾‹åŒ–Getå¯¹è±¡
         */
        Get get = new Get(Bytes.toBytes(rowKey));

        /**
         * Specify column family & column name
         * æŒ‡å®šåˆ—æ—&åˆ—å
         */
        get.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes(columnName));

        /**
         * Execution method
         * æ‰§è¡Œæ–¹æ³•
         */
        Result result = table.get(get);

        Cell[] cells = result.rawCells();

        /**
         * Traversing the Row Key collection data
         * éå†RowKeyé›†åˆæ•°æ®
         */
        for (Cell cell : cells) {
            System.out.println("RowKey is = " + Bytes.toString(CellUtil.cloneRow(cell))
                    + " & " + "ColumnFamily is = " + Bytes.toString(CellUtil.cloneFamily(cell))
                    + " & " + "ColumnName is = " + Bytes.toString(CellUtil.cloneQualifier(cell))
                    + " & " + "Value is = " + Bytes.toString(CellUtil.cloneValue(cell))
                    + "\n" + ("===========================================================================")
            );
        }

        /**
         * Logger INFO
         */
        System.out.println("Specified Parameter Data Query Success !");

        /**
         * Close resource
         * å…³é—­èµ„æº
         */
        table.close();
    }

    public static void main(String[] args) throws IOException {

        /**
         * Specified Parameter - Query Data
         */
        getData("test", "0001", "info", "name");

        /**
         * Close Resource
         * å…³é—­èµ„æº
         */
        close(connection, admin);
    }
}
```
- æŒ‡å®šå‚æ•°æŸ¥è¯¢æ•°æ® æ‰§è¡Œè¿”å›ç»“æœ
```
RowKey is = 0001 & ColumnFamily is = info & ColumnName is = name & Value is = testuser001
===========================================================================
Specified Parameter Data Query Success !
```

### 6.8 åˆ é™¤æ•°æ®
``` java
package com.geekparkhub.core.hbase.api.producehub;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.*;
import org.apache.hadoop.hbase.client.*;
import org.apache.hadoop.hbase.util.Bytes;

import java.io.IOException;

/**
 * Geek International Park | æå®¢å›½é™…å…¬å›­
 * GeekParkHub | æå®¢å®éªŒå®¤
 * Website | https://www.geekparkhub.com/
 * Description | Openå¼€æ”¾ Â· Creationåˆ›æƒ³ | OpenSourceå¼€æ”¾æˆå°±æ¢¦æƒ³ GeekParkHubå…±å»ºå‰æ‰€æœªè§
 * HackerParkHub | é»‘å®¢å…¬å›­æ¢çº½
 * Website | https://www.hackerparkhub.com/
 * Description | ä»¥æ— æ‰€ç•æƒ§çš„æ¢ç´¢ç²¾ç¥ å¼€åˆ›æœªçŸ¥æŠ€æœ¯ä¸å¯¹æŠ€æœ¯çš„å´‡æ‹œ
 * GeekDeveloper : JEEP-711
 *
 * @author system
 * <p>
 * HbaseHub
 * <p>
 */

public class HbaseHub {

    /**
     * Public Configuration information
     * å…¬å…±é…ç½®ä¿¡æ¯
     */
    private static Admin admin = null;
    private static Connection connection = null;
    private static Configuration configuration;

    static {

        /**
         * HBase ConfigurationFile
         * HBase é…ç½®æ–‡ä»¶
         */
        configuration = HBaseConfiguration.create();
        configuration.set("hbase.zookeeper.quorum", "172.16.168.130");
        configuration.set("hbase.zookeeper.property.clientPort", "2181");
        try {

            /**
             * Get Connected
             * è·å–è¿æ¥
             */
            connection = ConnectionFactory.createConnection(configuration);

            /**
             * Get HBase Administrator Object
             * è·å–HBaseç®¡ç†å‘˜å¯¹è±¡
             */
            admin = connection.getAdmin();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    /**
     * Close Resource
     * å…³é—­èµ„æº
     *
     * @param conf
     * @param admin
     */
    private static void close(Connection conf, Admin admin) {
        if (conf != null) {
            try {
                conf.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
        if (admin != null) {
            try {
                admin.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }

    /**
     * Determine if DataTable Exists
     * åˆ¤æ–­æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
     *
     * @param tableName
     */
    public static boolean isTableExist(String tableName) throws IOException {

        /**
         * Execution Method
         * æ‰§è¡Œæ–¹æ³•
         */
        boolean tableExists = admin.tableExists(TableName.valueOf(tableName));

        return tableExists;
    }

    /**
     * Delete Data
     * åˆ é™¤æ•°æ®
     *
     * @param tableName
     * @param rowKey
     * @param columnFamily
     * @param columnName
     * @throws IOException
     */
    public static void deleteData(String tableName, String rowKey, String columnFamily, String columnName) throws IOException {

        /**
         * Instantiated Table Object
         * å®ä¾‹åŒ– è¡¨å¯¹è±¡
         */
        Table table = connection.getTable(TableName.valueOf(tableName));

        /**
         * Verify that the data table exists before modifying the data
         * åˆ é™¤æ•°æ®å‰,éªŒè¯æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
         */
        if (!isTableExist(String.valueOf(TableName.valueOf(tableName)))) {
            System.out.println("Delete Data Failed, Reason: " + table + "DataTable Does Not Exist !");
            return;
        }

        /**
         * Instantiate the delete object
         * å®ä¾‹åŒ– deleteå¯¹è±¡
         */
        Delete delete = new Delete(Bytes.toBytes(rowKey));

        /**
         * åˆ é™¤æŒ‡å®šæ•°æ®
         */
        delete.addColumns(Bytes.toBytes(columnFamily), Bytes.toBytes(columnName));

        /**
         * Execution method
         * æ‰§è¡Œæ–¹æ³•
         */
        table.delete(delete);

        /**
         * Logger INFO
         */
        System.out.println("Data Deletion is Successful!");

        /**
         * Close resource
         * å…³é—­èµ„æº
         */
        table.close();
    }

    public static void main(String[] args) throws IOException {

        /**
         * Delete Data
         */
        deleteData("test001", "0003", "name", "testUser004");

        /**
         * Close Resource
         * å…³é—­èµ„æº
         */
        close(connection, admin);
    }
}
```
- æ‰§è¡Œè¿”å›ç»“æœ
```
Data Deletion is Successful!
```

### 6.9 MapReduce
- ä½¿ç”¨MapReduceå°†æ•°æ®ä»æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿå¯¼å…¥åˆ°HBaseçš„è¡¨ä¸­,ä»HBaseä¸­è¯»å–åŸå§‹æ•°æ®åä½¿ç”¨MapReduceæ•°æ®åˆ†æ.

#### 6.9.1 å®˜æ–¹HBase-MapReduce
- æŸ¥çœ‹HBaseçš„MapReduceä»»åŠ¡æ‰§è¡Œ
```
[root@systemhub511 hbase]# bin/hbase mapredcp
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/module/hbase/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/module/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
/opt/module/hbase/lib/netty-all-4.0.23.Final.jar:/opt/module/hbase/lib/hbase-client-1.3.1.jar:/opt/module/hbase/lib/metrics-core-2.2.0.jar:/opt/module/hbase/lib/zookeeper-3.4.10.jar:/opt/module/hbase/lib/hbase-prefix-tree-1.3.1.jar:/opt/module/hbase/lib/hbase-common-1.3.1.jar:/opt/module/hbase/lib/protobuf-java-2.5.0.jar:/opt/module/hbase/lib/guava-12.0.1.jar:/opt/module/hbase/lib/htrace-core-3.1.0-incubating.jar:/opt/module/hbase/lib/hbase-protocol-1.3.1.jar:/opt/module/hbase/lib/hbase-hadoop-compat-1.3.1.jar:/opt/module/hbase/lib/hbase-server-1.3.1.jar
[root@systemhub511 hbase]#
```
#### 6.9.2 æ‰§è¡Œç¯å¢ƒå˜é‡å¯¼å…¥
- å…³é—­æ‰€æœ‰Hadoopç›¸å…³æœåŠ¡
- vim `/etc/profile`
```
## SET HBASE_HOME
export HBASE_HOME=/opt/module/hbase
```
```
[root@systemhub511 hadoop]# source /etc/profile
```
- vim `hadoop-env.sh` / æ³¨æ„ : åœ¨forè¯­å¥åè¿½åŠ æ­¤é…ç½®å‚æ•°.
```
export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/opt/module/hbase/lib/*
```
- é…ç½®æ–‡ä»¶åˆ†å‘é›†ç¾¤
- é€ä¸€å¼€å¯ç›¸å…³æœåŠ¡

#### 6.9.3 è¿è¡Œå®˜æ–¹MapReduceä»»åŠ¡
- `Demo1` : ç»Ÿè®¡testè¡¨ä¸­æœ‰å¤šå°‘è¡Œæ•°æ®
```
[root@systemhub511 hbase]# /opt/module/hadoop/bin/yarn jar lib/hbase-server-1.3.1.jar rowcounter test
HBase Counters
                BYTES_IN_REMOTE_RESULTS=0
                BYTES_IN_RESULTS=74
                MILLIS_BETWEEN_NEXTS=549
                NOT_SERVING_REGION_EXCEPTION=0
                NUM_SCANNER_RESTARTS=0
                NUM_SCAN_RESULTS_STALE=0
                REGIONS_SCANNED=1
                REMOTE_RPC_CALLS=0
                REMOTE_RPC_RETRIES=0
                ROWS_FILTERED=0
                ROWS_SCANNED=2
                RPC_CALLS=3
                RPC_RETRIES=0
        org.apache.hadoop.hbase.mapreduce.RowCounter$RowCounterMapper$Counters
                ROWS=2
        File Input Format Counters 
                Bytes Read=0
        File Output Format Counters 
                Bytes Written=0
```

- `Demo2` : ä½¿ç”¨MapReduceå°†æœ¬åœ°æ•°æ®å¯¼å…¥åˆ°HBase
- åˆ›å»ºåç¼€ä¸º.tsvæ ¼å¼æ–‡ä»¶
```
[root@systemhub511 hbase]# touch test002.tsv
[root@systemhub511 hbase]# vim test002.tsv
```
```
1001    Test001 Red
1002    Test002 Yellow
1003    Test003 Yellow
```
- å°†æ–‡ä»¶ä¸Šä¼ åˆ°HDFS
```
[root@systemhub511 hbase]# hadoop fs -put test002.tsv /core_flow/test/
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/module/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/module/hbase/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
[root@systemhub511 hbase]# 
```
- åˆ›å»ºHBaseè¡¨
```
hbase(main):001:0> create 'test002','info'
0 row(s) in 3.1610 seconds

=> Hbase::Table - test002
hbase(main):002:0> 
```
- æ‰§è¡ŒMapReduce
```
[root@systemhub511 hbase]# /opt/module/hadoop/bin/yarn jar ./lib/hbase-server-1.3.1.jar importtsv -Dimporttsv.columns=HBASE_ROW_KEY,info:name,info:color test002 hdfs://systemhub511:9000/core_flow/test/test002.tsv
Map-Reduce Framework
                Map input records=3
                Map output records=3
                Input split bytes=116
                Spilled Records=0
                Failed Shuffles=0
                Merged Map outputs=0
                GC time elapsed (ms)=131
                CPU time spent (ms)=1690
                Physical memory (bytes) snapshot=108429312
                Virtual memory (bytes) snapshot=2071105536
                Total committed heap usage (bytes)=16318464

```
- ä½¿ç”¨scanæŒ‡ä»¤æŸ¥çœ‹å¯¼å…¥åç»“æœ
```
hbase(main):001:0> scan 'test002'
ROW                        COLUMN+CELL                                                                 
 1001                      column=info:color, timestamp=1556886127536, value=Red                       
 1001                      column=info:name, timestamp=1556886127536, value=Test001                    
 1002                      column=info:color, timestamp=1556886127536, value=Yellow                    
 1002                      column=info:name, timestamp=1556886127536, value=Test002                    
 1003                      column=info:color, timestamp=1556886127536, value=Yellow                    
 1003                      column=info:name, timestamp=1556886127536, value=Test003                    
3 row(s) in 0.5090 seconds
hbase(main):002:0> 
```

#### 6.9.4 è‡ªå®šä¹‰ HBase-MapReduce (1)
- å°†test002è¡¨ä¸­ä¸€éƒ¨åˆ†æ•°æ®,é€šè¿‡MapReduceè¿å…¥åˆ°test002_mrè¡¨ä¸­.
- Create `TestMapper.class` / ç”¨äºè¯»å–test002è¡¨ä¸­æ•°æ®.
``` java
package com.geekparkhub.core.hbase.api.mapreduce;

import org.apache.hadoop.hbase.Cell;
import org.apache.hadoop.hbase.CellUtil;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.client.Result;
import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
import org.apache.hadoop.hbase.mapreduce.TableMapper;
import org.apache.hadoop.hbase.util.Bytes;

import java.io.IOException;

/**
 * Geek International Park | æå®¢å›½é™…å…¬å›­
 * GeekParkHub | æå®¢å®éªŒå®¤
 * Website | https://www.geekparkhub.com/
 * Description | Openå¼€æ”¾ Â· Creationåˆ›æƒ³ | OpenSourceå¼€æ”¾æˆå°±æ¢¦æƒ³ GeekParkHubå…±å»ºå‰æ‰€æœªè§
 * HackerParkHub | é»‘å®¢å…¬å›­æ¢çº½
 * Website | https://www.hackerparkhub.com/
 * Description | ä»¥æ— æ‰€ç•æƒ§çš„æ¢ç´¢ç²¾ç¥ å¼€åˆ›æœªçŸ¥æŠ€æœ¯ä¸å¯¹æŠ€æœ¯çš„å´‡æ‹œ
 * GeekDeveloper : JEEP-711
 *
 * @author system
 * <p>
 * TestMapper
 * <p>
 */

public class TestMapper extends TableMapper<ImmutableBytesWritable, Put> {

    @Override
    protected void map(ImmutableBytesWritable key, Result value, Context context) throws IOException, InterruptedException {

        /**
         * Instantiate Put object
         * å®ä¾‹åŒ– Putå¯¹è±¡
         */
        Put put = new Put(key.get());

        /**
         * Traversing rowkey data
         * éå†rowkeyæ•°æ®
         */
        Cell[] cells = value.rawCells();
        for (Cell cell : cells) {
            if ("name".equals(Bytes.toString(CellUtil.cloneQualifier(cell)))) {
                put.add(cell);
            }
        }
        context.write(key, put);
    }
}
```
- Create `TestReducer.class` / ç”¨äºå°†è¯»å–test002è¡¨æ•°æ®å†™å…¥åˆ°test002_mrè¡¨ä¸­.
``` java
package com.geekparkhub.core.hbase.api.mapreduce;

import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
import org.apache.hadoop.hbase.mapreduce.TableReducer;
import org.apache.hadoop.io.NullWritable;

import java.io.IOException;

/**
 * Geek International Park | æå®¢å›½é™…å…¬å›­
 * GeekParkHub | æå®¢å®éªŒå®¤
 * Website | https://www.geekparkhub.com/
 * Description | Openå¼€æ”¾ Â· Creationåˆ›æƒ³ | OpenSourceå¼€æ”¾æˆå°±æ¢¦æƒ³ GeekParkHubå…±å»ºå‰æ‰€æœªè§
 * HackerParkHub | é»‘å®¢å…¬å›­æ¢çº½
 * Website | https://www.hackerparkhub.com/
 * Description | ä»¥æ— æ‰€ç•æƒ§çš„æ¢ç´¢ç²¾ç¥ å¼€åˆ›æœªçŸ¥æŠ€æœ¯ä¸å¯¹æŠ€æœ¯çš„å´‡æ‹œ
 * GeekDeveloper : JEEP-711
 *
 * @author system
 * <p>
 * TestReducer
 * <p>
 */

public class TestReducer extends TableReducer<ImmutableBytesWritable, Put, NullWritable> {

    @Override
    protected void reduce(ImmutableBytesWritable key, Iterable<Put> values, Context context) throws IOException, InterruptedException {
        for (Put value : values) {
            context.write(NullWritable.get(), value);
        }
    }
}
```
- Create `TestDriver.class` / ç”¨äºç»„è£…è¿è¡ŒJobä»»åŠ¡
``` java
package com.geekparkhub.core.hbase.api.mapreduce;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.client.Scan;
import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
import org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;

/**
 * Geek International Park | æå®¢å›½é™…å…¬å›­
 * GeekParkHub | æå®¢å®éªŒå®¤
 * Website | https://www.geekparkhub.com/
 * Description | Openå¼€æ”¾ Â· Creationåˆ›æƒ³ | OpenSourceå¼€æ”¾æˆå°±æ¢¦æƒ³ GeekParkHubå…±å»ºå‰æ‰€æœªè§
 * HackerParkHub | é»‘å®¢å…¬å›­æ¢çº½
 * Website | https://www.hackerparkhub.com/
 * Description | ä»¥æ— æ‰€ç•æƒ§çš„æ¢ç´¢ç²¾ç¥ å¼€åˆ›æœªçŸ¥æŠ€æœ¯ä¸å¯¹æŠ€æœ¯çš„å´‡æ‹œ
 * GeekDeveloper : JEEP-711
 *
 * @author system
 * <p>
 * TestDriver
 * <p>
 */

public class TestDriver extends Configuration implements Tool {

    Configuration configuration = null;

    public int run(String[] args) throws Exception {

        /**
         * å®ä¾‹åŒ– Jobå¯¹è±¡
         */
        Job job = Job.getInstance(configuration);
        job.setJarByClass(TestDriver.class);

        TableMapReduceUtil.initTableMapperJob("test002", new Scan(), TestMapper.class, ImmutableBytesWritable.class, Put.class, job);

        TableMapReduceUtil.initTableReducerJob("test002_mr", TestReducer.class, job);

        boolean completion = job.waitForCompletion(true);

        return completion ? 0 : 1;
    }

    public void setConf(Configuration conf) {
        this.configuration = conf;
    }

    public Configuration getConf() {
        return configuration;
    }

    public static void main(String[] args) throws Exception {
        Configuration configuration = HBaseConfiguration.create();
        int run = ToolRunner.run(configuration, new TestDriver(), args);
    }
}
```
- è¿è¡Œä»»åŠ¡å‰,å¦‚æœå¾…æ•°æ®å¯¼å…¥è¡¨ä¸å­˜åœ¨,åˆ™éœ€è¦æå‰åˆ›å»º
```
[root@systemhub511 hbase]# bin/hbase shell
hbase(main):001:0> create 'test002_mr','info'
0 row(s) in 2.8570 seconds
=> Hbase::Table - test002_mr
hbase(main):002:0> 
```
- æ‰“åŒ…è¿è¡Œä»»åŠ¡
```
[root@systemhub511 hbase]# /opt/module/hadoop/bin/yarn jar ./hbase_server-1.0.jar com.geekparkhub.core.hbase.api.mapreduce.TestDriver
 INFO mapreduce.Job: Counters: 62
        File System Counters
                FILE: Number of bytes read=195
                FILE: Number of bytes written=298305
                FILE: Number of read operations=0
                FILE: Number of large read operations=0
                FILE: Number of write operations=0
                HDFS: Number of bytes read=109
                HDFS: Number of bytes written=0
                HDFS: Number of read operations=1
                HDFS: Number of large read operations=0
                HDFS: Number of write operations=0
        Job Counters 
                Launched map tasks=1
                Launched reduce tasks=1
                Rack-local map tasks=1
                Total time spent by all maps in occupied slots (ms)=21676
                Total time spent by all reduces in occupied slots (ms)=10110
                Total time spent by all map tasks (ms)=21676
                Total time spent by all reduce tasks (ms)=10110
                Total vcore-milliseconds taken by all map tasks=21676
                Total vcore-milliseconds taken by all reduce tasks=10110
                Total megabyte-milliseconds taken by all map tasks=22196224
                Total megabyte-milliseconds taken by all reduce tasks=10352640
        Map-Reduce Framework
                Map input records=3
                Map output records=3
                Map output bytes=183
                Map output materialized bytes=195
                Input split bytes=109
                Combine input records=3
                Combine output records=3
                Reduce input groups=3
                Reduce shuffle bytes=195
                Reduce input records=3
                Reduce output records=3
                Spilled Records=6
                Shuffled Maps =1
                Failed Shuffles=0
                Merged Map outputs=1
                GC time elapsed (ms)=612
                CPU time spent (ms)=6990
                Physical memory (bytes) snapshot=333955072
                Virtual memory (bytes) snapshot=4147179520
                Total committed heap usage (bytes)=144588800
        HBase Counters
                BYTES_IN_REMOTE_RESULTS=0
                BYTES_IN_RESULTS=255
                MILLIS_BETWEEN_NEXTS=1667
                NOT_SERVING_REGION_EXCEPTION=0
                NUM_SCANNER_RESTARTS=0
                NUM_SCAN_RESULTS_STALE=0
                REGIONS_SCANNED=1
                REMOTE_RPC_CALLS=0
                REMOTE_RPC_RETRIES=0
                ROWS_FILTERED=0
                ROWS_SCANNED=3
                RPC_CALLS=3
                RPC_RETRIES=0
        Shuffle Errors
                BAD_ID=0
                CONNECTION=0
                IO_ERROR=0
                WRONG_LENGTH=0
                WRONG_MAP=0
                WRONG_REDUCE=0
        File Input Format Counters 
                Bytes Read=0
        File Output Format Counters 
                Bytes Written=0
[root@systemhub511 hbase]# 
```
- æŸ¥çœ‹æ‰§è¡Œç»“æœ
```
hbase(main):002:0> scan 'test002_mr'
ROW                        COLUMN+CELL                                                                 
 1001                      column=info:name, timestamp=1556886127536, value=Test001                    
 1002                      column=info:name, timestamp=1556886127536, value=Test002                    
 1003                      column=info:name, timestamp=1556886127536, value=Test003                    
3 row(s) in 0.0290 seconds
hbase(main):004:0> 
```

#### 6.9.5 è‡ªå®šä¹‰ HBase-MapReduce (2)
- å®ç°å°†HDFSä¸­æ•°æ®å†™å…¥åˆ°HBaseè¡¨ä¸­.

### 6.10 HBaseé›†æˆHive


## 7. HBase ä¼˜åŒ–


## 8. ä¿®ä»™ä¹‹é“ æŠ€æœ¯æ¶æ„è¿­ä»£ ç™»å³°é€ æä¹‹åŠ¿
![Alt text](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/main/technical_framework.jpg)


-----

## ğŸ’¡å¦‚ä½•å¯¹è¯¥å¼€æºæ–‡æ¡£è¿›è¡Œè´¡çŒ®ğŸ’¡

1. Blogå†…å®¹å¤§å¤šæ˜¯æ‰‹æ•²,æ‰€ä»¥éš¾å…ä¼šæœ‰ç¬”è¯¯,ä½ å¯ä»¥å¸®æˆ‘æ‰¾é”™åˆ«å­—ã€‚
2. å¾ˆå¤šçŸ¥è¯†ç‚¹æˆ‘å¯èƒ½æ²¡æœ‰æ¶‰åŠåˆ°,æ‰€ä»¥ä½ å¯ä»¥å¯¹å…¶ä»–çŸ¥è¯†ç‚¹è¿›è¡Œè¡¥å……ã€‚
3. ç°æœ‰çš„çŸ¥è¯†ç‚¹éš¾å…å­˜åœ¨ä¸å®Œå–„æˆ–è€…é”™è¯¯,æ‰€ä»¥ä½ å¯ä»¥å¯¹å·²æœ‰çŸ¥è¯†ç‚¹çš„ä¿®æ”¹/è¡¥å……ã€‚
4. ğŸ’¡æ¬¢è¿è´¡çŒ®`å„é¢†åŸŸå¼€æºé‡ç”ŸBlog`&`ç¬”è®°`&`æ–‡ç« `&`ç‰‡æ®µ`&`åˆ†äº«`&`åˆ›æƒ³`&`OpenSource Project`&`Code`&`Code Review`
5. ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ issues: [geekparkhub.github.io/issues](https://github.com/geekparkhub/geekparkhub.github.io/issues) ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ

### å¸Œæœ›æ¯ä¸€ç¯‡æ–‡ç« éƒ½èƒ½å¤Ÿå¯¹è¯»è€…ä»¬æä¾›å¸®åŠ©ä¸æå‡,è¿™ä¹ƒæ˜¯æ¯ä¸€ä½ç¬”è€…çš„åˆè¡·                          


-----


## ğŸ’Œæ„Ÿè°¢æ‚¨çš„é˜…è¯» æ¬¢è¿æ‚¨çš„ç•™è¨€ä¸å»ºè®®ğŸ’Œ

- FaceBookï¼š[JEEP SevenEleven](https://www.facebook.com/profile.php?id=100018099483403)
- Twitterï¼š[@JEEP7ll](https://twitter.com/JEEP7ll)
- Sina Weibo: [@JEEP-711](https://weibo.com/JEEP511)
- GeekParkHub GithubHomeï¼š<https://github.com/geekparkhub>
- GeekParkHub GiteeHomeï¼š<https://gitee.com/geekparkhub>
- Blog GardenHomeï¼š<http://www.cnblogs.com/JEEP711/>
- W3C/BlogHomeï¼š<https://www.w3cschool.cn/jeep711blog/>
- CSDN/BlogHomeï¼š<http://blog.csdn.net/jeep911>
- 51CTO/BlogHomeï¼š<http://jeep711.blog.51cto.com/>
- **`Official Public Email`**
- Group Emailï¼š<geekparkhub@outlook.com> â€”â€” <hackerparkhub@outlook.com> â€”â€” <hackerpark@hotmail.com>
- User Emailï¼š<jeep711.home.@gmail.com> â€”â€” <jeep-711@outlook.com>
- System Emailï¼š<systemhub-711@outlook.com>
- Service Emailï¼š<servicehub-711@outlook.com>



### æåŠ© é¡¹ç›®çš„å‘å±•ç¦»ä¸å¼€ä½ çš„æ”¯æŒ,è¯·å¼€å‘è€…å–æ¯â˜•Coffeeâ˜•å§!
![enter image description here](https://www.geekparkhub.com/docs/images/pay.jpg)

#### `è‡´è°¢`ï¼š
**æåŠ©æ—¶è¯·å¤‡æ³¨ UserName**
| ID| UserName | Donation | Money | Consume |
|:-| :-------- | --------:| :--: |:--: |
|1 | Object | WeChatPay |  5RMB | ä¸€æ¯å¯ä¹ | 
|2| æ³°è¿ªç†Šçœ‹æœˆäº®  | AliPay |  20RMB  | ä¸€æ¯å’–å•¡ | 
|3| ä¿®ä»™é“é•¿  | WeChatPay |  10RMB | ä¸¤æ¯å¯ä¹ | 


## License å¼€æºåè®®
[Apache License Version 2.0](https://github.com/geekparkhub/geekparkhub.github.io/blob/master/LICENSE)

---------