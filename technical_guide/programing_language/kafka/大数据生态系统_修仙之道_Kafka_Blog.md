# å¤§æ•°æ®ç”Ÿæ€ç³»ç»Ÿ ä¿®ä»™ä¹‹é“ Kafka Blog

@(2019-04-01)[ Docs Language:ç®€ä½“ä¸­æ–‡ & English|Programing Language:Kafka|Website:[www.geekparkhub.com](https://www.geekparkhub.com/)|![OpenSource](https://img.shields.io/badge/Open%20Source-%E2%9D%A4-brightgreen.svg) | ![GitHub repo size in bytes](https://img.shields.io/github/repo-size/geekparkhub/geekparkhub.github.io.svg) | GeekDeveloper:[JEEP-711](https://github.com/jeep711)|Github:[github.com/geekparkhub](https://github.com/geekparkhub)|Gitee:[gitee.com/geekparkhub](https://gitee.com/geekparkhub) ]

##  ğŸ˜ Kafka Technology ä¿®ä»™ä¹‹é“ ç‚¼è™šåˆé“ ğŸ˜

![Alt text](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/kafka/kafka.jpg)

- **æå®¢å®éªŒå®¤æ˜¯æå®¢å›½é™…å…¬å›­æ——ä¸‹ä¸ºæœªæ¥è€Œæ„å»ºçš„æå®¢ç¤¾åŒº;**
- **æˆ‘ä»¬æ­£åœ¨æ„å»ºä¸€ä¸ªæ´»è·ƒçš„å°ä¼—ç¤¾åŒº,æ±‡èšä¼—å¤šä¼˜ç§€å¼€å‘è€…ä¸è®¾è®¡å¸ˆ;**
- **å…³æ³¨æå…·åˆ›æ–°ç²¾ç¥çš„å‰æ²¿æŠ€æœ¯&åˆ†äº«äº¤æµ&é¡¹ç›®åˆä½œæœºä¼šç­‰äº’è”ç½‘è¡Œä¸šæœåŠ¡;**
- **Openå¼€æ”¾ `Â·` Creationåˆ›æƒ³ `|` OpenSourceå¼€æ”¾æˆå°±æ¢¦æƒ³ GeekParkHubå…±å»ºå‰æ‰€æœªè§!**
- **Future Vision : Establishment of the Geek Foundation;**
- **GeekParkHub GithubHome:**<https://github.com/geekparkhub>
- **GeekParkHub GiteeHome:**<https://gitee.com/geekparkhub>
- **æ¬¢è¿è´¡çŒ®`å„é¢†åŸŸå¼€æºé‡ç”ŸBlog`&`ç¬”è®°`&`æ–‡ç« `&`ç‰‡æ®µ`&`åˆ†äº«`&`åˆ›æƒ³`&`OpenSource Project`&`Code`&`Code Review`**
- ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ issues: [geekparkhub.github.io/issues](https://github.com/geekparkhub/geekparkhub.github.io/issues) ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ
- **`Official Public Email`**
- Group Emailï¼š<geekparkhub@outlook.com> â€”â€” <hackerparkhub@outlook.com> â€”â€” <hackerpark@hotmail.com>
- User Emailï¼š<jeep711.home.@gmail.com> â€”â€” <jeep-711@outlook.com>
- System Emailï¼š<systemhub-711@outlook.com>
- Service Emailï¼š<servicehub-711@outlook.com>


-------------------



[TOC]



## 1. Kafka æ¦‚è¿°
### 1.1 æ¶ˆæ¯é˜Ÿåˆ—

![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/kafka/start_002.jpg)
> `ç‚¹å¯¹ç‚¹æ¨¡å¼` (ä¸€å¯¹ä¸€,æ¶ˆè´¹è€…ä¸»åŠ¨æ‹‰å–æ•°æ®,æ¶ˆæ¯æ”¶åˆ°åæ¶ˆæ¯æ¸…é™¤)ç‚¹å¯¹ç‚¹æ¨¡å‹é€šå¸¸æ˜¯ä¸€ä¸ªåŸºäºæ‹‰å–æˆ–è€…è½®è¯¢çš„æ¶ˆæ¯ä¼ é€æ¨¡å‹,è¿™ç§æ¨¡å‹ä»é˜Ÿåˆ—ä¸­è¯·æ±‚ä¿¡æ¯,è€Œä¸æ˜¯å°†æ¶ˆæ¯æ¨é€åˆ°å®¢æˆ·ç«¯.è¿™ä¸ªæ¨¡å‹çš„ç‰¹ç‚¹æ˜¯å‘é€åˆ°é˜Ÿåˆ—çš„æ¶ˆæ¯è¢«ä¸€ä¸ªä¸”åªæœ‰ä¸€ä¸ªæ¥æ”¶è€…æ¥æ”¶å¤„ç†,å³ä½¿æœ‰å¤šä¸ªæ¶ˆæ¯ç›‘å¬è€…ä¹Ÿæ˜¯å¦‚æ­¤.
> 
> `å‘å¸ƒ/è®¢é˜…æ¨¡å¼` (ä¸€å¯¹å¤š,æ•°æ®ç”Ÿäº§å,æ¨é€ç»™æ‰€æœ‰è®¢é˜…è€…)
> å‘å¸ƒè®¢é˜…æ¨¡å‹åˆ™æ˜¯ä¸€ä¸ªåŸºäºæ¨é€çš„æ¶ˆæ¯ä¼ é€æ¨¡å‹,å‘å¸ƒè®¢é˜…æ¨¡å‹å¯ä»¥æœ‰å¤šç§ä¸åŒçš„è®¢é˜…è€…,ä¸´æ—¶è®¢é˜…è€…åªåœ¨ä¸»åŠ¨ç›‘å¬ä¸»é¢˜æ—¶æ‰æ¥æ”¶æ¶ˆæ¯,è€ŒæŒä¹…è®¢é˜…è€…åˆ™ç›‘å¬ä¸»é¢˜çš„æ‰€æœ‰æ¶ˆæ¯,å³ä½¿å½“å‰è®¢é˜…è€…ä¸å¯ç”¨,å¤„äºç¦»çº¿çŠ¶æ€.
### 1.2 ä¸ºä»€ä¹ˆéœ€è¦æ¶ˆæ¯é˜Ÿåˆ—
> `è§£è€¦` : å…è®¸ä½ ç‹¬ç«‹çš„æ‰©å±•æˆ–ä¿®æ”¹ä¸¤è¾¹çš„å¤„ç†è¿‡ç¨‹,åªè¦ç¡®ä¿å®ƒä»¬éµå®ˆåŒæ ·çš„æ¥å£çº¦æŸ.
> 
> `å†—ä½™` : æ¶ˆæ¯é˜Ÿåˆ—æŠŠæ•°æ®è¿›è¡ŒæŒä¹…åŒ–ç›´åˆ°å®ƒä»¬å·²ç»è¢«å®Œå…¨å¤„ç†,é€šè¿‡è¿™ä¸€æ–¹å¼è§„é¿äº†æ•°æ®ä¸¢å¤±é£é™©,è®¸å¤šæ¶ˆæ¯é˜Ÿåˆ—æ‰€é‡‡ç”¨çš„"æ’å…¥-è·å–-åˆ é™¤"èŒƒå¼ä¸­,åœ¨æŠŠä¸€ä¸ªæ¶ˆæ¯ä»é˜Ÿåˆ—ä¸­åˆ é™¤ä¹‹å‰,éœ€è¦ä½ çš„å¤„ç†ç³»ç»Ÿæ˜ç¡®çš„æŒ‡å‡ºè¯¥æ¶ˆæ¯å·²ç»è¢«å¤„ç†å®Œæ¯•,ä»è€Œç¡®ä¿ä½ çš„æ•°æ®è¢«å®‰å…¨çš„ä¿å­˜ç›´åˆ°ä½ ä½¿ç”¨å®Œæ¯•.
> 
> `æ‰©å±•æ€§` : å› ä¸ºæ¶ˆæ¯é˜Ÿåˆ—è§£è€¦äº†ä½ çš„å¤„ç†è¿‡ç¨‹,æ‰€ä»¥å¢å¤§æ¶ˆæ¯å…¥é˜Ÿå’Œå¤„ç†çš„é¢‘ç‡æ˜¯å¾ˆå®¹æ˜“çš„,åªè¦å¦å¤–å¢åŠ å¤„ç†è¿‡ç¨‹å³å¯.
> 
> `çµæ´»æ€§&å³°å€¼å¤„ç†èƒ½åŠ›` : åœ¨è®¿é—®é‡å‰§å¢çš„æƒ…å†µä¸‹,åº”ç”¨ä»ç„¶éœ€è¦ç»§ç»­å‘æŒ¥ä½œç”¨,ä½†æ˜¯è¿™æ ·çš„çªå‘æµé‡å¹¶ä¸å¸¸è§,å¦‚æœä¸ºä»¥èƒ½å¤„ç†è¿™ç±»å³°å€¼è®¿é—®ä¸ºæ ‡å‡†æ¥æŠ•å…¥èµ„æºéšæ—¶å¾…å‘½æ— ç–‘æ˜¯å·¨å¤§çš„æµªè´¹,ä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—èƒ½å¤Ÿä½¿å…³é”®ç»„ä»¶é¡¶ä½çªå‘çš„è®¿é—®å‹åŠ›,è€Œä¸ä¼šå› ä¸ºçªå‘çš„è¶…è´Ÿè·çš„è¯·æ±‚è€Œå®Œå…¨å´©æºƒ.
> 
> `å¯æ¢å¤æ€§` : ç³»ç»Ÿçš„ä¸€éƒ¨åˆ†ç»„ä»¶å¤±æ•ˆæ—¶,ä¸ä¼šå½±å“åˆ°æ•´ä¸ªç³»ç»Ÿ,æ¶ˆæ¯é˜Ÿåˆ—é™ä½äº†è¿›ç¨‹é—´çš„è€¦åˆåº¦,æ‰€ä»¥å³ä½¿ä¸€ä¸ªå¤„ç†æ¶ˆæ¯çš„è¿›ç¨‹æŒ‚æ‰,åŠ å…¥é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯ä»ç„¶å¯ä»¥åœ¨ç³»ç»Ÿæ¢å¤åè¢«å¤„ç†.
> 
> `é¡ºåºä¿è¯` : åœ¨å¤§å¤šä½¿ç”¨åœºæ™¯ä¸‹,æ•°æ®å¤„ç†çš„é¡ºåºéƒ½å¾ˆé‡è¦,å¤§éƒ¨åˆ†æ¶ˆæ¯é˜Ÿåˆ—æœ¬æ¥å°±æ˜¯æ’åºçš„,å¹¶ä¸”èƒ½ä¿è¯æ•°æ®ä¼šæŒ‰ç…§ç‰¹å®šçš„é¡ºåºæ¥å¤„ç†,(Kafkaä¿è¯ä¸€ä¸ªPartitionå†…çš„æ¶ˆæ¯çš„æœ‰åºæ€§).
> 
> `ç¼“å†²` : æœ‰åŠ©äºæ§åˆ¶å’Œä¼˜åŒ–æ•°æ®æµç»è¿‡ç³»ç»Ÿçš„é€Ÿåº¦,è§£å†³ç”Ÿäº§æ¶ˆæ¯å’Œæ¶ˆè´¹æ¶ˆæ¯çš„å¤„ç†é€Ÿåº¦ä¸ä¸€è‡´çš„æƒ…å†µ.
> 
> `å¼‚æ­¥é€šä¿¡` : å¾ˆå¤šæ—¶å€™ç”¨æˆ·ä¸æƒ³ä¹Ÿä¸éœ€è¦ç«‹å³å¤„ç†æ¶ˆæ¯,æ¶ˆæ¯é˜Ÿåˆ—æä¾›äº†å¼‚æ­¥å¤„ç†æœºåˆ¶,å…è®¸ç”¨æˆ·æŠŠä¸€ä¸ªæ¶ˆæ¯æ”¾å…¥é˜Ÿåˆ—,ä½†å¹¶ä¸ç«‹å³å¤„ç†å®ƒ,æƒ³å‘é˜Ÿåˆ—ä¸­æ”¾å…¥å¤šå°‘æ¶ˆæ¯å°±æ”¾å¤šå°‘,ç„¶ååœ¨éœ€è¦çš„æ—¶å€™å†å»å¤„ç†å®ƒä»¬.

### 1.3 Kafka ç®€ä»‹
> åœ¨æµå¼è®¡ç®—ä¸­,Kafkaä¸€èˆ¬ç”¨æ¥ç¼“å­˜æ•°æ®,Stormé€šè¿‡æ¶ˆè´¹Kafkaæ•°æ®è¿›è¡Œè®¡ç®—.
> 
> Apache Kafkaæ˜¯ä¸€ä¸ªå¼€æºæ¶ˆæ¯ç³»ç»Ÿ,æ˜¯ç”±Scalaç¼–ç¨‹è¯­è¨€ç¼–å†™,Apacheè½¯ä»¶åŸºé‡‘ä¼šå¼€å‘ä¸€ä¸ªå¼€æºæ¶ˆæ¯ç³»ç»Ÿé¡¹ç›®.
> 
> Kafkaæœ€åˆæ˜¯ç”±LinkedInå…¬å¸å¼€å‘,å¹¶äº2011å¹´åˆå¼€æº,2012å¹´10æœˆä»Apache Incubatoræ¯•ä¸š,è¯¥é¡¹ç›®çš„ç›®æ ‡æ˜¯ä¸ºå¤„ç†å®æ—¶æ•°æ®æä¾›ä¸€ä¸ªç»Ÿä¸€ / é«˜é€šé‡ / ä½ç­‰å¾…å¹³å°.
> 
> Kafkaæ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼æ¶ˆæ¯é˜Ÿåˆ—,Kafkaå¯¹æ¶ˆæ¯ä¿å­˜æ—¶æ ¹æ®Topicè¿›è¡Œå½’ç±»,å‘é€æ¶ˆæ¯è€…ç§°ä¸ºProducer,æ¶ˆæ¯æ¥å—è€…ç§°ä¸ºConsumer,æ­¤å¤–Kafkaé›†ç¾¤æœ‰å¤šä¸ªKafkaå®ä¾‹ç»„æˆ,æ¯ä¸ªå®ä¾‹(Server)æˆä¸ºBroker.
> 
> æ— è®ºæ˜¯Kafkaé›†ç¾¤,è¿˜æ˜¯Producerå’Œconsumeréƒ½ä¾èµ–äºZookeeperé›†ç¾¤ä¿å­˜ä¸€äº›Metaä¿¡æ¯æ¥ä¿è¯ç³»ç»Ÿå¯ç”¨æ€§.

### 1.4 Kafka æ¶æ„

![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/kafka/start_003.jpg)

> `Producer` : æ¶ˆæ¯ç”Ÿäº§è€…,å‘Kafka Brokerå‘æ¶ˆæ¯çš„å®¢æˆ·ç«¯.
> 
> `Consumer` : æ¶ˆæ¯æ¶ˆè´¹è€…,å‘Kafka Brokeræ‹‰å–æ¶ˆæ¯çš„å®¢æˆ·ç«¯.
> 
> `Topic` : å¯ä»¥ç†è§£ä¸ºä¸€ä¸ªé˜Ÿåˆ—.
> 
> `Consumer Group`(CG) : è¿™æ˜¯Kafkaç”¨æ¥å®ç°Topicæ¶ˆæ¯å¹¿æ’­(å‘ç»™æ‰€æœ‰Consumer)å•æ’­(å‘ç»™ä»»æ„ä¸€ä¸ªConsumer)æ‰‹æ®µ,ä¸€ä¸ªTopicå¯ä»¥æœ‰å¤šä¸ªCG,Topicæ¶ˆæ¯ä¼šå¤åˆ¶(ä»…ä»…åªæ˜¯æ¦‚å¿µä¸Šçš„å¤åˆ¶)æ‰€æœ‰CG,ä½†æ¯ä¸ªPartionåªä¼šæŠŠæ¶ˆæ¯å‘ç»™è¯¥CGä¸­ä¸€ä¸ªConsumer.
> å¦‚æœéœ€è¦å®ç°å¹¿æ’­,åªè¦æ¯ä¸ªConsumeræœ‰ä¸€ä¸ªç‹¬ç«‹CGå°±å¯ä»¥äº†,è¦å®ç°å•æ’­åªè¦æ‰€æœ‰Consumeråœ¨åŒä¸€ä¸ªCG,ç”¨CGè¿˜å¯ä»¥å°†Consumerè¿›è¡Œè‡ªç”±åˆ†ç»„è€Œä¸éœ€è¦å¤šæ¬¡å‘é€æ¶ˆæ¯åˆ°ä¸åŒçš„Topic.
> 
> `Broker` : ä¸€å°KafkaæœåŠ¡å™¨å°±æ˜¯ä¸€ä¸ªBroker,ä¸€ä¸ªé›†ç¾¤ç”±å¤šä¸ªBrokerç»„æˆ,ä¸€ä¸ªBrokerå¯ä»¥å®¹çº³å¤šä¸ªTopic.
> 
> `Partition` : ä¸ºäº†å®ç°æ‰©å±•æ€§,ä¸€ä¸ªéå¸¸å¤§çš„Topicå¯ä»¥åˆ†å¸ƒåˆ°å¤šä¸ªBroker(å³æ˜¯æœåŠ¡å™¨),ä¸€ä¸ªTopicå¯ä»¥åˆ†ä¸ºå¤šä¸ªPartition,æ¯ä¸ªPartitionæ˜¯ä¸€ä¸ªæœ‰åºé˜Ÿåˆ—,Partitionä¸­æ¯æ¡æ¶ˆæ¯éƒ½ä¼šè¢«åˆ†é…ä¸€ä¸ªæœ‰åºId(Offset),Kafkaåªä¿è¯æŒ‰ä¸€ä¸ªPartitionä¸­é¡ºåºå°†æ¶ˆæ¯å‘ç»™Consumer,ä¸ä¿è¯ä¸€ä¸ªTopicæ•´ä½“(å¤šä¸ªPartitioné—´)é¡ºåº.
> 
> `Offset` : Kafkaå­˜å‚¨æ–‡ä»¶éƒ½æ˜¯æŒ‰ç…§offset.kafkaæ¥å‘½å,ç”¨Offsetä½œä¸ºåç§°çš„å¥½å¤„æ˜¯æ–¹ä¾¿æŸ¥æ‰¾,ä¾‹å¦‚æƒ³æ‰¾ä½äº2049ä½ç½®,åªè¦æ‰¾åˆ°2048.kafkaæ–‡ä»¶å³å¯,å½“ç„¶`the first offset`å°±æ˜¯00000000000.kafka.

## 2. Kafka é›†ç¾¤éƒ¨ç½²
### 2.1 ç¯å¢ƒå‡†å¤‡
#### 2.1.1 é›†ç¾¤è§„åˆ’
| Server Node | Zookooper Server | Kafka Server |
| :--------: | :--------:| :------: |
| systemhub511 ğŸ–¥ï¸ | zookeeper âœ… | kafka âœ…  |
| systemhub611 ğŸ–¥ï¸ | zookeeper âœ… | kafka âœ…  |
| systemhub711 ğŸ–¥ï¸ | zookeeper âœ… | kafka âœ…  |

#### 2.1.2 Download
- `Download Zookeeper` : [archive.apache.org/dist/zookeeper](https://archive.apache.org/dist/zookeeper/)
- `Download Kafka` : [kafka.apache.org/downloads](http://kafka.apache.org/downloads.html)

#### 2.1.3 å®‰è£… Zookeeper
##### 2.1.3.1 è§£å‹ zookeeper
```
[root@systemhub511 ~]#  cd /opt/software/
[root@systemhub511 software]# ll
total 512064
-rwxrwxrwx. 1 root root  35042811 Jan 17 19:18 zookeeper-3.4.10.tar.gz
[root@systemhub511 software]# tar -zxvf zookeeper-3.4.10.tar.gz -C /opt/module/
zookeeper-3.4.10/
zookeeper-3.4.10/LICENSE.txt
zookeeper-3.4.10/lib/
zookeeper-3.4.10/lib/log4j-1.2.16.LICENSE.txt
[root@systemhub511 software]#
```
##### 2.1.3.2 é‡å‘½å zookeeper
```
[root@systemhub511 module]# mv zookeeper-3.4.10 zookeeper
[root@systemhub511 module]# ll
total 20
drwxr-xr-x.  9 root  root  4096 Feb 24 21:55 apache-tomcat
drwxr-xr-x. 10 root  root  4096 Apr 11 17:02 flume
drwxr-xr-x. 12 10011 10011 4096 Mar  3 00:42 hadoop
drwxr-xr-x.  8 uucp    143 4096 Dec 20  2017 jdk1.8.0_162
drwxr-xr-x. 10  1001  1001 4096 Mar 23  2017 zookeeper
```
##### 2.1.3.3 åˆ›å»º zkDataç›®å½•
```
[root@systemhub511 zookeeper]# mkdir zkData
```
##### 2.1.3.4 é‡å‘½åé…ç½®æ–‡ä»¶
```
[root@systemhub511 conf]# mv zoo_sample.cfg zoo.cfg
[root@systemhub511 conf]# ll
total 12
-rw-rw-r--. 1 1001 1001  535 Mar 23  2017 configuration.xsl
-rw-rw-r--. 1 1001 1001 2161 Mar 23  2017 log4j.properties
-rw-rw-r--. 1 1001 1001  922 Mar 23  2017 zoo.cfg
[root@systemhub511 conf]# 
```
##### 2.1.3.5 é…ç½® zoo.cfgæ–‡ä»¶
> é…ç½®æ•°æ®ç¼“å­˜è·¯å¾„
```
[root@systemhub511 zkData]# pwd
/opt/module/zookeeper/zkData
[root@systemhub511 zookeeper]# cd conf/
[root@systemhub511 conf]# vim zoo.cfg
```
> ä¿®æ”¹é…ç½®ä¿¡æ¯
> 
> é…ç½®å‚æ•°è§£è¯» : `Server.A = B:C:D`
> Aè¡¨ç¤º æ ‡è¯†æœåŠ¡å™¨èŠ‚ç‚¹ID.
> Bè¡¨ç¤º æ ‡è¯†æœåŠ¡å™¨èŠ‚ç‚¹åç§°.
> Cè¡¨ç¤º æ ‡è¯†æœåŠ¡å™¨ä¸é›†ç¾¤ä¸­LeaderæœåŠ¡å™¨äº¤æ¢ä¿¡æ¯ç«¯å£.
> Dè¡¨ç¤º å¦‚é›†ç¾¤ä¸­LeaderæœåŠ¡å™¨å®•æœºæ—¶,éœ€è¦ä¸€ä¸ªç«¯å£æ¥é‡æ–°è¿›è¡Œé€‰ä¸¾,å¹¶é€‰å‡ºæ–°çš„Leader,è€Œè¿™ä¸ªç«¯å£å°±æ˜¯ç”¨æ¥æ‰§è¡Œé€‰ä¸¾æ—¶æœåŠ¡å™¨ç›¸äº’é€šä¿¡ç«¯å£.
``` dsconfig
# The number of milliseconds of each tick
tickTime=2000
# The number of ticks that the initial 
# synchronization phase can take
initLimit=10
# The number of ticks that can pass between 
# sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just 
# example sakes.
dataDir=/opt/module/zookeeper/zkData
# the port at which the clients will connect
clientPort=2181

################### Cluster ######################
server.1=systemhub511:2888:3888
server.2=systemhub611:2888:3888
server.3=systemhub711:2888:3888
```

##### 2.1.3.6 Zookeeper é›†ç¾¤
> é›†ç¾¤æ¨¡å¼ä¸‹éœ€é…ç½®myidæ–‡ä»¶,æ­¤æ–‡ä»¶æ˜¯åœ¨dataDirç›®å½•ä¸‹,æ­¤æ–‡ä»¶æ•°æ®ä¸­å°±æ˜¯Aå€¼,Zookeeperå¯åŠ¨æ—¶è¯»å–æ­¤æ–‡ä»¶,å¾—åˆ°çš„æ•°æ®ä¸zoo.cfgä¸­é…ç½®ä¿¡æ¯æ¯”è¾ƒä»è€Œåˆ¤æ–­å“ªä¸ªServer.
> 
> åˆ›å»ºmyid
```
[root@systemhub511 zookeeper]# cd zkData/
[root@systemhub511 zkData]# touch myid
[root@systemhub511 zkData]# vim myid
```
> æ ¹æ®zoo.cfgæœåŠ¡èŠ‚ç‚¹é…ç½®å¯¹åº”id,åœ¨å½“å‰systemhub511æœåŠ¡å™¨,idå¦‚1
```
1
```
> é›†ç¾¤åˆ†å‘
```
[root@systemhub511 module]# scp -r zookeeper/ root@systemhub611:/opt/module/zookeeper/
README.txt 100% 1585     1.6KB/s   00:00 
zookeeper-3.4.10-recipes-election.jar 100%   13KB  13.4KB/s   00:00    
[root@systemhub511 module]# 
[root@systemhub511 module]# scp -r zookeeper/ root@systemhub711:/opt/module/zookeeper/
README.txt 100% 1585     1.6KB/s   00:00 
zookeeper-3.4.10-recipes-election.jar 100%   13KB  13.4KB/s   00:00    
[root@systemhub511 module]#  
```
> åˆ†åˆ«é…ç½®myidæ–‡ä»¶
```
[root@systemhub611 module]# cd zookeeper/zkData/
[root@systemhub611 zkData]# vim myid
```
```
2
```
```
[root@systemhub711 module]# cd zookeeper/zkData/
[root@systemhub711 zkData]# vim myid
```
```
3
```
> å¯åŠ¨ Zookeeper Server é›†ç¾¤
> 
> åº”äº‹å…ˆå…³é—­é›†ç¾¤é˜²ç«å¢™
> 
>  Start systemhub511 Server Node
```
[root@systemhub511 zookeeper]# bin/zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /opt/module/zookeeper/bin/../conf/zoo.cfg
Starting zookeeper ... already running as process 31221.
[root@systemhub511 zookeeper]#
```
>  Start systemhub611 Server Node
```
[root@systemhub611 zookeeper]# bin/zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /opt/module/zookeeper/bin/../conf/zoo.cfg
Starting zookeeper ... already running as process 29605.
[root@systemhub611 zookeeper]# 
```
>  Start systemhub711 Server Node
```
[root@systemhub711 zookeeper]# bin/zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /opt/module/zookeeper/bin/../conf/zoo.cfg
Starting zookeeper ... already running as process 29650.
[root@systemhub711 zookeeper]#
```
> æŸ¥çœ‹ Zookeeper Server é›†ç¾¤çŠ¶æ€
> 
> systemhub511 Server Node Info
```
[root@systemhub511 zookeeper]# bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /opt/module/zookeeper/bin/../conf/zoo.cfg
Mode: follower
[root@systemhub511 zookeeper]#
```
> systemhub611 Server Node Info
```
[root@systemhub611 zookeeper]# bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /opt/module/zookeeper/bin/../conf/zoo.cfg
Mode: leader
[root@systemhub611 zookeeper]# 
```
> systemhub711 Server Node Info
```
[root@systemhub711 zookeeper]# bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /opt/module/zookeeper/bin/../conf/zoo.cfg
Mode: follower
[root@systemhub711 zookeeper]#
```


### 2.2 Kafka é›†ç¾¤éƒ¨ç½²
#### 2.2.1 è§£å‹ kafka
```
[root@systemhub511 software]# tar -zxvf kafka_2.11-0.11.0.0.tgz -C /opt/module/
kafka_2.11-0.11.0.0/
kafka_2.11-0.11.0.0/LICENSE
kafka_2.11-0.11.0.0/NOTICE
kafka_2.11-0.11.0.0/bin/
[root@systemhub511 software]#
```
#### 2.2.2 é‡å‘½åæ–‡ä»¶åç§°
```
[root@systemhub511 module]# mv kafka_2.11-0.11.0.0 kafka
[root@systemhub511 module]# ll
drwxr-xr-x.  6 root  root  4096 Jun 23  2017 kafka
[root@systemhub511 module]# 
```
#### 2.2.3 åˆ›å»ºlogsç›®å½•
```
[root@systemhub511 module]# cd kafka/
[root@systemhub511 kafka]# mkdir logs
```
#### 2.2.4 ä¿®æ”¹é…ç½®æ–‡ä»¶
```
[root@systemhub511 kafka]# cd config/
[root@systemhub511 config]# vim server.properties
```
> 
```
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# see kafka.server.KafkaConfig for additional details and defaults

############################# Server Basics #############################

# The id of the broker. This must be set to a unique integer for each broker.
broker.id=0

# Switch to enable topic deletion or not, default value is false
delete.topic.enable=true

############################# Socket Server Settings #############################

# The address the socket server listens on. It will get the value returned from 
# java.net.InetAddress.getCanonicalHostName() if not configured.
#   FORMAT:
#     listeners = listener_name://host_name:port
#   EXAMPLE:
#     listeners = PLAINTEXT://your.host.name:9092
#listeners=PLAINTEXT://:9092

# Hostname and port the broker will advertise to producers and consumers. If not set, 
# it uses the value for "listeners" if configured.  Otherwise, it will use the value
# returned from java.net.InetAddress.getCanonicalHostName().
#advertised.listeners=PLAINTEXT://your.host.name:9092

# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details
#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL

# The number of threads that the server uses for receiving requests from the network and sending responses to the network
num.network.threads=3

# The number of threads that the server uses for processing requests, which may include disk I/O
num.io.threads=8

# The send buffer (SO_SNDBUF) used by the socket server
socket.send.buffer.bytes=102400

# The receive buffer (SO_RCVBUF) used by the socket server
socket.receive.buffer.bytes=102400

# The maximum size of a request that the socket server will accept (protection against OOM)
socket.request.max.bytes=104857600


############################# Log Basics #############################

# A comma seperated list of directories under which to store log files
log.dirs=/opt/module/kafka/logss

# The default number of log partitions per topic. More partitions allow greater
# parallelism for consumption, but this will also result in more files across
# the brokers.
num.partitions=1

# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
# This value is recommended to be increased for installations with data dirs located in RAID array.
num.recovery.threads.per.data.dir=1

############################# Internal Topic Settings  #############################
# The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"
# For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1

############################# Log Flush Policy #############################

# Messages are immediately written to the filesystem but by default we only fsync() to sync
# the OS cache lazily. The following configurations control the flush of data to disk.
# There are a few important trade-offs here:
#    1. Durability: Unflushed data may be lost if you are not using replication.
#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.
#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to exceessive seeks.
# The settings below allow one to configure the flush policy to flush data after a period of time or
# every N messages (or both). This can be done globally and overridden on a per-topic basis.

# The number of messages to accept before forcing a flush of data to disk
#log.flush.interval.messages=10000

# The maximum amount of time a message can sit in a log before we force a flush
#log.flush.interval.ms=1000

############################# Log Retention Policy #############################

# The following configurations control the disposal of log segments. The policy can
# be set to delete segments after a period of time, or after a given size has accumulated.
# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens
# from the end of the log.

# The minimum age of a log file to be eligible for deletion due to age
log.retention.hours=168

# A size-based retention policy for logs. Segments are pruned from the log as long as the remaining
# segments don't drop below log.retention.bytes. Functions independently of log.retention.hours.
#log.retention.bytes=1073741824

# The maximum size of a log segment file. When this size is reached a new log segment will be created.
log.segment.bytes=1073741824

# The interval at which log segments are checked to see if they can be deleted according
# to the retention policies
log.retention.check.interval.ms=300000

############################# Zookeeper #############################

# Zookeeper connection string (see zookeeper docs for details).
# This is a comma separated host:port pairs, each corresponding to a zk
# server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
# You can also append an optional chroot string to the urls to specify the
# root directory for all kafka znodes.
zookeeper.connect=systemhub511:2181,systemhub611:2181,systemhub711:2181

# Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=6000


############################# Group Coordinator Settings #############################

# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.
# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.
# The default value for this is 3 seconds.
# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.
# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.
group.initial.rebalance.delay.ms=0
```
#### 2.2.5 é…ç½®ç¯å¢ƒå˜é‡
```
[root@systemhub511 kafka]# pwd
/opt/module/kafka
[root@systemhub511 kafka]# vim /etc/profile
```
> é…ç½®ä¿¡æ¯
```
## SET KAFKA_HOME
export KAFKA_HOME=/opt/module/kafka
export PATH=$PATH:$KAFKA_HOME/bin	
```
> æ›´æ–°é…ç½®æ–‡ä»¶
```
[root@systemhub511 kafka]# source /etc/profile
[root@systemhub511 kafka]# echo $KAFKA_HOME
/opt/module/kafka
```

#### 2.2.6 åˆ†å‘ kafkaé›†ç¾¤
```
[root@systemhub511 module]# scp -r kafka/ root@systemhub611:/opt/module/kafka/
connect-file-source.properties 100%  881     0.9KB/s   00:00    
.server.properties.swp 100%   16KB  16.0KB/s   00:00    
connect-file-sink.properties 100%  883     0.9KB/s   00:00
[root@systemhub511 module]#
```
```
[root@systemhub511 module]# scp -r kafka/ root@systemhub711:/opt/module/kafka/
connect-file-source.properties 100%  881     0.9KB/s   00:00    
.server.properties.swp 100%   16KB  16.0KB/s   00:00 
[root@systemhub511 module]#
```
> åˆ†åˆ«ä¿®æ”¹é…ç½®æ–‡ä»¶,broker.idä¸å¾—é‡å¤
```
[root@systemhub611 ~]# cd /opt/module/kafka/config/
[root@systemhub611 config]# vim server.properties
```
```
# The id of the broker. This must be set to a unique integer for each broker.
broker.id=1
```
```
[root@systemhub711 ~]# cd /opt/module/kafka/config/
[root@systemhub711 config]# vim server.properties
```
```
# The id of the broker. This must be set to a unique integer for each broker.
broker.id=2
```

#### 2.2.7 å¯åŠ¨ kafkaé›†ç¾¤
> å› KafkaServerä¾èµ–äºZookeeperServer,æ‰€ä»¥è¦äº‹å…ˆå¼€å¯ZookeeperServer.
```
[root@systemhub511 kafka]#  bin/kafka-server-start.sh config/server.properties
[1] 23152
```

```
[root@systemhub611 kafka]#  bin/kafka-server-start.sh config/server.properties
[1] 22647
```

```
[root@systemhub711 kafka]# bin/kafka-server-start.sh config/server.properties &
[1] 22736
```
#### 2.2.8 å…³é—­ kafkaé›†ç¾¤
```
[root@systemhub511 kafka]# bin/kafka-server-stop.sh stop
```
```
[root@systemhub611 kafka]# bin/kafka-server-stop.sh stop
```
```
[root@systemhub711 kafka]# bin/kafka-server-stop.sh stop
```


### 2.3 Kafka æŒ‡ä»¤
#### 2.3.1 åˆ›å»ºTopic
> å‚æ•°è¯´æ˜ : 
> `--topic` å®šä¹‰topicåç§°
> `--replication-factor` å®šä¹‰å‰¯æœ¬æ•°é‡
> `--partitions`   å®šä¹‰åˆ†åŒºæ•°é‡
```
[root@systemhub511 kafka]# bin/kafka-topics.sh --create --zookeeper systemhub511:2181 -partitions 2 --replication-factor 2 --topic topic001
Created topic "topic001".
[root@systemhub511 kafka]# 
```
#### 2.3.2 æŸ¥çœ‹å½“å‰æœåŠ¡ä¸­æ‰€æœ‰Topic
```
[root@systemhub511 kafka]# bin/kafka-topics.sh --list --zookeeper systemhub511:2181
topic001
[root@systemhub511 kafka]# 
```

#### 2.3.3 ç”Ÿäº§è€…
```
[root@systemhub511 kafka]# bin/kafka-console-producer.sh --broker-list systemhub511:9092 --topic topic001
>hello kafka
```
#### 2.3.4 æ¶ˆè´¹è€…
> è¿‡æ—¶ç‰ˆæœ¬è¯­æ³•
```
[root@systemhub711 kafka]# bin/kafka-console-consumer.sh --zookeeper systemhub511:2181 --topic topic001
Using the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].
hello kafka
```
> æ–°ç‰ˆæœ¬è¯­æ³•
``` dsconfig
[root@systemhub711 kafka]# bin/kafka-console-consumer.sh --bootstrap-server systemhub511:9092 --topic topic001 --from-beginning

hello kafka
```
#### 2.3.5 æŸ¥çœ‹Topicè¯¦æƒ…
```
[root@systemhub511 kafka]# bin/kafka-topics.sh --describe --zookeeper systemhub511 --topic topic001
Topic:topic001  PartitionCount:2        ReplicationFactor:2     Configs:
        Topic: topic001 Partition: 0    Leader: 1       Replicas: 1,0   Isr: 0,1
        Topic: topic001 Partition: 1    Leader: 2       Replicas: 2,1   Isr: 1,2
[root@systemhub511 kafka]# 
```
#### 2.3.6 åˆ é™¤Topic
> éœ€è¦åœ¨server.propertiesé…ç½®æ–‡ä»¶ä¸­è®¾ç½®`delete.topic.enable=true`
> å¦åˆ™åªæ˜¯æ ‡è®°åˆ é™¤æˆ–è€…ç›´æ¥é‡å¯
```
[root@systemhub511 kafka]# bin/kafka-topics.sh --delete --zookeeper systemhub511:2181 --topic topic001
Topic topic001 is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
[root@systemhub511 kafka]# 
```

### 2.4 Kafka é…ç½®ä¿¡æ¯
#### 2.4.1 Broker é…ç½®ä¿¡æ¯

| å±æ€§        |     é»˜è®¤å€¼ |   æè¿°   |
| :--------: | :--------:| :------: |
| broker.id     |   0/1/2/3/... |  å¿…å¡«å‚æ•°,brokerå”¯ä¸€æ ‡è¯†.  |
| log.dirs     |   /tmp/kafka-logs |  Kafkaæ•°æ®å­˜æ”¾çš„ç›®å½•,å¯ä»¥æŒ‡å®šå¤šä¸ªç›®å½•,ä¸­é—´ç”¨é€—å·åˆ†éš”,å½“æ–°partitionè¢«åˆ›å»ºæ—¶ä¼šè¢«å­˜æ”¾åˆ°å½“å‰å­˜æ”¾partitionæœ€å°‘çš„ç›®å½•.  |
| port     |   9092 |  BrokerServeræ¥å—å®¢æˆ·ç«¯è¿æ¥ç«¯å£å·  |
| zookeeper.connect     |   null |  Zookeeperè¿æ¥ä¸²æ ¼å¼ä¸º:`hostname1:port1,hostname2:port2,hostname3:port3`,æ³¨æ„,æ­¤é…ç½®å…è®¸æŒ‡å®šä¸€ä¸ªzookeeperè·¯å¾„æ¥å­˜æ”¾æ­¤kafkaé›†ç¾¤æ‰€æœ‰æ•°æ®,ä¸ºäº†ä¸å…¶ä»–åº”ç”¨é›†ç¾¤åŒºåˆ†å¼€,å»ºè®®åœ¨æ­¤é…ç½®ä¸­æŒ‡å®šæœ¬é›†ç¾¤å­˜æ”¾ç›®å½•æ ¼å¼ä¸º:`hostname1:port1,hostname2:port2,hostname3:port3/chroot/path`,è¦æ³¨æ„çš„æ˜¯,æ¶ˆè´¹è€…å‚æ•°è¦å’Œæ­¤å‚æ•°ä¸€è‡´.  |
| message.max.bytes     |   1000000 |  æœåŠ¡å™¨å¯ä»¥æ¥æ”¶åˆ°æœ€å¤§æ¶ˆæ¯çš„å¤§å°,æ³¨æ„æ­¤å‚æ•°è¦å’Œconsumerçš„`maximum.message.size`å€¼å¤§å°ä¸€è‡´,å¦åˆ™ä¼šå› ä¸ºç”Ÿäº§è€…ç”Ÿäº§æ¶ˆæ¯å¤ªå¤§å¯¼è‡´æ¶ˆè´¹è€…æ— æ³•æ¶ˆè´¹.  |
| num.io.threads     |   8 |  æœåŠ¡å™¨ç”¨æ¥æ‰§è¡Œè¯»å†™è¯·æ±‚IOçº¿ç¨‹æ•°,æ­¤å‚æ•°æ•°é‡è‡³å°‘è¦ç­‰äºæœåŠ¡å™¨ä¸Šç£ç›˜æ•°é‡.  |
| queued.max.requests     |   500 |  I/Oçº¿ç¨‹å¯ä»¥å¤„ç†è¯·æ±‚é˜Ÿåˆ—å¤§å°,è‹¥å®é™…è¯·æ±‚æ•°è¶…è¿‡æ­¤å¤§å°,ç½‘ç»œçº¿ç¨‹å°†åœæ­¢æ¥æ”¶æ–°è¯·æ±‚.  |
| socket.send.buffer.bytes     |   100 * 1024 |  The SO_SNDBUFF buffer    the server prefers for socket connections  |
| socket.receive.buffer.bytes.     |   field2 |  field3  |
| field1     |   100 * 1024 |  The SO_RCVBUFF buffer the server prefers for socket connections.  |
| socket.request.max.bytes     |   100 * 1024 * 1024 |  æœåŠ¡å™¨å…è®¸è¯·æ±‚æœ€å¤§å€¼,ç”¨æ¥é˜²æ­¢å†…å­˜æº¢å‡º,å…¶å€¼åº”è¯¥å°äºJava heap size.  |
| num.partitions     |   1 |  é»˜è®¤partitionæ•°é‡,å¦‚æœtopicåœ¨åˆ›å»ºæ—¶æ²¡æœ‰æŒ‡å®špartitionæ•°é‡,é»˜è®¤ä½¿ç”¨æ­¤å€¼,å»ºè®®æ”¹ä¸º5.  |
| log.segment.bytes     |   1024 * 1024 * 1024 |  Segmentæ–‡ä»¶å¤§å°,è¶…è¿‡æ­¤å€¼å°†ä¼šè‡ªåŠ¨æ–°å»ºä¸€ä¸ªsegment,æ­¤å€¼å¯ä»¥è¢«topicçº§åˆ«å‚æ•°è¦†ç›–.  |
| log.roll.{ms,hours}     |   24 * 7 hours |  æ–°å»ºsegmentæ–‡ä»¶æ—¶é—´,æ­¤å€¼å¯ä»¥è¢«topicçº§åˆ«å‚æ•°è¦†ç›–.  |
| log.retention.{ms,minutes,hours}     |   7 days |  Kafka segment logä¿å­˜å‘¨æœŸ,ä¿å­˜å‘¨æœŸè¶…è¿‡æ­¤æ—¶é—´æ—¥å¿—å°±ä¼šè¢«åˆ é™¤,æ­¤å‚æ•°å¯ä»¥è¢«topicçº§åˆ«å‚æ•°è¦†ç›–,æ•°æ®é‡å¤§æ—¶å»ºè®®å‡å°æ­¤å€¼.  |
| log.retention.bytes     |   -1 |  æ¯ä¸ªpartitionæœ€å¤§å®¹é‡,è‹¥æ•°æ®é‡è¶…è¿‡æ­¤å€¼,partitionæ•°æ®å°†ä¼šè¢«åˆ é™¤,æ³¨æ„è¿™ä¸ªå‚æ•°æ§åˆ¶æ¯ä¸ªpartitionè€Œä¸æ˜¯topic,æ­¤å‚æ•°å¯ä»¥è¢«logçº§åˆ«å‚æ•°è¦†ç›–.  |
| log.retention.check.interval.ms     |   5 minutes |  åˆ é™¤ç­–ç•¥çš„æ£€æŸ¥å‘¨æœŸ  |
| auto.create.topics.enable     |   true |  è‡ªåŠ¨åˆ›å»ºtopicå‚æ•°,å»ºè®®æ­¤å€¼è®¾ç½®ä¸ºfalse,ä¸¥æ ¼æ§åˆ¶topicç®¡ç†,é˜²æ­¢ç”Ÿäº§è€…é”™å†™topic.  |
| default.replication.factor     |   1 |  é»˜è®¤å‰¯æœ¬æ•°é‡,å»ºè®®æ”¹ä¸º2  |
| replica.lag.time.max.ms     |   10000 |  åœ¨æ­¤çª—å£æ—¶é—´å†…æ²¡æœ‰æ”¶åˆ°follower fetchè¯·æ±‚,leaderä¼šå°†å…¶ä»ISR(in-syncreplicas)ä¸­ç§»é™¤.  |
| replica.lag.max.messages     |   4000 |  å¦‚æœreplicaèŠ‚ç‚¹è½åleaderèŠ‚ç‚¹æ­¤å€¼å¤§å°æ¶ˆæ¯æ•°é‡,leaderèŠ‚ç‚¹å°±ä¼šå°†å…¶ä»ISRä¸­ç§»é™¤.  |
| replica.socket.timeout.ms     |   30 * 1000 |  replicaå‘leaderå‘é€è¯·æ±‚çš„è¶…æ—¶æ—¶é—´.  |
| replica.socket.receive.buffer.bytes     |   64 * 1024 |  The socket  receive buffer for network requests tothe leader for replicating data.  |
| replica.fetch.max.bytes     |   1024 * 1024 |  The number of byes   of messages to attempt to fetch for each partition in the fetch requests  the replicas send to the leader.  |
| replica.fetch.wait.max.ms     |   500 |  The maximum amount of time  towait time for data to arrive on the leader in the fetch requests sent by the replicas to the leader.  |
| num.replica.fetchers     |   1 |  Number of threads used to replicate messages from leaders. Increasing this value can increase the degree of  I/O parallelism in thefollower broker  |
| fetch.purgatory.purge.interval.requests     |   1000 |  The purge    interval (in number of requests) of the fetch request purgatory.  |
| zookeeper.session.timeout.ms     |   6000 |  ZooKeeper sessionè¶…æ—¶æ—¶é—´,å¦‚æœåœ¨æ­¤æ—¶é—´å†…serveræ²¡æœ‰å‘zookeeperå‘é€å¿ƒè·³,zookeeperå°±ä¼šè®¤ä¸ºæ­¤èŠ‚ç‚¹å·²æŒ‚æ‰,æ­¤å€¼å¤ªä½å¯¼è‡´èŠ‚ç‚¹å®¹æ˜“è¢«æ ‡è®°æ­»äº¡,è‹¥å¤ªé«˜ä¼šå¯¼è‡´å¤ªè¿Ÿå‘ç°èŠ‚ç‚¹æ­»äº¡. |
| zookeeper.connection.timeout.ms     |   6000 |  å®¢æˆ·ç«¯è¿æ¥zookeeperè¶…æ—¶æ—¶é—´.  |
| controlled.shutdown.enable     |   true |  å…è®¸broker shutdown,å¦‚æœå¯ç”¨brokeråœ¨å…³é—­ä¹‹å‰ä¼šæŠŠå®ƒä¸Šé¢æ‰€æœ‰leadersè½¬ç§»åˆ°å…¶å®ƒbrokersä¸Š,å»ºè®®å¯ç”¨å¢åŠ é›†ç¾¤ç¨³å®šæ€§.  |
| auto.leader.rebalance.enable     |   true |  If this is enabled the   controller will automatically try to balance leadership for partitions   among the brokers by periodically returning leadership to the â€œpreferredâ€  replica for each partition if it is available.  |
| leader.imbalance.per.broker.percentage     |   10 |  The percentage   of leader imbalance allowed per broker. The controller will rebalance  leadership if this ratio goes above the configured value per broker  |
| delete.topic.enable     |   false |  å¯ç”¨deletetopicå‚æ•°,å»ºè®®è®¾ç½®ä¸ºtrue.  |


#### 2.4.2 Producer é…ç½®ä¿¡æ¯

| å±æ€§        |     é»˜è®¤å€¼ |   æè¿°   |
| :--------: | :--------:| :------: |
| metadata.broker.list     |   |  å¯åŠ¨æ—¶produceræŸ¥è¯¢brokersåˆ—è¡¨,å¯ä»¥æ˜¯é›†ç¾¤ä¸­æ‰€æœ‰brokersä¸€ä¸ªå­é›†,æ³¨æ„è¿™ä¸ªå‚æ•°åªæ˜¯ç”¨æ¥è·å–topicå…ƒä¿¡æ¯,producerä¼šä»å…ƒä¿¡æ¯ä¸­æŒ‘é€‰åˆé€‚çš„brokerå¹¶ä¸ä¹‹å»ºç«‹socketè¿æ¥,æ ¼å¼ä¸º:`host1:port1,host2:port2`  |
| request.timeout.ms     |   10000 |  Brokerç­‰å¾…ackè¶…æ—¶æ—¶é—´,è‹¥ç­‰å¾…æ—¶é—´è¶…è¿‡æ­¤å€¼,ä¼šè¿”å›å®¢æˆ·ç«¯é”™è¯¯ä¿¡æ¯.  |
| producer.type     |   sync |  åŒæ­¥å¼‚æ­¥æ¨¡å¼,asyncè¡¨ç¤ºå¼‚æ­¥,syncè¡¨ç¤ºåŒæ­¥,å¦‚æœè®¾ç½®æˆå¼‚æ­¥æ¨¡å¼,å¯ä»¥å…è®¸ç”Ÿäº§è€…ä»¥batchå½¢å¼pushæ•°æ®,è¿™æ ·ä¼šæå¤§æé«˜brokeræ€§èƒ½,æ¨èè®¾ç½®ä¸ºå¼‚æ­¥.  |
| serializer.class     |   kafka.serializer.DefaultEncoder |  åºåˆ—å·ç±»,é»˜è®¤åºåˆ—åŒ–ç±»å‹ä¸ºbyte[]  |
| key.serializer.class     |   |  Keyåºåˆ—åŒ–ç±»,é»˜è®¤åŒä¸Š  |
| partitioner.class     |   kafka.producer.DefaultPartitioner |  Partitionç±»,é»˜è®¤å¯¹keyè¿›è¡Œhash.  |
| compression.codec     |   none |  æŒ‡å®šproduceræ¶ˆæ¯å‹ç¼©æ ¼å¼,å¯é€‰å‚æ•°ä¸ºï¼šnone / gzip / snappy  |
| compressed.topics     |   null |  å¯ç”¨å‹ç¼©topicåç§°,è‹¥ä¸Šé¢å‚æ•°é€‰æ‹©äº†ä¸€ä¸ªå‹ç¼©æ ¼å¼,é‚£ä¹ˆå‹ç¼©ä»…å¯¹æœ¬å‚æ•°æŒ‡å®šçš„topicæœ‰æ•ˆ,è‹¥æœ¬å‚æ•°ä¸ºç©ºåˆ™å¯¹æ‰€æœ‰topicæœ‰æ•ˆ.  |
| message.send.max.retries     |   3 |  Producerå‘é€å¤±è´¥æ—¶é‡è¯•æ¬¡æ•°,è‹¥ç½‘ç»œå‡ºç°é—®é¢˜å¯èƒ½ä¼šå¯¼è‡´ä¸æ–­é‡è¯•.  |
| queue.buffering.max.ms     |   5000 |  å¯ç”¨å¼‚æ­¥æ¨¡å¼æ—¶,producerç¼“å­˜æ¶ˆæ¯æ—¶é—´,æ¯”å¦‚è®¾ç½®æˆ1000æ—¶,å®ƒä¼šç¼“å­˜1ç§’æ•°æ®å†ä¸€æ¬¡å‘é€å‡ºå»,è¿™æ ·å¯ä»¥æå¤§å¢åŠ brokerååé‡,ä½†ä¹Ÿä¼šé€ æˆæ—¶æ•ˆæ€§é™ä½.  |
| queue.buffering.max.messages     |   10000 |  é‡‡ç”¨å¼‚æ­¥æ¨¡å¼æ—¶producer  bufferé˜Ÿåˆ—é‡Œæœ€å¤§ç¼“å­˜æ¶ˆæ¯æ•°é‡,å¦‚æœè¶…è¿‡è¿™ä¸ªæ•°å€¼,producerå°±ä¼šé˜»å¡æˆ–è€…ä¸¢æ‰æ¶ˆæ¯.  |
| queue.enqueue.timeout.ms     |   -1 |  å½“è¾¾åˆ°ä¸Šé¢å‚æ•°å€¼æ—¶produceré˜»å¡ç­‰å¾…æ—¶é—´,å¦‚æœå€¼è®¾ç½®ä¸º0,bufferé˜Ÿåˆ—æ»¡æ—¶producerä¸ä¼šé˜»å¡,æ¶ˆæ¯ç›´æ¥è¢«ä¸¢æ‰,è‹¥å€¼è®¾ç½®ä¸º-1,producerä¼šè¢«é˜»å¡ä¸ä¼šä¸¢æ¶ˆæ¯.  |
| batch.num.messages     |   200 |  ç”¨å¼‚æ­¥æ¨¡å¼æ—¶,ä¸€ä¸ªbatchç¼“å­˜æ¶ˆæ¯æ•°é‡,è¾¾åˆ°è¿™ä¸ªæ•°é‡å€¼æ—¶produceræ‰ä¼šå‘é€æ¶ˆæ¯.  |
| send.buffer.bytes     |   100 * 1024 |  Socket write buffer size  |


#### 2.4.3 Consumer é…ç½®ä¿¡æ¯
| å±æ€§        |     é»˜è®¤å€¼ |   æè¿°   |
| :--------: | :--------:| :------: |
| group.id     |   |  Consumerç»„ID,ç›¸åŒgoup.idçš„consumerå±äºåŒä¸€ä¸ªç»„.  |
| zookeeper.connect     |   |  Consumerçš„zookeeperè¿æ¥ä¸²,è¦å’Œbrokerçš„é…ç½®ä¸€è‡´. |
| consumer.id     |   null |  å¦‚æœä¸è®¾ç½®ä¼šè‡ªåŠ¨ç”Ÿæˆ.  |
| socket.timeout.ms     |   30 * 1000 |  ç½‘ç»œè¯·æ±‚socketè¶…æ—¶æ—¶é—´,å®é™…è¶…æ—¶æ—¶é—´ç”±`max.fetch.wait` + `socket.timeout.ms` ç¡®å®š. |
| fetch.message.max.bytes     |   1024 * 1024 |  æŸ¥è¯¢topic-partitionæ—¶å…è®¸çš„æœ€å¤§æ¶ˆæ¯å¤§å°,consumerä¼šä¸ºæ¯ä¸ªpartitionç¼“å­˜æ­¤å¤§å°æ¶ˆæ¯åˆ°å†…å­˜,å› æ­¤è¿™ä¸ªå‚æ•°å¯ä»¥æ§åˆ¶consumerå†…å­˜ä½¿ç”¨é‡,è¿™ä¸ªå€¼åº”è¯¥è‡³å°‘æ¯”serverå…è®¸æœ€å¤§æ¶ˆæ¯å¤§å°å¤§,ä»¥å…producerå‘é€æ¶ˆæ¯å¤§äºconsumerå…è®¸æ¶ˆæ¯.  |
| auto.commit.enable     |   true |  å¦‚æœæ­¤å€¼è®¾ç½®ä¸ºtrue,consumerä¼šå‘¨æœŸæ€§æŠŠå½“å‰æ¶ˆè´¹offsetå€¼ä¿å­˜åˆ°zookeeper,å½“consumerå¤±è´¥é‡å¯ä¹‹åå°†ä¼šä½¿ç”¨æ­¤å€¼ä½œä¸ºæ–°å¼€å§‹æ¶ˆè´¹çš„å€¼.  |
| auto.commit.interval.ms     |   60 * 1000 |  Consumeræäº¤offsetå€¼åˆ°zookeeperå‘¨æœŸ.  |
| queued.max.message.chunks     |   2 |  ç”¨æ¥è¢«consumeræ¶ˆè´¹message chunks æ•°é‡,æ¯ä¸ªchunkå¯ä»¥ç¼“å­˜`fetch.message.max.bytes`å¤§å°æ•°æ®é‡.  |
| auto.commit.interval.ms     |   60 * 1000 |  Consumeræäº¤offsetå€¼åˆ°zookeeperå‘¨æœŸ.  |
| queued.max.message.chunks     |   2 |  ç”¨æ¥è¢«consumeræ¶ˆè´¹message chunks æ•°é‡,æ¯ä¸ªchunkå¯ä»¥ç¼“å­˜`fetch.message.max.bytes`å¤§å°æ•°æ®é‡.  |
| consumer.timeout.ms     |   -1 |  è‹¥åœ¨æŒ‡å®šæ—¶é—´å†…æ²¡æœ‰æ¶ˆæ¯æ¶ˆè´¹,consumerå°†ä¼šæŠ›å‡ºå¼‚å¸¸.  |


## 3. Kafka å·¥ä½œæµåˆ†æ
![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/kafka/start_003.jpg)

### 3.1 Kafka ç”Ÿäº§è¿‡ç¨‹
#### 3.1.1 å†™å…¥æ–¹å¼
> produceré‡‡ç”¨æ¨(push)æ¨¡å¼å°†æ¶ˆæ¯å‘å¸ƒåˆ°broker,æ¯æ¡æ¶ˆæ¯éƒ½è¢«è¿½åŠ (append)åˆ°åˆ†åŒº(patition)ä¸­,å±äºé¡ºåºå†™ç£ç›˜(é¡ºåºå†™ç£ç›˜æ•ˆç‡æ¯”éšæœºå†™å†…å­˜è¦é«˜,ä¿éšœkafkaååç‡).

#### 3.1.2 åˆ†åŒº (Partition)
> æ¶ˆæ¯å‘é€æ—¶éƒ½è¢«å‘é€åˆ°ä¸€ä¸ªtopic,å…¶æœ¬è´¨å°±æ˜¯ä¸€ä¸ªç›®å½•,è€Œtopicæ˜¯ç”±ä¸€äº›Partition Logs(åˆ†åŒºæ—¥å¿—)ç»„æˆ,å…¶ç»„ç»‡ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤º

![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/kafka/start_004.jpg)
> æ¯ä¸ªPartitionä¸­çš„æ¶ˆæ¯éƒ½æ˜¯æœ‰åº,ç”Ÿäº§æ¶ˆæ¯è¢«ä¸æ–­è¿½åŠ åˆ°Partition logä¸Š,å…¶ä¸­æ¯ä¸€ä¸ªæ¶ˆæ¯éƒ½è¢«èµ‹äºˆäº†ä¸€ä¸ªå”¯ä¸€çš„offsetå€¼.
> 
> `åˆ†åŒºåŸå› `
> 1.æ–¹ä¾¿åœ¨é›†ç¾¤ä¸­æ‰©å±•,æ¯ä¸ªPartitionå¯ä»¥é€šè¿‡è°ƒæ•´ä»¥é€‚åº”å®ƒæ‰€åœ¨æœºå™¨,è€Œä¸€ä¸ªtopicåˆå¯ä»¥æœ‰å¤šä¸ªPartitionç»„æˆ,å› æ­¤æ•´ä¸ªé›†ç¾¤å°±å¯ä»¥é€‚åº”ä»»æ„å¤§å°æ•°æ®äº†.
> 
> 2.å› ä¸ºä»¥Partitionä¸ºå•ä½è¯»å†™,æ‰€ä»¥å¯ä»¥æé«˜å¹¶å‘.
> 
> `åˆ†åŒºè§„åˆ™`
> æŒ‡å®špatition,åˆ™ç›´æ¥ä½¿ç”¨.
> æœªæŒ‡å®špatitionä½†æŒ‡å®škey,é€šè¿‡å¯¹keyçš„valueè¿›è¡Œhashå‡ºä¸€ä¸ªpatition.
> patitionå’Œkeyéƒ½æœªæŒ‡å®š,ä½¿ç”¨è½®è¯¢é€‰å‡ºä¸€ä¸ªpatition.
> 
> DefaultPartitionerç±»
``` java
    public int partition(String topic, Object key, byte[] keyBytes,
        Object value, byte[] valueBytes, Cluster cluster) {
        List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
        intnumPartitions = partitions.size();

        if (keyBytes == null) {
            intnextValue = nextValue(topic);

            List<PartitionInfo> availablePartitions = cluster.availablePartitionsForTopic(topic);

            if (availablePartitions.size() > 0) {
                intpart = Utils.toPositive(nextValue) % availablePartitions.size();

                return availablePartitions.get(part).partition();
            } else {
                // no partitions are available, give a non-available partition
                return Utils.toPositive(nextValue) % numPartitions;
            }
        } else {
            // hash the keyBytes to choose a partition
            return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
        }
    }
```

#### 3.1.3 å‰¯æœ¬ (Replication)
> åŒä¸€ä¸ªpartitionå¯èƒ½ä¼šæœ‰å¤šä¸ªreplication(å¯¹åº”server.propertiesé…ç½®ä¸­çš„`default.replication.factor=N`)
> 
> æ²¡æœ‰replicationæƒ…å†µä¸‹,ä¸€æ—¦brokerå®•æœº,å…¶ä¸Šæ‰€æœ‰patitionæ•°æ®éƒ½ä¸å¯è¢«æ¶ˆè´¹.
> 
> åŒæ—¶producerä¹Ÿä¸èƒ½å†å°†æ•°æ®å­˜äºå…¶ä¸Šçš„patition,å¼•å…¥replicationä¹‹å,åŒä¸€ä¸ªpartitionå¯èƒ½ä¼šæœ‰å¤šä¸ªreplication,è€Œè¿™æ—¶éœ€è¦åœ¨è¿™äº›replicationä¹‹é—´é€‰å‡ºä¸€ä¸ªleader,producerå’Œconsumeråªä¸è¿™ä¸ªleaderäº¤äº’,å…¶å®ƒreplicationä½œä¸ºfollowerä»leaderä¸­å¤åˆ¶æ•°æ®.


#### 3.1.4 å†™å…¥æµç¨‹
![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/kafka/start_005.jpg)
> 1.producerå…ˆä»zookeeper `/brokers/.../state`èŠ‚ç‚¹æ‰¾åˆ°è¯¥partitionçš„leader.
> 
> 2.producerå°†æ¶ˆæ¯å‘é€ç»™è¯¥leader.
> 
> 3.leaderå°†æ¶ˆæ¯å†™å…¥æœ¬åœ°log.
> 
> 4.followersä»leader pullæ¶ˆæ¯,å†™å…¥æœ¬åœ°logåå‘leaderå‘é€ACK.
> 
> 5.leaderæ”¶åˆ°æ‰€æœ‰ISRä¸­çš„replicationçš„ACKå,å¢åŠ HW(high watermark,æœ€åcommit çš„offset)å‘producerå‘é€ACK


### 3.2 Broker å­˜å‚¨è¿‡ç¨‹
#### 3.2.1 å­˜å‚¨æ–¹å¼
> ç‰©ç†ä¸ŠæŠŠtopicåˆ†æˆä¸€ä¸ªæˆ–å¤šä¸ªpatition(å¯¹åº”server.propertiesä¸­`num.partitions=3`é…ç½®),æ¯ä¸ªpatitionç‰©ç†ä¸Šå¯¹åº”ä¸€ä¸ªæ–‡ä»¶å¤¹(è¯¥æ–‡ä»¶å¤¹å­˜å‚¨è¯¥patitionçš„æ‰€æœ‰æ¶ˆæ¯å’Œç´¢å¼•æ–‡ä»¶).
```
[root@systemhub511 kafka]# cd logs
[root@systemhub511 logs]# ll
total 312
-rw-r--r--. 1 root root   293 Apr 17 21:07 controller.log
-rw-r--r--. 1 root root     0 Apr 17 14:15 kafka-authorizer.log
-rw-r--r--. 1 root root     0 Apr 17 14:15 kafka-request.log
-rw-r--r--. 1 root root 21691 Apr 18 00:01 kafkaServer-gc.log.0.current
-rw-r--r--. 1 root root   318 Apr 17 22:37 log-cleaner.log
-rw-r--r--. 1 root root   195 Apr 18 00:01 server.log
-rw-r--r--. 1 root root 32012 Apr 17 22:37 state-change.log
[root@systemhub511 logs]# 
```
#### 3.2.2 å­˜å‚¨ç­–ç•¥
> æ— è®ºæ¶ˆæ¯æ˜¯å¦è¢«æ¶ˆè´¹,kafkaéƒ½ä¼šä¿ç•™æ‰€æœ‰æ¶ˆæ¯,æœ‰ä¸¤ç§ç­–ç•¥å¯ä»¥åˆ é™¤æ—§æ•°æ®:
> 1.åŸºäºæ—¶é—´ : log.retention.hours=168
> 2.åŸºäºå¤§å° : log.retention.bytes=1073741824
> éœ€è¦æ³¨æ„çš„æ˜¯,å› ä¸ºKafkaè¯»å–ç‰¹å®šæ¶ˆæ¯çš„æ—¶é—´å¤æ‚åº¦ä¸ºO(1),å³ä¸æ–‡ä»¶å¤§å°æ— å…³,æ‰€ä»¥è¿™é‡Œåˆ é™¤è¿‡æœŸæ–‡ä»¶ä¸æé«˜Kafkaæ€§èƒ½æ— å…³.

#### 3.2.3 Zookeeper å­˜å‚¨ç»“æ„
> æ³¨æ„ï¼šproducerä¸åœ¨zkä¸­æ³¨å†Œ,è€Œæ¶ˆè´¹è€…åœ¨zkä¸­æ³¨å†Œ.
![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/kafka/start_006.jpg)


### 3.3 Kafka æ¶ˆè´¹è¿‡ç¨‹
> Kafkaæä¾›ä¸¤å¥—consumer API : é«˜çº§Consumer API å’Œ ä½çº§API
#### 3.3.1 é«˜çº§ API
> `é«˜çº§API ä¼˜ç‚¹`
- é«˜çº§APIç¼–å†™èµ·æ¥éå¸¸ç®€å•. 
- ä¸éœ€è¦è‡ªè¡Œç®¡ç†offset,ç³»ç»Ÿé€šè¿‡zookeeperè‡ªè¡Œç®¡ç†.
- ä¸éœ€è¦ç®¡ç†åˆ†åŒº,å‰¯æœ¬ç­‰æƒ…å†µ,ç³»ç»Ÿè‡ªåŠ¨ç®¡ç†.
- æ¶ˆè´¹è€…æ–­çº¿ä¼šè‡ªåŠ¨æ ¹æ®ä¸Šä¸€æ¬¡è®°å½•åœ¨zookeeperä¸­çš„offsetè·å–æ•°æ®(é»˜è®¤è®¾ç½®1åˆ†é’Ÿæ›´æ–°ä¸€ä¸‹zookeeperä¸­å­˜çš„offset).
- å¯ä»¥ä½¿ç”¨groupæ¥åŒºåˆ†å¯¹åŒä¸€ä¸ªtopicä¸åŒç¨‹åºè®¿é—®åˆ†ç¦»å¼€æ¥(ä¸åŒçš„groupè®°å½•ä¸åŒçš„offset,è¿™æ ·ä¸åŒç¨‹åºè¯»å–åŒä¸€ä¸ªtopicæ‰ä¸ä¼šå› ä¸ºoffsetäº’ç›¸å½±å“).

> `é«˜çº§API ç¼ºç‚¹`
- å¯¹äºæŸäº›ç‰¹æ®Šéœ€æ±‚æ¥è¯´,ä¸èƒ½è‡ªè¡Œæ§åˆ¶offset.
- ä¸èƒ½ç»†åŒ–æ§åˆ¶å¦‚åˆ†åŒºã€å‰¯æœ¬ã€zkç­‰.

#### 3.3.2 ä½çº§ API
> `ä½çº§API ä¼˜ç‚¹`
- èƒ½è®©å¼€å‘è€…è‡ªæ§offset.
- è‡ªè¡Œæ§åˆ¶è¿æ¥åˆ†åŒº,å¯¹åˆ†åŒºè‡ªå®šä¹‰è¿›è¡Œè´Ÿè½½å‡è¡¡.
- å¯¹zookeeperä¾èµ–æ€§é™ä½ (å¦‚ : offsetä¸ä¸€å®šè¦é zkå­˜å‚¨,è‡ªè¡Œå­˜å‚¨offsetå³å¯,æ¯”å¦‚å­˜åœ¨æ–‡ä»¶æˆ–è€…å†…å­˜ä¸­).

> `ä½çº§API ç¼ºç‚¹`
- æ“ä½œå¤ªè¿‡å¤æ‚,éœ€è¦è‡ªè¡Œæ§åˆ¶offset,è¿æ¥åˆ†åŒº,æ‰¾åˆ°åˆ†åŒºleaderç­‰.


#### 3.3.3 æ¶ˆè´¹è€…ç»„
![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/kafka/start_007.jpg)
> æ¶ˆè´¹è€…æ˜¯ä»¥consumer groupæ¶ˆè´¹è€…ç»„çš„æ–¹å¼å·¥ä½œ,ç”±ä¸€ä¸ªæˆ–è€…å¤šä¸ªæ¶ˆè´¹è€…ç»„æˆä¸€ä¸ªç»„ï¼Œå…±åŒæ¶ˆè´¹ä¸€ä¸ªtopic.
> 
> æ¯ä¸ªåˆ†åŒºåœ¨åŒä¸€æ—¶é—´åªèƒ½ç”±groupä¸­çš„ä¸€ä¸ªæ¶ˆè´¹è€…è¯»å–,ä½†æ˜¯å¤šä¸ªgroupå¯ä»¥åŒæ—¶æ¶ˆè´¹è¿™ä¸ªpartition.
> 
> å¦‚å›¾æ‰€ç¤º,ä¸€ä¸ªç”±ä¸‰ä¸ªæ¶ˆè´¹è€…ç»„æˆçš„group,æœ‰ä¸€ä¸ªæ¶ˆè´¹è€…è¯»å–ä¸»é¢˜ä¸­ä¸¤ä¸ªåˆ†åŒº,å¦å¤–ä¸¤ä¸ªåˆ†åˆ«è¯»å–ä¸€ä¸ªåˆ†åŒº,æŸä¸ªæ¶ˆè´¹è€…è¯»å–æŸä¸ªåˆ†åŒº,ä¹Ÿå¯ä»¥å«åšæŸä¸ªæ¶ˆè´¹è€…æ˜¯æŸä¸ªåˆ†åŒºçš„æ‹¥æœ‰è€….
> 
> åœ¨è¿™ç§æƒ…å†µä¸‹,æ¶ˆè´¹è€…å¯ä»¥é€šè¿‡æ°´å¹³æ‰©å±•æ–¹å¼åŒæ—¶è¯»å–å¤§é‡æ¶ˆæ¯,å¦å¤–,å¦‚æœä¸€ä¸ªæ¶ˆè´¹è€…å¤±è´¥äº†,é‚£ä¹ˆå…¶ä»–groupæˆå‘˜ä¼šè‡ªåŠ¨è´Ÿè½½å‡è¡¡è¯»å–ä¹‹å‰å¤±è´¥æ¶ˆè´¹è€…è¯»å–åˆ†åŒº.


#### 3.3.4 æ¶ˆè´¹æ–¹å¼
> consumeré‡‡ç”¨pull(æ‹‰)æ¨¡å¼ä»brokerä¸­è¯»å–æ•°æ®.
> 
> push(æ¨)æ¨¡å¼å¾ˆéš¾é€‚åº”æ¶ˆè´¹é€Ÿç‡ä¸åŒæ¶ˆè´¹è€…,å› ä¸ºæ¶ˆæ¯å‘é€é€Ÿç‡æ˜¯ç”±brokerå†³å®š.
> å®ƒç›®æ ‡æ˜¯å°½å¯èƒ½ä»¥æœ€å¿«é€Ÿåº¦ä¼ é€’æ¶ˆæ¯,ä½†æ˜¯è¿™æ ·å¾ˆå®¹æ˜“é€ æˆconsumeræ¥ä¸åŠå¤„ç†æ¶ˆæ¯,å…¸å‹è¡¨ç°å°±æ˜¯æ‹’ç»æœåŠ¡ä»¥åŠç½‘ç»œæ‹¥å¡,è€Œpullæ¨¡å¼åˆ™å¯ä»¥æ ¹æ®consumeræ¶ˆè´¹èƒ½åŠ›ä»¥é€‚å½“é€Ÿç‡æ¶ˆè´¹æ¶ˆæ¯.
> 
> å¯¹äºKafkaè€Œè¨€,pullæ¨¡å¼æ›´åˆé€‚,å®ƒå¯ç®€åŒ–brokerçš„è®¾è®¡,consumerå¯è‡ªä¸»æ§åˆ¶æ¶ˆè´¹æ¶ˆæ¯é€Ÿç‡,åŒæ—¶consumerå¯ä»¥è‡ªå·±æ§åˆ¶æ¶ˆè´¹æ–¹å¼â€”â€”å³å¯æ‰¹é‡æ¶ˆè´¹ä¹Ÿå¯é€æ¡æ¶ˆè´¹,åŒæ—¶è¿˜èƒ½é€‰æ‹©ä¸åŒæäº¤æ–¹å¼ä»è€Œå®ç°ä¸åŒä¼ è¾“è¯­ä¹‰.
> 
> pullæ¨¡å¼ä¸è¶³ä¹‹å¤„æ˜¯,å¦‚æœkafkaæ²¡æœ‰æ•°æ®,æ¶ˆè´¹è€…å¯èƒ½ä¼šé™·å…¥å¾ªç¯ä¸­,ä¸€ç›´ç­‰å¾…æ•°æ®åˆ°è¾¾.
> 
> ä¸ºäº†é¿å…è¿™ç§æƒ…å†µ,åœ¨æ‹‰è¯·æ±‚ä¸­æœ‰å‚æ•°,å…è®¸æ¶ˆè´¹è€…è¯·æ±‚åœ¨ç­‰å¾…æ•°æ®åˆ°è¾¾â€œé•¿è½®è¯¢â€ä¸­è¿›è¡Œé˜»å¡(å¹¶ä¸”å¯é€‰åœ°ç­‰å¾…åˆ°ç»™å®šçš„å­—èŠ‚æ•°,ä»¥ç¡®ä¿å¤§çš„ä¼ è¾“å¤§å°)

#### 3.3.5 æ¶ˆè´¹è€…ç»„æ¡ˆä¾‹
> æµ‹è¯•åŒä¸€ä¸ªæ¶ˆè´¹è€…ç»„ä¸­çš„æ¶ˆè´¹è€…,åŒä¸€æ—¶åˆ»åªèƒ½æœ‰ä¸€ä¸ªæ¶ˆè´¹è€…æ¶ˆè´¹.
> 
> åœ¨systemhub511ã€systemhub611æœåŠ¡å™¨ä¸­ä¿®æ”¹`/opt/module/kafka/config/consumer.properties`é…ç½®æ–‡ä»¶ä¸­çš„`group.id`å±æ€§ä¸ºä»»æ„ç»„å.
```
[root@systemhub511 module]# cd kafka/
[root@systemhub511 kafka]# vim config/consumer.properties
```
```
#consumer group id
group.id=systemhub511
```
```
[root@systemhub611 module]# cd kafka/
[root@systemhub611 kafka]# vim config/consumer.properties
```
```
#consumer group id
group.id=systemhub611
```
> åˆ†åˆ«å¯åŠ¨æ¶ˆè´¹è€…
```
[root@systemhub511 kafka]# bin/kafka-console-consumer.sh --zookeeper systemhub511:2181 --topic topic001 --consumer.config config/consumer.properties
Using the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].
```
```
[root@systemhub611 kafka]# bin/kafka-console-consumer.sh --zookeeper systemhub511:2181 --topic topic001 --consumer.config config/consumer.properties
Using the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].
[067] WARN [systemhub611_systemhub611-1555744110617-1d4d406d], no brokers found when trying to rebalance. (kafka.consumer.ZookeeperConsumerConnector)
```
> åœ¨systemhub711æœåŠ¡å™¨ å¯åŠ¨ç”Ÿäº§è€…
```
[root@systemhub711 kafka]# bin/kafka-console-producer.sh --broker-list systemhub511:9092 --topic topic001
>hello kafka!
```
> æŸ¥çœ‹systemhub511å’Œsystemhub611 æ¥æ”¶è€…
> åŒä¸€æ—¶åˆ»åªæœ‰ä¸€ä¸ªæ¶ˆè´¹è€…æ¥æ”¶åˆ°æ¶ˆæ¯.
```
[root@systemhub611 kafka]# bin/kafka-console-consumer.sh --zookeeper systemhub511:2181 --topic topic001 --consumer.config config/consumer.properties
Using the ConsoleConsumer with old consumer is deprecated and will be removed in a future major release. Consider using the new consumer by passing [bootstrap-server] instead of [zookeeper].
hello kafka!
```


## 4. Kafka API

## 5. Kafka Produceræ‹¦æˆªå™¨

## 6. Kafka Streams


## 7. ä¿®ä»™ä¹‹é“ æŠ€æœ¯æ¶æ„è¿­ä»£ ç™»å³°é€ æä¹‹åŠ¿
![Alt text](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/main/technical_framework.jpg)


-----

## ğŸ’¡å¦‚ä½•å¯¹è¯¥å¼€æºæ–‡æ¡£è¿›è¡Œè´¡çŒ®ğŸ’¡

1. Blogå†…å®¹å¤§å¤šæ˜¯æ‰‹æ•²,æ‰€ä»¥éš¾å…ä¼šæœ‰ç¬”è¯¯,ä½ å¯ä»¥å¸®æˆ‘æ‰¾é”™åˆ«å­—ã€‚
2. å¾ˆå¤šçŸ¥è¯†ç‚¹æˆ‘å¯èƒ½æ²¡æœ‰æ¶‰åŠåˆ°,æ‰€ä»¥ä½ å¯ä»¥å¯¹å…¶ä»–çŸ¥è¯†ç‚¹è¿›è¡Œè¡¥å……ã€‚
3. ç°æœ‰çš„çŸ¥è¯†ç‚¹éš¾å…å­˜åœ¨ä¸å®Œå–„æˆ–è€…é”™è¯¯,æ‰€ä»¥ä½ å¯ä»¥å¯¹å·²æœ‰çŸ¥è¯†ç‚¹çš„ä¿®æ”¹/è¡¥å……ã€‚
4. ğŸ’¡æ¬¢è¿è´¡çŒ®`å„é¢†åŸŸå¼€æºé‡ç”ŸBlog`&`ç¬”è®°`&`æ–‡ç« `&`ç‰‡æ®µ`&`åˆ†äº«`&`åˆ›æƒ³`&`OpenSource Project`&`Code`&`Code Review`
5. ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ issues: [geekparkhub.github.io/issues](https://github.com/geekparkhub/geekparkhub.github.io/issues) ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ

### å¸Œæœ›æ¯ä¸€ç¯‡æ–‡ç« éƒ½èƒ½å¤Ÿå¯¹è¯»è€…ä»¬æä¾›å¸®åŠ©ä¸æå‡,è¿™ä¹ƒæ˜¯æ¯ä¸€ä½ç¬”è€…çš„åˆè¡·                          


-----


## ğŸ’Œæ„Ÿè°¢æ‚¨çš„é˜…è¯» æ¬¢è¿æ‚¨çš„ç•™è¨€ä¸å»ºè®®ğŸ’Œ

- FaceBookï¼š[JEEP SevenEleven](https://www.facebook.com/profile.php?id=100018099483403)
- Twitterï¼š[@JEEP7ll](https://twitter.com/JEEP7ll)
- Sina Weibo: [@JEEP-711](https://weibo.com/JEEP511)
- GeekParkHub GithubHomeï¼š<https://github.com/geekparkhub>
- GeekParkHub GiteeHomeï¼š<https://gitee.com/geekparkhub>
- Blog GardenHomeï¼š<http://www.cnblogs.com/JEEP711/>
- W3C/BlogHomeï¼š<https://www.w3cschool.cn/jeep711blog/>
- CSDN/BlogHomeï¼š<http://blog.csdn.net/jeep911>
- 51CTO/BlogHomeï¼š<http://jeep711.blog.51cto.com/>
- **`Official Public Email`**
- Group Emailï¼š<geekparkhub@outlook.com> â€”â€” <hackerparkhub@outlook.com> â€”â€” <hackerpark@hotmail.com>
- User Emailï¼š<jeep711.home.@gmail.com> â€”â€” <jeep-711@outlook.com>
- System Emailï¼š<systemhub-711@outlook.com>
- Service Emailï¼š<servicehub-711@outlook.com>



### æåŠ© é¡¹ç›®çš„å‘å±•ç¦»ä¸å¼€ä½ çš„æ”¯æŒ,è¯·å¼€å‘è€…å–æ¯â˜•Coffeeâ˜•å§!
![enter image description here](https://www.geekparkhub.com/docs/images/pay.jpg)

#### `è‡´è°¢`ï¼š
**æåŠ©æ—¶è¯·å¤‡æ³¨ UserName**
| ID| UserName | Donation | Money | Consume |
|:-| :-------- | --------:| :--: |:--: |
|1 | Object | WeChatPay |  5RMB | ä¸€æ¯å¯ä¹ | 
|2| æ³°è¿ªç†Šçœ‹æœˆäº®  | AliPay |  20RMB  | ä¸€æ¯å’–å•¡ | 
|3| ä¿®ä»™é“é•¿  | WeChatPay |  10RMB | ä¸¤æ¯å¯ä¹ | 


## License å¼€æºåè®®
[Apache License Version 2.0](https://github.com/geekparkhub/geekparkhub.github.io/blob/master/LICENSE)

---------