	
# å¤§æ•°æ®ç”Ÿæ€ç³»ç»Ÿ ä¿®ä»™ä¹‹é“ Hive Blog

@(2019-03-18)[ Docs Language:ç®€ä½“ä¸­æ–‡ & English|Programing Language:Hive|Website:[www.geekparkhub.com](https://www.geekparkhub.com/)|![OpenSource](https://img.shields.io/badge/Open%20Source-%E2%9D%A4-brightgreen.svg) | ![GitHub repo size in bytes](https://img.shields.io/github/repo-size/geekparkhub/geekparkhub.github.io.svg) | GeekDeveloper:[JEEP-711](https://github.com/jeep711)|Github:[github.com/geekparkhub](https://github.com/geekparkhub)|Gitee:[gitee.com/geekparkhub](https://gitee.com/geekparkhub) ]

##  ğŸ˜ Hive Technology ä¿®ä»™ä¹‹é“ ç‚¼æ°”åŒ–ç¥ ğŸ˜

![Alt text](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hive/hive.jpg)

- **æå®¢å®éªŒå®¤æ˜¯æå®¢å›½é™…å…¬å›­æ——ä¸‹ä¸ºæœªæ¥è€Œæ„å»ºçš„æå®¢ç¤¾åŒº;**
- **æˆ‘ä»¬æ­£åœ¨æ„å»ºä¸€ä¸ªæ´»è·ƒçš„å°ä¼—ç¤¾åŒº,æ±‡èšä¼—å¤šä¼˜ç§€å¼€å‘è€…ä¸è®¾è®¡å¸ˆ;**
- **å…³æ³¨æå…·åˆ›æ–°ç²¾ç¥çš„å‰æ²¿æŠ€æœ¯&åˆ†äº«äº¤æµ&é¡¹ç›®åˆä½œæœºä¼šç­‰äº’è”ç½‘è¡Œä¸šæœåŠ¡;**
- **Openå¼€æ”¾ `Â·` Creationåˆ›æƒ³ `|` OpenSourceå¼€æ”¾æˆå°±æ¢¦æƒ³ GeekParkHubå…±å»ºå‰æ‰€æœªè§!**
- **Future Vision : Establishment of the Geek Foundation;**
- **GeekParkHub GithubHome:**<https://github.com/geekparkhub>
- **GeekParkHub GiteeHome:**<https://gitee.com/geekparkhub>
- **æ¬¢è¿è´¡çŒ®`å„é¢†åŸŸå¼€æºé‡ç”ŸBlog`&`ç¬”è®°`&`æ–‡ç« `&`ç‰‡æ®µ`&`åˆ†äº«`&`åˆ›æƒ³`&`OpenSource Project`&`Code`&`Code Review`**
- ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ issues: [geekparkhub.github.io/issues](https://github.com/geekparkhub/geekparkhub.github.io/issues) ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ
- **`Official Public Email`**
- Group Emailï¼š<geekparkhub@outlook.com> â€”â€” <hackerparkhub@outlook.com> â€”â€” <hackerpark@hotmail.com>
- User Emailï¼š<jeep711.home.@gmail.com> â€”â€” <jeep-711@outlook.com>
- System Emailï¼š<systemhub-711@outlook.com>
- Service Emailï¼š<servicehub-711@outlook.com>


-------------------

[TOC]


## 1. Hive åŸºæœ¬æ¦‚è¿°
### 1.1 ğŸ¤” ä»€ä¹ˆæ˜¯Hive ğŸ¤”
> Hive ç”±FaceBookå¼€æºå¹¶ç”¨äºè§£å†³æµ·é‡ç»“æ„åŒ–æ—¥å¿—çš„æ•°æ®ç»Ÿè®¡åˆ†æ.
> 
> Hiveæ˜¯åŸºäºHadoopçš„ä¸€ä¸ªæ•°æ®ä»“åº“å·¥å…·,å¯ä»¥å°†ç»“æ„åŒ–çš„æ•°æ®æ–‡ä»¶æ˜ å°„ä¸ºä¸€å¼ æ•°æ®è¡¨,å¹¶æä¾›ç±»SQLæŸ¥è¯¢åŠŸèƒ½.
> 
> æœ¬è´¨æ˜¯: å°†HQLè½¬åŒ–æˆMapReduceç¨‹åº.
> ![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hive/start_001.jpg)
> 
> 1.Hiveå¤„ç†çš„æ•°æ®å­˜å‚¨åœ¨HDFS.
> 
> 2.Hiveåˆ†ææ•°æ®åº•å±‚çš„å®ç°æ˜¯MapReduce.
> 
> 3.æ‰§è¡Œç¨‹åºè¿è¡Œåœ¨Yarnä¸Š.

### 1.1.2 Hive ç‰¹æ€§
> Hiveä½œä¸ºæ•°æ®ä»“åº“è½¯ä»¶,ä½¿ç”¨ç±»SQLçš„HiveQLè¯­è¨€å®ç°æ•°æ®æŸ¥è¯¢,æ‰€æœ‰Hiveæ•°æ®å‡å­˜å‚¨åœ¨Hadoopåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿä¸­,Hiveå…·æœ‰ä»¥ä¸‹ç‰¹å¾.
> 
> ä½¿ç”¨HiveQLä»¥ç±»ä¼¼SQLæŸ¥è¯¢æ–¹å¼è½»æ¾è®¿é—®æ•°æ®,å°†HQLæŸ¥è¯¢è½¬æ¢ä¸ºMapReduceçš„ä»»åŠ¡åœ¨Hadoopé›†ç¾¤ä¸Šæ‰§è¡Œ,å®ŒæˆETL(æå– / è½¬æ¢ / åŠ è½½ / æŠ¥è¡¨ / æ•°æ®åˆ†æ)ç­‰æ•°æ®ä»“åº“ä»»åŠ¡.
> 
> å¤šç§æ–‡ä»¶æ ¼å¼çš„å…ƒæ•°æ®æœåŠ¡,åŒ…æ‹¬TextFile / SequuenceFile / RCFile / ORCFile,å…¶ä¸­é»˜è®¤æ ¼å¼ä¸ºTextFile.
> 
> ç›´æ¥è®¿é—®HDFSæ–‡ä»¶æˆ–å…¶ä»–æ•°æ®å­˜å‚¨ç³»ç»Ÿ(å¦‚: HBase)ä¸­çš„æ–‡ä»¶.
> 
> æ”¯æŒMapReduce / Teza / Spark ç­‰å¤šç§è®¡ç®—å¼•æ“,å¼€å‘è€…å¯æ ¹æ®ä¸åŒçš„æ•°æ®å¤„ç†åœºæ™¯é€‰æ‹©åˆé€‚çš„è®¡ç®—å¼•æ“.
> 
> æ”¯æŒHPL/SQLç¨‹åºè¯­è¨€,HPL/SQLæ˜¯ä¸€ç§æ··åˆå¼‚æ„çš„è¯­è¨€,å¯ä»¥ç†è§£å‡ ä¹ä»»ä½•ç°æœ‰çš„è¿‡ç¨‹æ€§SQLè¯­è¨€çš„è¯­æ³•å’Œè¯­ä¹‰,æœ‰åŠ©äºå°†ä¼ ç»Ÿæ•°æ®ä»“åº“çš„ä¸šåŠ¡é€»è¾‘è¿ç§»åˆ°Hadoopä¸Š,åœ¨Hadoopä¸Šå®ç°ETLæµç¨‹çš„æœ‰æ•ˆæ–¹å¼.
> 
> å¯ä»¥é€šè¿‡HiveLLAP,Yarnè¿›è¡Œç§’çº§åˆ«çš„æŸ¥è¯¢æ£€ç´¢,LLAPç»“åˆäº†æŒä¹…æŸ¥è¯¢æœåŠ¡å™¨å’Œä¼˜åŒ–çš„å†…å­˜ç¼“å­˜,ä½¿Hiveèƒ½å¤Ÿç«‹å³å¯åŠ¨æŸ¥è¯¢,é¿å…ä¸å¿…è¦çš„ç£ç›˜å¼€é”€,æä¾›è¾ƒä½³çš„æŸ¥è¯¢æ£€ç´¢æ•ˆç‡.


### 1.1.3 Hive åº”ç”¨åœºæ™¯
> Hiveæ„å»ºåœ¨Hadoopæ–‡ä»¶ç³»ç»Ÿä¹‹ä¸Š,Hiveä¸æä¾›å®æ—¶çš„æŸ¥è¯¢å’ŒåŸºäºè¡Œçº§æ•°æ®çš„æ›´æ–°æ“ä½œ,ä¸é€‚åˆéœ€è¦ä½å»¶æ—¶ä½œç”¨çš„åº”ç”¨,å¦‚è”æœºäº‹åŠ¡å¤„ç†ç›¸å…³åº”ç”¨.
| ç±»åˆ«       | å…·ä½“åº”ç”¨åœºæ™¯ |
| :-------- | :--------:|
| æ•°æ®æŒ–æ˜    |   ç”¨æˆ·è¡Œä¸ºåˆ†æ / å…´è¶£åˆ†åŒº / åŒºåŸŸå±•ç¤º |
| éå®æ—¶åˆ†ææŒ–æ˜    |   æ—¥å¿—åˆ†æ / æ–‡æœ¬åˆ†æ |
| æ•°æ®æ±‡æ€»   |   ç”¨æˆ·ç‚¹å‡»é‡ç»Ÿè®¡ / æµé‡ç»Ÿè®¡  |
| æ•°æ®ä»“åº“   |   æ•°æ®æŠ½å– / æ•°æ®åŠ è½½ / æ•°æ®è½¬æ¢ |

### 1.2 HIve ä¼˜ç¼ºç‚¹
#### ä¼˜ç‚¹
> 1.æ“ä½œæ¥å£é‡‡ç”¨ç±»SQLè¯­æ³•,æä¾›å¿«é€Ÿå¼€å‘çš„èƒ½åŠ›(ç®€å•å®¹æ˜“ä¸Šæ‰‹).
> 2.é¿å…äº†å»å†™MapReduce,å‡å°‘å¼€å‘äººå‘˜çš„å­¦ä¹ æˆæœ¬.
> 3.Hiveçš„æ‰§è¡Œå»¶è¿Ÿæ¯”è¾ƒé«˜,å› æ­¤Hiveå¸¸ç”¨äºæ•°æ®åˆ†æ,å¯¹å®æ—¶æ€§è¦æ±‚ä¸é«˜çš„åœºåˆ.
> 4.Hiveä¼˜åŠ¿åœ¨äºå¤„ç†å¤§æ•°æ®,å¯¹äºå¤„ç†å°æ•°æ®æ²¡æœ‰ä¼˜åŠ¿,å› ä¸ºHiveçš„æ‰§è¡Œå»¶è¿Ÿæ¯”è¾ƒé«˜.
> 5.Hiveæ”¯æŒå¼€å‘è€…è‡ªå®šä¹‰å‡½æ•°,å¼€å‘è€…å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚æ¥å®ç°è‡ªå·±çš„å‡½æ•°.
#### ç¼ºç‚¹
> 1.Hiveçš„HQLè¡¨è¾¾èƒ½åŠ›æœ‰é™
> (1) è¿­ä»£å¼ç®—æ³•æ— æ³•è¡¨è¾¾.
> (2) æ•°æ®æŒ–æ˜æ–¹é¢ä¸æ“…é•¿.
> 
> 2.Hiveçš„æ•ˆç‡æ¯”è¾ƒä½
> (1) Hiveè‡ªåŠ¨ç”Ÿæˆçš„MapReduceä½œä¸š,é€šå¸¸æƒ…å†µä¸‹ä¸å¤Ÿæ™ºèƒ½åŒ–.
> (2) Hiveè°ƒä¼˜æ¯”è¾ƒå›°éš¾,ç²’åº¦è¾ƒç²—.

### 1.3 HIve æ¶æ„åŸç† ğŸ¤”ğŸ¤”ğŸ¤”

![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hive/start_002.jpg)

> Hiveé€šè¿‡ç»™å¼€å‘è€…æä¾›çš„ä¸€ç³»åˆ—äº¤äº’æ¥å£,æ¥æ”¶åˆ°å¼€å‘è€…çš„æŒ‡ä»¤(SQL),ä½¿ç”¨è‡ªå·±çš„Driver,ç»“åˆå…ƒæ•°æ®(MetaStore),å°†è¿™äº›æŒ‡ä»¤ç¿»è¯‘æˆMapReduce,æäº¤åˆ°Hadoopä¸­æ‰§è¡Œ,æœ€å,å°†æ‰§è¡Œè¿”å›çš„ç»“æœè¾“å‡ºåˆ°å¼€å‘è€…äº¤äº’æ¥å£.
> 
#### 1.ç”¨æˆ·æ¥å£: Client
> CLI (Hive Shell) / JDBC/ODBC (Javaè®¿é—®Hive) / WEBUI (æµè§ˆå™¨è®¿é—®Hive).
#### 2.å…ƒæ•°æ®: Metastore
> å…ƒæ•°æ®åŒ…æ‹¬: è¡¨åã€è¡¨æ‰€å±çš„æ•°æ®åº“(é»˜è®¤æ˜¯default)ã€è¡¨çš„æ‹¥æœ‰è€…,åˆ—/åˆ†åŒºå­—æ®µ/è¡¨çš„ç±»å‹(æ˜¯å¦æ˜¯å¤–éƒ¨è¡¨),è¡¨çš„æ•°æ®æ‰€åœ¨ç›®å½•ç­‰.
> 
> é»˜è®¤å­˜å‚¨åœ¨è‡ªå¸¦çš„derbyæ•°æ®åº“ä¸­,æ¨èä½¿ç”¨MySQLå­˜å‚¨Metastore.
#### 3.Hadoop
> ä½¿ç”¨HDFSè¿›è¡Œå­˜å‚¨,ä½¿ç”¨MapReduceè¿›è¡Œè®¡ç®—.
#### 4.é©±åŠ¨å™¨: Driver
> (1) è§£æå™¨(SQL  Parser): å°†SQLå­—ç¬¦ä¸²è½¬æ¢æˆæŠ½è±¡è¯­æ³•æ ‘AST,è¿™ä¸€æ­¥ä¸€èˆ¬éƒ½ç”¨ç¬¬ä¸‰æ–¹å·¥å…·åº“å®Œæˆ,æ¯”å¦‚antlr,å¯¹ASTè¿›è¡Œè¯­æ³•åˆ†æ,æ¯”å¦‚è¡¨æ˜¯å¦å­˜åœ¨ã€å­—æ®µæ˜¯å¦å­˜åœ¨ã€SQLè¯­ä¹‰æ˜¯å¦æœ‰è¯¯.
> 
> (2) ç¼–è¯‘å™¨(Physical Plan): å°†ASTç¼–è¯‘ç”Ÿæˆé€»è¾‘æ‰§è¡Œè®¡åˆ’.
> 
> (3) ä¼˜åŒ–å™¨(Query Optimizer): å¯¹é€»è¾‘æ‰§è¡Œè®¡åˆ’è¿›è¡Œä¼˜åŒ–.
> 
> (4) æ‰§è¡Œå™¨(Execution): æŠŠé€»è¾‘æ‰§è¡Œè®¡åˆ’è½¬æ¢æˆå¯ä»¥è¿è¡Œçš„ç‰©ç†è®¡åˆ’,å¯¹äºHiveæ¥è¯´,å°±æ˜¯MR & Spark.

### 1.4 HIve & æ•°æ®åº“æ¯”è¾ƒ
> ç”±äºHiveé‡‡ç”¨äº†ç±»ä¼¼SQLçš„æŸ¥è¯¢è¯­è¨€HQL(Hive Query Language),å› æ­¤å¾ˆå®¹æ˜“å°†Hiveç†è§£ä¸ºæ•°æ®åº“.
> 
> å…¶å®ä»ç»“æ„ä¸Šæ¥çœ‹,Hiveå’Œæ•°æ®åº“é™¤äº†æ‹¥æœ‰ç±»ä¼¼çš„æŸ¥è¯¢è¯­è¨€,å†æ— ç±»ä¼¼ä¹‹å¤„,æ•°æ®åº“å¯ä»¥ç”¨åœ¨Onlineçš„åº”ç”¨ä¸­,ä½†æ˜¯Hiveæ˜¯ä¸ºæ•°æ®ä»“åº“è€Œè®¾è®¡çš„,æ¸…æ¥šè¿™ä¸€ç‚¹,æœ‰åŠ©äºä»åº”ç”¨è§’åº¦ç†è§£Hiveçš„ç‰¹æ€§.
#### 1.4.1 æŸ¥è¯¢è¯­è¨€
> ç”±äºSQLè¢«å¹¿æ³›çš„åº”ç”¨åœ¨æ•°æ®ä»“åº“ä¸­,å› æ­¤,ä¸“é—¨é’ˆå¯¹Hiveçš„ç‰¹æ€§è®¾è®¡äº†ç±»SQLçš„æŸ¥è¯¢è¯­è¨€HQL,ç†Ÿæ‚‰SQLå¼€å‘çš„å¼€å‘è€…å¯ä»¥å¾ˆæ–¹ä¾¿çš„ä½¿ç”¨Hiveè¿›è¡Œå¼€å‘.
#### 1.4.2 æ•°æ®å­˜å‚¨ä½ç½®
> Hiveæ˜¯å»ºç«‹åœ¨Hadoopä¹‹ä¸Šçš„,æ‰€æœ‰Hiveçš„æ•°æ®éƒ½æ˜¯å­˜å‚¨åœ¨HDFSä¸­çš„,è€Œæ•°æ®åº“åˆ™å¯ä»¥å°†æ•°æ®ä¿å­˜åœ¨å—è®¾å¤‡æˆ–è€…æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿä¸­.
#### 1.4.3 æ•°æ®æ›´æ–°
> ç”±äºHiveæ˜¯é’ˆå¯¹æ•°æ®ä»“åº“åº”ç”¨è®¾è®¡çš„,è€Œæ•°æ®ä»“åº“çš„å†…å®¹æ˜¯è¯»å¤šå†™å°‘çš„,å› æ­¤Hiveä¸­ä¸å»ºè®®å¯¹æ•°æ®çš„æ”¹å†™,æ‰€æœ‰çš„æ•°æ®éƒ½æ˜¯åœ¨åŠ è½½çš„æ—¶å€™ç¡®å®šå¥½çš„.
> 
> è€Œæ•°æ®åº“ä¸­çš„æ•°æ®é€šå¸¸æ˜¯éœ€è¦ç»å¸¸è¿›è¡Œä¿®æ”¹çš„,å› æ­¤å¯ä»¥ä½¿ç”¨`INSERTINTO...VALUES`æ·»åŠ æ•°æ®,ä½¿ç”¨`UPDATE...SET`ä¿®æ”¹æ•°æ®.
#### 1.4.4 ç´¢å¼•
> Hiveåœ¨åŠ è½½æ•°æ®çš„è¿‡ç¨‹ä¸­ä¸ä¼šå¯¹æ•°æ®è¿›è¡Œä»»ä½•å¤„ç†,ç”šè‡³ä¸ä¼šå¯¹æ•°æ®è¿›è¡Œæ‰«æ,å› æ­¤ä¹Ÿæ²¡æœ‰å¯¹æ•°æ®ä¸­çš„æŸäº›Keyå»ºç«‹ç´¢å¼•.
> 
> Hiveè¦è®¿é—®æ•°æ®ä¸­æ»¡è¶³æ¡ä»¶çš„ç‰¹å®šå€¼æ—¶,éœ€è¦æš´åŠ›æ‰«ææ•´ä¸ªæ•°æ®,å› æ­¤è®¿é—®å»¶è¿Ÿè¾ƒé«˜.
> 
> ç”±äºMapReduceçš„å¼•å…¥,Hiveå¯ä»¥å¹¶è¡Œè®¿é—®æ•°æ®,å› æ­¤å³ä½¿æ²¡æœ‰ç´¢å¼•,å¯¹äºå¤§æ•°æ®é‡çš„è®¿é—®,Hiveä»ç„¶å¯ä»¥ä½“ç°å‡ºä¼˜åŠ¿.
> 
> æ•°æ®åº“ä¸­,é€šå¸¸ä¼šé’ˆå¯¹ä¸€ä¸ªæˆ–è€…å‡ ä¸ªåˆ—å»ºç«‹ç´¢å¼•,å› æ­¤å¯¹äºå°‘é‡çš„ç‰¹å®šæ¡ä»¶çš„æ•°æ®çš„è®¿é—®,æ•°æ®åº“å¯ä»¥æœ‰å¾ˆé«˜çš„æ•ˆç‡,è¾ƒä½çš„å»¶è¿Ÿ,ç”±äºæ•°æ®çš„è®¿é—®å»¶è¿Ÿè¾ƒé«˜,å†³å®šäº†Hiveä¸é€‚åˆåœ¨çº¿æ•°æ®æŸ¥è¯¢.
#### 1.4.5 æ‰§è¡Œ
> Hiveä¸­å¤§å¤šæ•°æŸ¥è¯¢çš„æ‰§è¡Œæ˜¯é€šè¿‡Hadoopæä¾›çš„MapReduceæ¥å®ç°çš„,è€Œæ•°æ®åº“é€šå¸¸æœ‰è‡ªå·±çš„æ‰§è¡Œå¼•æ“.
#### 1.4.6 æ‰§è¡Œå»¶è¿Ÿ
> Hiveåœ¨æŸ¥è¯¢æ•°æ®çš„æ—¶å€™,ç”±äºæ²¡æœ‰ç´¢å¼•,éœ€è¦æ‰«ææ•´ä¸ªæ•°æ®è¡¨,å› æ­¤å»¶è¿Ÿè¾ƒé«˜,å¦å¤–ä¸€ä¸ªå¯¼è‡´Hiveæ‰§è¡Œå»¶è¿Ÿé«˜çš„å› ç´ æ˜¯MapReduceæ¡†æ¶.
> 
> ç”±äºMapReduceæœ¬èº«å…·æœ‰è¾ƒé«˜çš„å»¶è¿Ÿ,å› æ­¤åœ¨åˆ©ç”¨MapReduceæ‰§è¡ŒHiveæŸ¥è¯¢æ—¶,ä¹Ÿä¼šæœ‰è¾ƒé«˜çš„å»¶è¿Ÿ,ç›¸å¯¹çš„æ•°æ®åº“çš„æ‰§è¡Œå»¶è¿Ÿè¾ƒä½,å½“ç„¶,è¿™ä¸ªä½æ˜¯æœ‰æ¡ä»¶çš„,å³æ•°æ®è§„æ¨¡è¾ƒå°,å½“æ•°æ®è§„æ¨¡å¤§åˆ°è¶…è¿‡æ•°æ®åº“çš„å¤„ç†èƒ½åŠ›çš„æ—¶å€™,Hiveçš„å¹¶è¡Œè®¡ç®—æ˜¾ç„¶èƒ½ä½“ç°å‡ºä¼˜åŠ¿.
#### 1.4.7 å¯æ‰©å±•æ€§
> ç”±äºHiveæ˜¯å»ºç«‹åœ¨Hadoopä¹‹ä¸Šçš„,å› æ­¤Hiveçš„å¯æ‰©å±•æ€§æ˜¯å’ŒHadoopçš„å¯æ‰©å±•æ€§æ˜¯ä¸€è‡´çš„(ä¸–ç•Œä¸Šæœ€å¤§çš„Hadoopé›†ç¾¤åœ¨Yahoo!,2009å¹´çš„è§„æ¨¡åœ¨4000å°èŠ‚ç‚¹å·¦å³),è€Œæ•°æ®åº“ç”±äºACIDè¯­ä¹‰çš„ä¸¥æ ¼é™åˆ¶,æ‰©å±•è¡Œéå¸¸æœ‰é™,ç›®å‰æœ€å…ˆè¿›çš„å¹¶è¡Œæ•°æ®åº“Oracleåœ¨ç†è®ºä¸Šçš„æ‰©å±•èƒ½åŠ›ä¹Ÿåªæœ‰100å°å·¦å³.
#### 1.4.8 æ•°æ®è§„æ¨¡
> ç”±äºHiveå»ºç«‹åœ¨é›†ç¾¤ä¸Šå¹¶å¯ä»¥åˆ©ç”¨MapReduceå¹¶è¡Œè®¡ç®—,å› æ­¤å¯ä»¥æ”¯æŒå¾ˆå¤§è§„æ¨¡çš„æ•°æ®,å¯¹åº”çš„æ•°æ®åº“å¯ä»¥æ”¯æŒçš„æ•°æ®è§„æ¨¡è¾ƒå°.

## 2. Hive å®‰è£…éƒ¨ç½²
### 2.1 Hive Download Link
> 1.Hiveå®˜ç½‘: [hive.apache.org/](http://hive.apache.org/)
> 
> 2.Hiveæ–‡æ¡£: [cwiki.apache.org/confluence/display/Hive/](https://cwiki.apache.org/confluence/display/Hive/GettingStarted)
> 
> 3.Github: [github.com/apache/hive](https://github.com/apache/hive)
> 
> 4.Download Link: [archive.apache.org/dist/hive/](http://archive.apache.org/dist/hive/)
> 
> 5.ä»¥apache-hive-1.2.1-bin.tar.gz ç¨³å®šç‰ˆæœ¬ ä¸ºå®ä¾‹è¿›è¡Œå®‰è£….

#### 1. å°†apache-hive-1.2.1-bin.tar.gzä¸Šä¼ è‡³ linux system/opt/softwareç›®å½•ä¸‹
``` powershell
[root@systemhub711 ~]# cd /opt/software/
[root@systemhub711 software]# ll
total 526728
-rw-r--r--. 1 root root  92834839 Mar 24 23:51 apache-hive-1.2.1-bin.tar.gz
-rwxrwxrwx. 1 root root   9621331 Jan 14 09:36 apache-tomcat-8.5.33.tar.gz
-rwxrwxrwx. 1 root root 212046774 Jan 24 20:37 hadoop-2.7.2.tar.gz
-rwxrwxrwx. 1 root root 189815615 Jan 14 10:22 jdk-8u162-linux-x64.tar.gz
-rwxrwxrwx. 1 root root  35042811 Jan 17 19:18 zookeeper-3.4.10.tar.gz
```
#### 2. è§£å‹apache-hive-1.2.1-bin.tar.gz è‡³ /opt/module/ç›®å½•ä¸‹
``` powershell
[root@systemhub711 software]# tar -zxvf apache-hive-1.2.1-bin.tar.gz -C /opt/module/
apache-hive-1.2.1-bin/NOTICE
apache-hive-1.2.1-bin/LICENSE
apache-hive-1.2.1-bin/README.txt
apache-hive-1.2.1-bin/RELEASE_NOTES.txt
apache-hive-1.2.1-bin/examples/files/emp.txt
apache-hive-1.2.1-bin/examples/files/type_evolution.avro
apache-hive-1.2.1-bin/examples/files/extrapolate_stats_partial.txt
apache-hive-1.2.1-bin/examples/files/lineitem.txt
```
#### 3. ä¿®æ”¹apache-hive-1.2.1-bin.tar.gzåŒ…åç§°æ›´æ”¹ä¸ºhive
``` powershell
[root@systemhub711 software]# cd ..
[root@systemhub711 opt]# cd module/
[root@systemhub711 module]# ll
total 20
drwxr-xr-x.  8 root root 4096 Mar 24 23:53 apache-hive-1.2.1-bin
drwxr-xr-x.  9 root root 4096 Feb 24 21:55 apache-tomcat
drwxr-xr-x. 12 root root 4096 Feb 27 14:24 hadoop
drwxr-xr-x.  8 uucp  143 4096 Dec 20  2017 jdk1.8.0_162
drwxr-xr-x. 10 1001 1001 4096 Mar 23  2017 zookeeper
[root@systemhub711 module]# mv apache-hive-1.2.1-bin hive
[root@systemhub711 module]# ll
total 20
drwxr-xr-x.  9 root root 4096 Feb 24 21:55 apache-tomcat
drwxr-xr-x. 12 root root 4096 Feb 27 14:24 hadoop
drwxr-xr-x.  8 root root 4096 Mar 24 23:53 hive
drwxr-xr-x.  8 uucp  143 4096 Dec 20  2017 jdk1.8.0_162
drwxr-xr-x. 10 1001 1001 4096 Mar 23  2017 zookeeper
[root@systemhub711 module]# 
```
#### 4. ä¿®æ”¹/opt/module/hive/confç›®å½•ä¸‹hive-env.sh.templateåç§°æ›´æ”¹ä¸ºhive-env.sh
``` powershell
[root@systemhub711 module]# cd /opt/module/hive/conf
[root@systemhub711 conf]# ll
total 188
-rw-rw-r--. 1 root root   1139 Apr 30  2015 beeline-log4j.properties.template
-rw-rw-r--. 1 root root 168431 Jun 19  2015 hive-default.xml.template
-rw-rw-r--. 1 root root   2378 Apr 30  2015 hive-env.sh.template
-rw-rw-r--. 1 root root   2662 Apr 30  2015 hive-exec-log4j.properties.template
-rw-rw-r--. 1 root root   3050 Apr 30  2015 hive-log4j.properties.template
-rw-rw-r--. 1 root root   1593 Apr 30  2015 ivysettings.xml
[root@systemhub711 conf]# mv hive-env.sh.template hive-env.sh
[root@systemhub711 conf]# ll
total 188
-rw-rw-r--. 1 root root   1139 Apr 30  2015 beeline-log4j.properties.template
-rw-rw-r--. 1 root root 168431 Jun 19  2015 hive-default.xml.template
-rw-rw-r--. 1 root root   2378 Apr 30  2015 hive-env.sh
-rw-rw-r--. 1 root root   2662 Apr 30  2015 hive-exec-log4j.properties.template
-rw-rw-r--. 1 root root   3050 Apr 30  2015 hive-log4j.properties.template
-rw-rw-r--. 1 root root   1593 Apr 30  2015 ivysettings.xml
[root@systemhub711 conf]# 
```

#### 5. é…ç½®ç¯å¢ƒå˜é‡
> åœ¨systemä¸­é…ç½®HIVE_HOME
``` powershell
[root@systemhub711 hive]# vim /etc/profile
```
``` powershell

## SET JAVA_HOME
JAVA_HOME=/opt/module/jdk1.8.0_162
PATH=/opt/module/jdk1.8.0_162/bin:$PATH
export JAVA_HOME PATH

## SET TOMCAT_HOME
TOMCAT_HOME=/opt/module/apache-tomcat
export TOMCAT_HOME

## SET HADOOP_HOME
HADOOP_HOME=/opt/module/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin

## SET HIVE_HOME
export HIVE_HOME=/opt/module/hive
export PATH=$PATH:$HIVE_HOME/bin
```
> é…ç½®å®Œæ¯•,æŒ‰ESC,è¾“å…¥:wq ä¿å­˜å¹¶é€€é€€å‡º.
> 
> æ›´æ–°é…ç½®ä¿¡æ¯
``` powershell
[root@systemhub711 hive]# source /etc/profile
```
> åœ¨hive-env.shé…ç½®HADOOP_HOMEè·¯å¾„ & é…ç½®HIVE_CONF_DIRè·¯å¾„
``` powershell
[root@systemhub711 conf]# echo $HADOOP_HOME
/opt/module/hadoop
[root@systemhub711 conf]# vim hive-env.sh
```
> é…ç½®å®Œæ¯•,æŒ‰ESC,è¾“å…¥:wq ä¿å­˜å¹¶é€€é€€å‡º.
``` powershell
#   fi
# fi

# The heap size of the jvm stared by hive shell script can be controlled via:
#
# export HADOOP_HEAPSIZE=1024
#
# Larger heap size may be required when running queries over large number of files or partitions. 
# By default hive shell scripts use a heap size of 256 (MB).  Larger heap size would also be 
# appropriate for hive server (hwi etc).

# Set HADOOP_HOME to point to a specific hadoop install directory
export HADOOP_HOME=/opt/module/hadoop

# Hive Configuration Directory can be controlled by:
export HIVE_CONF_DIR=/opt/module/hive/conf
```

### 2.2 å¯åŠ¨Hadoopé›†ç¾¤
#### 2.2.3 å¯åŠ¨ HDFS Service
``` powershell
[root@systemhub511 ~]# cd /opt/module/hadoop/
[root@systemhub511 hadoop]# start-dfs.sh
```
#### 2.2.4 å¯åŠ¨ Yarn Service
``` powershell
[root@systemhub611 ~]# cd /opt/module/hadoop/
[root@systemhub611 hadoop]# start-yarn.sh
```
#### 2.2.5 jps æŸ¥çœ‹é›†ç¾¤è¿›ç¨‹
``` powershell
[root@systemhub511 hadoop]# jps
11121 NameNode
15719 Jps
11323 DataNode
15118 NodeManager
[root@systemhub511 hadoop]# 

[root@systemhub611 hadoop]# jps
9106 NodeManager
5865 DataNode
10650 Jps
7629 ResourceManager
[root@systemhub611 hadoop]# 

[root@systemhub711 hadoop]# jps
3089 Jps
30667 DataNode
1629 NodeManager
30974 SecondaryNameNode
[root@systemhub711 hadoop]# 
```
#### 2.2.6 åœ¨HDFSä¸Šåˆ›å»ºç›®å½•
> åˆ›å»º/tmpå’Œ/user/hive/warehouseä¸¤ä¸ªç›®å½•å¹¶ä¿®æ”¹åŒç»„æƒé™ä¸ºå¯å†™
```
[root@systemhub611 hadoop]# hadoop fs -mkdir /tmp
[root@systemhub511 hadoop]# hadoop fs -mkdir -p  /user/hive/warehouse
```
```
[root@systemhub511 hadoop]# hadoop fs -chmod 777 /tmp
[root@systemhub511 hadoop]# hadoop fs -chmod 777 /user/hive/warehouse
```

#### 2.2.7 HiveåŸºæœ¬æ“ä½œ
##### 2.2.7.1 å¯åŠ¨ Hive Service
``` powershell
[root@systemhub711 hive]# bin/hive
Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
hive> 
```
##### 2.2.7.2 æŸ¥çœ‹æ•°æ®åº“
```
hive> show databases;
OK
default
Time taken: 0.039 seconds, Fetched: 1 row(s) 
```
##### 2.2.7.3 æ‰“å¼€é»˜è®¤æ•°æ®åº“
```
hive> use default;
OK
Time taken: 0.06 seconds
hive> 
```
##### 2.2.7.4 æ˜¾ç¤ºdefaultæ•°æ®åº“ä¸­çš„è¡¨
```
hive> show tables;
OK
Time taken: 0.136 seconds
hive> 
```
##### 2.2.7.5 åˆ›å»ºä¸€å¼ è¡¨
```
hive> create table test(id int,name string);
OK
Time taken: 0.584 seconds
```
##### 2.2.7.6 æ˜¾ç¤ºæ•°æ®åº“ä¸­æœ‰å‡ å¼ è¡¨
```
hive> show tables;
OK
test
Time taken: 0.043 seconds, Fetched: 1 row(s)
hive> 
```
##### 2.2.7.7 æŸ¥çœ‹è¡¨çš„ç»“æ„
```
hive> desc test;
OK
id                      int                                         
name                    string                                      
Time taken: 0.181 seconds, Fetched: 2 row(s)
hive> 
```
##### 2.2.7.8 å‘è¡¨ä¸­æ’å…¥æ•°æ®
```
hive> insert into test values(1,"TestUser001");
Query ID = root_20190325104557_f36e7f6e-0254-4e4e-9216-60f08042dabb
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1553477836311_0001, Tracking URL = http://systemhub611:8088/proxy/application_1553477836311_0001/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553477836311_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
2019-03-25 10:46:18,198 Stage-1 map = 0%,  reduce = 0%
2019-03-25 10:46:26,679 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.96 sec
MapReduce Total cumulative CPU time: 1 seconds 960 msec
Ended Job = job_1553477836311_0001
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to: hdfs://systemhub511:9000/user/hive/warehouse/test/.hive-staging_hive_2019-03-25_10-45-57_843_1729594574229184317-1/-ext-10000
Loading data to table default.test
Table default.test stats: [numFiles=1, numRows=1, totalSize=14, rawDataSize=13]
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1   Cumulative CPU: 1.96 sec   HDFS Read: 3566 HDFS Write: 82 SUCCESS
Total MapReduce CPU Time Spent: 1 seconds 960 msec
OK
Time taken: 31.477 seconds
hive> 
```
##### 2.2.7.9 æŸ¥è¯¢è¡¨ä¸­æ•°æ®
```
hive> select * from test;
OK
1       TestUser001
Time taken: 0.144 seconds, Fetched: 1 row(s)
hive>
```
##### 2.2.7.10 é€€å‡ºhive
```
hive> quit;
[root@systemhub711 hive]# 
```

#### 2.2.8 Hiveå®æ“æ¡ˆä¾‹
##### 2.2.8.1 å°†æœ¬åœ°æ–‡ä»¶å¯¼å…¥Hiveä¸­
> éœ€æ±‚: å°†æœ¬åœ° /opt/module/datas/test.txt,è¿™ä¸ªç›®å½•ä¸‹çš„æ•°æ®å¯¼å…¥åˆ°hiveçš„test(id int, name string)æ•°æ®è¡¨ä¸­.
###### 1.æ•°æ®å‡†å¤‡
> åœ¨/opt/module/ç›®å½•ä¸‹åˆ›å»ºdatas
> 
> åœ¨/opt/module/datas/ç›®å½•ä¸‹åˆ›å»ºtest.txtæ–‡ä»¶å¹¶æ·»åŠ æ•°æ®,ä»¥Tabé”®é—´éš”
```
[root@systemhub711 ~]# cd /opt/module/
[root@systemhub711 module]# mkdir datas
[root@systemhub711 module]# cd datas/
[root@systemhub711 datas]# touch test.txt
[root@systemhub711 datas]# ll
total 0
-rw-r--r--. 1 root root 0 Mar 25 16:02 test.txt
[root@systemhub711 datas]#
[root@systemhub711 datas]# vim test.txt
```
```
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
```
###### 2.å¯åŠ¨ Hadoopé›†ç¾¤ & Hive
```
[root@systemhub711 ~]# cd /opt/module/hive/
[root@systemhub711 hive]# bin/hive
Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
hive>
```
###### 3.åˆ›å»ºtest001æ•°æ®è¡¨,å¹¶å£°æ˜æ–‡ä»¶åˆ†éš”ç¬¦"\t"
```
hive> create table test001(id int,name string) row format delimited fields terminated by "\t";
OK
Time taken: 0.222 seconds
hive> 
```
###### 4.å°†æ–‡ä»¶åŠ è½½åˆ°æ•°æ®è¡¨ä¸­
```
hive> load data local inpath "/opt/module/datas/test.txt" into table test001;
Loading data to table default.test
Table default.test stats: [numFiles=1, totalSize=56]
OK
Time taken: 0.479 seconds
hive>
```
###### 5.æŸ¥è¯¢æ•°æ®
```
hive> select * from test;
OK
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
Time taken: 0.076 seconds, Fetched: 4 row(s)
hive> 
```
##### 2.2.8.2 MySqlå®‰è£…
###### 1.å®‰è£…åŒ…å‡†å¤‡
> æŸ¥çœ‹mysqlæ˜¯å¦å®‰è£…,å¦‚æœå®‰è£…äº†,å¸è½½mysql.
```
[root@systemhub711 ~]# rpm -qa|grep mysql
mysql-libs-5.1.71-1.el6.x86_64
[root@systemhub711 ~]# rpm -e --nodeps mysql-libs-5.1.71-1.el6.x86_64
[root@systemhub711 ~]# 
```
> è§£å‹mysql-libs.zipæ–‡ä»¶åˆ°å½“å‰ç›®å½•.
```
[root@systemhub711 ~]# cd /opt/software/
[root@systemhub711 software]# unzip mysql-libs.zip
Archive:  mysql-libs.zip
   creating: mysql-libs/
  inflating: mysql-libs/MySQL-client-5.6.24-1.el6.x86_64.rpm  
  inflating: mysql-libs/mysql-connector-java-5.1.27.tar.gz  
  inflating: mysql-libs/MySQL-server-5.6.24-1.el6.x86_64.rpm  
```

##### 2.2.8.3 å®‰è£…MySqlæœåŠ¡ç«¯
> å®‰è£…mysqlæœåŠ¡ç«¯
```
[root@systemhub711 mysql-libs]# rpm -ivh MySQL-server-5.6.24-1.el6.x86_64.rpm
Preparing...                ########################################### [100%]
   1:MySQL-server           ########################################### [100%]
```
> å®‰è£…mysqlå®¢æˆ·ç«¯
```
[root@systemhub711 mysql-libs]# rpm -ivh MySQL-client-5.6.24-1.el6.x86_64.rpm
Preparing...                ########################################### [100%]
   1:MySQL-client           ########################################### [100%]
[root@systemhub711 mysql-libs]# 
```
> æŸ¥çœ‹äº§ç”Ÿçš„éšæœºå¯†ç 
```
[root@systemhub711 mysql-libs]# cat /root/.mysql_secret
# The random password set for the root user at Mon Mar 25 17:28:10 2019 (local time): 3krFauiObIJZG_xd
[root@systemhub711 mysql-libs]# 
```
> æŸ¥çœ‹mysqlçŠ¶æ€ å¹¶ å¼€å¯æœåŠ¡
```
[root@systemhub711 mysql-libs]# service mysql status
MySQL is not running                                       [å¤±è´¥]
[root@systemhub711 mysql-libs]# service mysql start
Starting MySQL..                                           [ç¡®å®š]
```
> ç™»å½•mysql
```
[root@systemhub711 mysql-libs]# mysql -uroot -p3krFauiObIJZG_xd
Warning: Using a password on the command line interface can be insecure.
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 2
Server version: 5.6.24

Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
mysql> 
```
> è®¾ç½®è‡ªå®šä¹‰ç™»å½•å¯†ç 
```
mysql> set password=password("000000");
Query OK, 0 rows affected (0.01 sec)
mysql> 
```
##### 2.2.8.4 MySqlæ— ä¸»æœºé…ç½®
> é…ç½®åªè¦æ˜¯rootç”¨æˆ·+password,å³å¯åœ¨ä»»ä½•ä¸»æœºä¸Šéƒ½èƒ½ç™»å½•MySQLæ•°æ®åº“.
> 
> ç™»å½•mysql
```
[root@systemhub711 mysql-libs]# mysql -uroot -p
Enter password: 
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 3
Server version: 5.6.24 MySQL Community Server (GPL)

Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
mysql> 
```
> æ˜¾ç¤ºå½“å‰æ•°æ®åº“
```
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| test               |
+--------------------+
4 rows in set (0.01 sec)

mysql> 
```
> è¿›å…¥mysqlæ•°æ®åº“
```
mysql> use mysql;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A
Database changed
mysql>
```
> æŸ¥è¯¢mysqlæ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨
```
mysql> show tables;
+---------------------------+
| Tables_in_mysql           |
+---------------------------+
| columns_priv              |
| db                        |
| event                     |
| func                      |
| general_log               |
| help_category             |
| help_keyword              |
| help_relation             |
| help_topic                |
| innodb_index_stats        |
| innodb_table_stats        |
| ndb_binlog_index          |
| plugin                    |
| proc                      |
| procs_priv                |
| proxies_priv              |
| servers                   |
| slave_master_info         |
| slave_relay_log_info      |
| slave_worker_info         |
| slow_log                  |
| tables_priv               |
| time_zone                 |
| time_zone_leap_second     |
| time_zone_name            |
| time_zone_transition      |
| time_zone_transition_type |
| user                      |
+---------------------------+
28 rows in set (0.00 sec)
mysql>
```
> æŸ¥è¯¢useræ•°æ®è¡¨
```
mysql> select User, Host, Password from user;
+------+--------------+-------------------------------------------+
| User | Host         | Password                                  |
+------+--------------+-------------------------------------------+
| root | localhost    | *032197AE5731D4664921A6CCAC7CFCE6A0698693 |
| root | systemhub711 | *DB2C3C3C317DE3F3FEFF12C9A60985CA29A7BBCD |
| root | 127.0.0.1    | *DB2C3C3C317DE3F3FEFF12C9A60985CA29A7BBCD |
| root | ::1          | *DB2C3C3C317DE3F3FEFF12C9A60985CA29A7BBCD |
+------+--------------+-------------------------------------------+
4 rows in set (0.01 sec)
mysql> 
```
> ä¿®æ”¹userè¡¨,æŠŠHostè¡¨å†…å®¹ä¿®æ”¹ä¸º`%`
```
mysql> update user set host='%' where host='localhost';
Query OK, 1 row affected (0.00 sec)
Rows matched: 1  Changed: 1  Warnings: 0

mysql> select User, Host, Password from user;
+------+--------------+-------------------------------------------+
| User | Host         | Password                                  |
+------+--------------+-------------------------------------------+
| root | %            | *032197AE5731D4664921A6CCAC7CFCE6A0698693 |
| root | systemhub711 | *DB2C3C3C317DE3F3FEFF12C9A60985CA29A7BBCD |
| root | 127.0.0.1    | *DB2C3C3C317DE3F3FEFF12C9A60985CA29A7BBCD |
| root | ::1          | *DB2C3C3C317DE3F3FEFF12C9A60985CA29A7BBCD |
+------+--------------+-------------------------------------------+
4 rows in set (0.00 sec)
mysql> 
```
> åˆ é™¤rootç”¨æˆ·çš„å…¶ä»–host
```
mysql> delete from user where Host='systemhub711';
Query OK, 1 row affected (0.00 sec)

mysql> delete from user where Host='127.0.0.1';
Query OK, 1 row affected (0.00 sec)

mysql> delete from user where Host='::1';
Query OK, 1 row affected (0.00 sec)

mysql> select User, Host, Password from user;
+------+------+-------------------------------------------+
| User | Host | Password                                  |
+------+------+-------------------------------------------+
| root | %    | *032197AE5731D4664921A6CCAC7CFCE6A0698693 |
+------+------+-------------------------------------------+
1 row in set (0.00 sec)
mysql> 
```
> åˆ·æ–°
```
mysql> flush privileges;
Query OK, 0 rows affected (0.00 sec)
mysql> 
```
> é€€å‡º
```
mysql> exit;
Bye
[root@systemhub711 mysql-libs]# 
```

##### 2.2.8.5 é…ç½®Metastoreåˆ°MySql
> 1.åœ¨/opt/module/hive/confç›®å½•ä¸‹åˆ›å»ºhive-site.xmlé…ç½®æ–‡ä»¶.
```
[root@systemhub711 ~]# cd /opt/module/hive/conf/
[root@systemhub711 conf]# touch hive-site.xml
[root@systemhub711 conf]# vim hive-site.xml
```
> 2.æ ¹æ®å®˜æ–¹æ–‡æ¡£é…ç½®å‚æ•°,æ‹·è´æ•°æ®åˆ°hive-site.xmlé…ç½®æ–‡ä»¶ä¸­ | [Hiveå®˜æ–¹é…ç½®æ–‡æ¡£](https://cwiki.apache.org/confluence/display/Hive/AdminManual+Metastore+Administration).
``` xml
<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
      <name>javax.jdo.option.ConnectionURL</name>
      <value>jdbc:mysql://systemhub711:3306/metastore?createDatabaseIfNotExist=true</value>
      <description>JDBC connect string for a JDBC metastore</description>
    </property>

    <property>
      <name>javax.jdo.option.ConnectionDriverName</name>
      <value>com.mysql.jdbc.Driver</value>
      <description>Driver class name for a JDBC metastore</description>
    </property>

    <property>
       <name>javax.jdo.option.ConnectionUserName</name>
       <value>root</value>
       <description>username to use against metastore database</description>
    </property>

    <property>
       <name>javax.jdo.option.ConnectionPassword</name>
       <value>000000</value>
       <description>passwordto use against metastore database</description>
    </property>

</configuration>
```
> é©±åŠ¨æ‹·è´
> å°†/opt/software/mysql-libsç›®å½•ä¸‹è§£å‹mysql-connector-java-5.1.27.tar.gzé©±åŠ¨åŒ….
```
[root@systemhub711 opt]# cd software/mysql-libs
[root@systemhub711 mysql-libs]# tar -zvxf mysql-connector-java-5.1.27.tar.gz
mysql-connector-java-5.1.27/
mysql-connector-java-5.1.27/docs/
mysql-connector-java-5.1.27/src/
mysql-connector-java-5.1.27/src/com/
mysql-connector-java-5.1.27/src/com/mysql/
mysql-connector-java-5.1.27/src/com/mysql/jdbc/
mysql-connector-java-5.1.27/src/com/mysql/jdbc/authentication/
```
> å°†mysql-connector-java-5.1.27-bin.jaråˆ°/opt/module/hive/lib/
```
[root@systemhub711 mysql-libs]# cd mysql-connector-java-5.1.27
[root@systemhub711 mysql-connector-java-5.1.27]# ll
total 1272
-rw-r--r--. 1 root root  47173 Oct 24  2013 build.xml
-rw-r--r--. 1 root root 222520 Oct 24  2013 CHANGES
-rw-r--r--. 1 root root  18122 Oct 24  2013 COPYING
drwxr-xr-x. 2 root root   4096 Mar 25 20:56 docs
-rw-r--r--. 1 root root 872303 Oct 24  2013 mysql-connector-java-5.1.27-bin.jar
-rw-r--r--. 1 root root  61423 Oct 24  2013 README
-rw-r--r--. 1 root root  63674 Oct 24  2013 README.txt
drwxr-xr-x. 7 root root   4096 Oct 24  2013 src
[root@systemhub711 mysql-connector-java-5.1.27]# cp mysql-connector-java-5.1.27-bin.jar /opt/module/hive/lib/
[root@systemhub711 mysql-connector-java-5.1.27]# cd /opt/module/hive/lib/
[root@systemhub711 lib]# ll
-rw-r--r--.  1 root root   872303 Mar 25 20:58 mysql-connector-java-5.1.27-bin.jar
```
> é…ç½®å®Œæ¯•å,å…ˆå¯åŠ¨MySQL,æŸ¥çœ‹æœ‰å‡ ä¸ªæ•°æ®åº“,ä¾ç„¶è¿˜æ˜¯å››ä¸ª.
```
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| test               |
+--------------------+
4 rows in set (0.01 sec)
mysql> 
```
> å†æ¬¡æ‰“å¼€å¤šä¸ªçª—å£,åˆ†åˆ«å¯åŠ¨hive.
```
[root@systemhub711 hive]# bin/hive

Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
hive>
```
> å¯åŠ¨hiveå,å›åˆ°MySQLçª—å£æŸ¥çœ‹æ•°æ®åº“,æ˜¾ç¤ºå¢åŠ äº†metastoreæ•°æ®åº“.
```
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| metastore          |
| mysql              |
| performance_schema |
| test               |
+--------------------+
5 rows in set (0.00 sec)
mysql> 
```
> å»metastoreæ•°æ®åº“ å–½ä¸€çœ¼.
```
mysql> use metastore;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A
Database changed
mysql> show tables;
+---------------------------+
| Tables_in_metastore       |
+---------------------------+
| BUCKETING_COLS            |
| CDS                       |
| COLUMNS_V2                |
| DATABASE_PARAMS           |
| DBS                       |
| FUNCS                     |
| FUNC_RU                   |
| GLOBAL_PRIVS              |
| PARTITIONS                |
| PARTITION_KEYS            |
| PARTITION_KEY_VALS        |
| PARTITION_PARAMS          |
| PART_COL_STATS            |
| ROLES                     |
| SDS                       |
| SD_PARAMS                 |
| SEQUENCE_TABLE            |
| SERDES                    |
| SERDE_PARAMS              |
| SKEWED_COL_NAMES          |
| SKEWED_COL_VALUE_LOC_MAP  |
| SKEWED_STRING_LIST        |
| SKEWED_STRING_LIST_VALUES |
| SKEWED_VALUES             |
| SORT_COLS                 |
| TABLE_PARAMS              |
| TAB_COL_STATS             |
| TBLS                      |
| VERSION                   |
+---------------------------+
29 rows in set (0.00 sec)
mysql>
```

##### 2.2.8.6 Hiveå¸¸ç”¨äº¤äº’å‘½ä»¤
###### 1. Hive å¸®åŠ©æŒ‡ä»¤
```
[root@systemhub711 hive]# bin/hive -help
usage: hive
 -d,--define <key=value>          Variable subsitution to apply to hive
                                  commands. e.g. -d A=B or --define A=B
    --database <databasename>     Specify the database to use
 -e <quoted-query-string>         SQL from command line
 -f <filename>                    SQL from files
 -H,--help                        Print help information
    --hiveconf <property=value>   Use value for given property
    --hivevar <key=value>         Variable subsitution to apply to hive
                                  commands. e.g. --hivevar A=B
 -i <filename>                    Initialization SQL file
 -S,--silent                      Silent mode in interactive shell
 -v,--verbose                     Verbose mode (echo executed SQL to the
                                  console)
[root@systemhub711 hive]# 
```

###### 2. -e ä¸è¿›å…¥hiveäº¤äº’çª—å£,å³å¯æ‰§è¡Œsqlè¯­å¥
```
[root@systemhub711 hive]# bin/hive -e "select * from test";

Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
OK
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
Time taken: 2.328 seconds, Fetched: 4 row(s)
[root@systemhub711 hive]# 
```

###### 3. -f æ‰§è¡Œè„šæœ¬ä¸­,æ‰§è¡Œsqlè¯­å¥
> åœ¨/opt/module/datasç›®å½•ä¸‹åˆ›å»º test_hivef.hqlæ–‡ä»¶
```
[root@systemhub711 hive]# cd ..
[root@systemhub711 module]# cd datas/
[root@systemhub711 datas]# touch test_hivef.hql
[root@systemhub711 datas]# ll
total 4
-rw-r--r--. 1 root root  0 Mar 25 22:24 test_hivef.hql
-rw-r--r--. 1 root root 56 Mar 25 16:46 test.txt
[root@systemhub711 datas]# vim test_hivef.hql
```
> æ–‡ä»¶ä¸­å†™å…¥æ­£ç¡®çš„sqlè¯­å¥
```
select * from test;
```
> æ‰§è¡Œæ–‡ä»¶ä¸­çš„sqlè¯­å¥
```
[root@systemhub711 datas]# cd /opt/module/hive/
[root@systemhub711 hive]# bin/hive -f /opt/module/datas/test_hivef.hql

Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
OK
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
Time taken: 2.012 seconds, Fetched: 4 row(s)
[root@systemhub711 hive]#
```
> æ‰§è¡Œæ–‡ä»¶ä¸­çš„sqlè¯­å¥å¹¶å°†ç»“æœå†™å…¥æ–‡ä»¶ä¸­
```
[root@systemhub711 hive]# bin/hive -f /opt/module/datas/test_hivef.hql > /opt/module/datas/test_hivef_result.txt

Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
OK
Time taken: 1.794 seconds, Fetched: 4 row(s)
[root@systemhub711 hive]# cat /opt/module/datas/test_hivef_result.txt
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
[root@systemhub711 hive]# 
```

##### 2.2.8.7 Hive å…¶ä»–å‘½ä»¤æ“ä½œ
###### 2.2.8.7.1 é€€å‡ºhiveçª—å£
> åœ¨æ–°ç‰ˆçš„oracleæ•°æ®åº“ä¸­ä¸¤ä¸ªé€€å‡ºæŒ‡ä»¤å·²ç»æ²¡æœ‰åŒºåˆ«äº†,åœ¨ä»¥å‰çš„ç‰ˆæœ¬æ˜¯æœ‰åŒºåˆ«.
> exit:å…ˆéšæ€§æäº¤æ•°æ®,å†é€€å‡º; quit:ä¸æäº¤æ•°æ®,é€€å‡º;
```
[root@systemhub711 hive]# bin/hive
Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
hive> quit;
[root@systemhub711 hive]# 
[root@systemhub711 hive]# bin/hive
Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
hive> exit;
[root@systemhub711 hive]# 
```
###### 2.2.8.7.2 åœ¨Hive CLIå‘½ä»¤çª—å£ä¸­æŸ¥çœ‹hdfsæ–‡ä»¶ç³»ç»Ÿ
```
hive> dfs -ls / ;
Found 3 items
drwxr-xr-x   - root supergroup          0 2019-01-27 14:35 /group
drwxrwxrwx   - root supergroup          0 2019-01-25 10:09 /tmp
drwxr-xr-x   - root supergroup          0 2019-01-25 09:58 /user
hive> 
```
###### 2.2.8.7.3 åœ¨Hive CLIå‘½ä»¤çª—å£ä¸­æŸ¥çœ‹hdfsæœ¬åœ°ç³»ç»Ÿ
```
hive> ! ls /opt/module;
apache-tomcat
datas
hadoop
hive
jdk1.8.0_162
zookeeper
hive> 
```
###### 2.2.8.7.4 æŸ¥çœ‹åœ¨Hiveä¸­è¾“å…¥æ‰€æœ‰å†å²å‘½ä»¤
> è¿›å…¥åˆ°å½“å‰ç”¨æˆ·çš„æ ¹ç›®å½•æ‰§è¡Œå†å²å‘½ä»¤.
```
[root@systemhub711 module]# cd
[root@systemhub711 ~]# cat .hivehistory
show databases;
show databases;
use default;
show tables;
create table test(id int,name string);
show tables;
insert into test(1,"TestUser001");
insert into test value(1,"TestUser001");
insert into test values(1,"TestUser001");
select * form test;
select * from test;
desc test;
quit;
load data local inpath "/opt/module/datas/test.txt" into table test;
select * form test;
select * from test;
drop table test;
create table test(id int,name string) row format delimited fields terminated by "\t";
load data local inpath "/opt/module/datas/test.txt" into table test;
select * from test;
exit;
[root@systemhub711 ~]# 
```

##### 2.2.8.8 Hiveå¸¸è§å±æ€§é…ç½®
###### 2.2.8.8.1 Hiveæ•°æ®ä»“åº“ä½ç½®é…ç½®
> 1.Defaultæ•°æ®ä»“åº“æœ€åŸå§‹ä½ç½®æ˜¯åœ¨hdfsä¸Šçš„: /user/hive/warehouseè·¯å¾„ä¸‹.
> 
> 2.åœ¨ä»“åº“ç›®å½•ä¸‹,æ²¡æœ‰å¯¹é»˜è®¤çš„æ•°æ®åº“defaultåˆ›å»ºæ–‡ä»¶å¤¹,å¦‚æœæŸå¼ æ•°æ®è¡¨å±äºdefaultæ•°æ®åº“,ç›´æ¥ä¼šåœ¨æ•°æ®ä»“åº“ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªæ–‡ä»¶å¤¹.
> 
> 3.ä¿®æ”¹defaultæ•°æ®ä»“åº“åŸå§‹ä½ç½®.
> 1.åœ¨hive-site.xmlé…ç½®æ–‡ä»¶ä¸­è¿½åŠ ä¸€ä¸‹é…ç½®ä¿¡æ¯.
``` xml
<property>
  <name>hive.metastore.warehouse.dir</name>
  <value>/user/hive/warehouse</value>
  <description>location of default database for the warehouse</description>
</property>
```
###### 2.2.8.8.2 é…ç½®æŸ¥è¯¢åä¿¡æ¯æ˜¾ç¤º
> 1.åœ¨hive-site.xmlæ–‡ä»¶ä¸­æ·»åŠ å¦‚ä¸‹é…ç½®ä¿¡æ¯,å°±å¯ä»¥å®ç°æ˜¾ç¤ºå½“å‰æ•°æ®åº“,ä»¥åŠæŸ¥è¯¢è¡¨çš„å¤´ä¿¡æ¯é…ç½®.
``` xml
<property> 
  <name>hive.cli.print.header</name>  
  <value>true</value> 
</property>

<property> 
  <name>hive.cli.print.current.db</name>  
  <value>true</value> 
</property>
```
> 2.é‡æ–°å¯åŠ¨hive,å¯¹æ¯”é…ç½®å‰åå·®å¼‚.
> 
> é…ç½®å‰.
```
hive> select * from test;
OK
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
Time taken: 0.808 seconds, Fetched: 4 row(s)
hive> 
```

> é…ç½®å.
```
hive (default)> select * from test;
OK
test.id test.name
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
Time taken: 1.708 seconds, Fetched: 4 row(s)
hive (default)> 
```

###### 2.2.8.8.3 Hiveè¿è¡Œæ—¥å¿—ä¿¡æ¯é…ç½®
> 1.Hiveçš„logé»˜è®¤å­˜æ”¾åœ¨/tmp/root/hive.logç›®å½•ä¸‹(å½“å‰ç”¨æˆ·åä¸‹).
> 2.ä¿®æ”¹hiveçš„logå­˜æ”¾æ—¥å¿—åˆ°/opt/module/hive/logs
> 2.1å°†hive-log4j.properties.templateæ–‡ä»¶åç§°ä¿®æ”¹ä¸ºhive-log4j.properties
```
[root@systemhub711 conf]# pwd
/opt/module/hive/conf
[root@systemhub711 conf]# ll
total 192
-rw-rw-r--. 1 root root   1139 Apr 30  2015 beeline-log4j.properties.template
-rw-rw-r--. 1 root root 168431 Jun 19  2015 hive-default.xml.template
-rw-rw-r--. 1 root root   2401 Mar 25 00:10 hive-env.sh
-rw-rw-r--. 1 root root   2662 Apr 30  2015 hive-exec-log4j.properties.template
-rw-rw-r--. 1 root root   3050 Apr 30  2015 hive-log4j.properties.template
-rw-r--r--. 1 root root   1416 Mar 25 23:11 hive-site.xml
-rw-rw-r--. 1 root root   1593 Apr 30  2015 ivysettings.xml
[root@systemhub711 conf]# mv hive-log4j.properties.template hive-log4j.properties
[root@systemhub711 conf]# ll
total 192
-rw-rw-r--. 1 root root   1139 Apr 30  2015 beeline-log4j.properties.template
-rw-rw-r--. 1 root root 168431 Jun 19  2015 hive-default.xml.template
-rw-rw-r--. 1 root root   2401 Mar 25 00:10 hive-env.sh
-rw-rw-r--. 1 root root   2662 Apr 30  2015 hive-exec-log4j.properties.template
-rw-rw-r--. 1 root root   3050 Apr 30  2015 hive-log4j.properties
-rw-r--r--. 1 root root   1416 Mar 25 23:11 hive-site.xml
-rw-rw-r--. 1 root root   1593 Apr 30  2015 ivysettings.xml
[root@systemhub711 conf]# 
```
> åœ¨hive-log4j.propertiesé…ç½®æ–‡ä»¶ä¸­ä¿®æ”¹logå­˜æ”¾ä½ç½®.
```
[root@systemhub711 conf]# vim hive-log4j.properties
```

```
-rw-r--r--. 1 root root   1416 Mar 25 23:11 hive-site.xml
-rw-rw-r--. 1 root root   1593 Apr 30  2015 ivysettings.xml
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Define some default values that can be overridden by system properties
hive.log.threshold=ALL
hive.root.logger=INFO,DRFA
hive.log.dir=/opt/module/hive/logs
```

###### 2.2.8.8.4 å‚æ•°é…ç½®æ–¹å¼
> 1.æŸ¥çœ‹å½“å‰æ‰€æœ‰çš„é…ç½®ä¿¡æ¯.
```
hive (default)> set;
_hive.hdfs.session.path=/tmp/hive/root/3227b090-9545-485f-bae7-b9b31cadc61d
_hive.local.session.path=/tmp/root/3227b090-9545-485f-bae7-b9b31cadc61d
_hive.tmp_table_space=/tmp/hive/root/3227b090-9545-485f-bae7-b9b31cadc61d/_tmp_space.db
datanucleus.autoCreateSchema=true
datanucleus.autoStartMechanismMode=checked
datanucleus.cache.level2=false
datanucleus.cache.level2.type=none
datanucleus.connectionPoolingType=BONECP
datanucleus.fixedDatastore=false
```

> 2.å‚æ•°çš„é…ç½®ä¸‰ç§æ–¹å¼.
> 
> 2.1 é…ç½®æ–‡ä»¶æ–¹å¼
> 
> é»˜è®¤é…ç½®æ–‡ä»¶: hive-default.xml
> 
> å¼€å‘è€…è‡ªå®šä¹‰é…ç½®æ–‡ä»¶: hive-site.xml
> 
> æ³¨æ„: å¼€å‘è€…è‡ªå®šä¹‰é…ç½®ä¼šè¦†ç›–é»˜è®¤é…ç½®,å¦å¤–,Hiveä¹Ÿä¼šè¯»å…¥Hadoopçš„é…ç½®,å› ä¸ºHiveæ˜¯ä½œä¸ºHadoopçš„å®¢æˆ·ç«¯å¯åŠ¨çš„,Hiveçš„é…ç½®ä¼šè¦†ç›–Hadoopçš„é…ç½®,é…ç½®æ–‡ä»¶çš„è®¾å®šå¯¹æœ¬æœºå¯åŠ¨çš„æ‰€æœ‰Hiveè¿›ç¨‹éƒ½æœ‰æ•ˆ.
> 
> 2.2 å‘½ä»¤è¡Œå‚æ•°æ–¹å¼
> 
> å¯åŠ¨Hiveæ—¶,å¯ä»¥åœ¨å‘½ä»¤è¡Œæ·»åŠ `-hiveconf param=value`æ¥è®¾å®šå‚æ•°.
> `ä»…å¯¹æœ¬æ¬¡hiveå¯åŠ¨æœ‰æ•ˆ`
```
[root@systemhub711 hive]# bin/hive -hiveconf mapred.reduce.tasks=10
Logging initialized using configuration in file:/opt/module/hive/conf/hive-log4j.properties
hive (default)> 
```
> æŸ¥çœ‹å‚æ•°è®¾ç½®
```
hive (default)> set mapred.reduce.tasks;
mapred.reduce.tasks=10
hive (default)> 
```
> 2.3 å‚æ•°å£°æ˜æ–¹å¼
> å¯ä»¥åœ¨HQLä¸­ä½¿ç”¨SETå…³é”®å­—è®¾å®šå‚æ•°.
> `ä»…å¯¹æœ¬æ¬¡hiveå¯åŠ¨æœ‰æ•ˆ`
```
[root@systemhub711 hive]# bin/hive -hiveconf mapred.reduce.tasks=100
Logging initialized using configuration in file:/opt/module/hive/conf/hive-log4j.properties
hive (default)> 
```
> æŸ¥çœ‹å‚æ•°è®¾ç½®
```
hive (default)> set mapred.reduce.tasks;
mapred.reduce.tasks=100
hive (default)> 
```
> ä¸Šè¿°ä¸‰ç§è®¾å®šæ–¹å¼çš„ä¼˜å…ˆçº§ä¾æ¬¡é€’å¢.
> 
> å³é…ç½®æ–‡ä»¶ `<` å‘½ä»¤è¡Œå‚æ•° `<` å‚æ•°å£°æ˜.
> 
> æ³¨æ„æŸäº›ç³»ç»Ÿçº§çš„å‚æ•°,ä¾‹å¦‚log4jç›¸å…³çš„è®¾å®š,å¿…é¡»ç”¨å‰ä¸¤ç§æ–¹å¼è®¾å®š,å› ä¸ºé‚£äº›å‚æ•°çš„è¯»å–åœ¨ä¼šè¯å»ºç«‹ä»¥å‰å·²ç»å®Œæˆäº†.


## 3. Hive æ•°æ®ç±»å‹
### 3.1 åŸºæœ¬æ•°æ®ç±»å‹
> å¯¹äºHiveçš„Stringç±»å‹ç›¸å½“äºæ•°æ®åº“çš„varcharç±»å‹,è¯¥ç±»å‹æ˜¯ä¸€ä¸ªå¯å˜çš„å­—ç¬¦ä¸²,ä¸è¿‡å®ƒä¸èƒ½å£°æ˜å…¶ä¸­æœ€å¤šèƒ½å­˜å‚¨å¤šå°‘ä¸ªå­—ç¬¦,ç†è®ºä¸Šå®ƒå¯ä»¥å­˜å‚¨2GBçš„å­—ç¬¦æ•°.

| Hive æ•°æ®ç±»å‹      |  Java æ•°æ®ç±»å‹ |   é•¿åº¦   |   æ•°å€¼   |
| :--------: | :--------:| :------: | :------: |
| TINYINT    |   byte |  1byteæœ‰ç¬¦å·æ•´æ•°  |  20  |
| SMALINT    |   short |  2byteæœ‰ç¬¦å·æ•´æ•°  |  20  |
| INT    |   int |  4byteæœ‰ç¬¦å·æ•´æ•°  |  20  |
| BIGINT    |   long |  8byteæœ‰ç¬¦å·æ•´æ•°  |  20  |
| BOOLEAN    |   boolean |  å¸ƒå°”ç±»å‹,trueæˆ–è€…false  |  TRUE / FALSE  |
| FLOAT    |   float |  å•ç²¾åº¦æµ®ç‚¹æ•°  |  3.14159  |
| DOUBLE    |   double |  åŒç²¾åº¦æµ®ç‚¹æ•°  |  3.14159  |
| STRING    |   string |  å­—ç¬¦ä¸²ç±»å‹,å¯ä»¥æŒ‡å®šå­—ç¬¦é›†,å¯ä»¥ä½¿ç”¨å•å¼•å·æˆ–è€…åŒå¼•å·  |  'now is the time' /  "for all good men"  |
| TIMESTAMP    |   |  æ—¶é—´ç±»å‹  |   |
| BINARY    |   |  å­—èŠ‚æ•°ç»„  |    |

### 3.2 é›†åˆæ•°æ®ç±»å‹
> Hiveæœ‰ä¸‰ç§å¤æ‚æ•°æ®ç±»å‹ARRAYã€MAP å’ŒSTRUCT,ARRAYå’ŒMAPä¸Javaä¸­çš„Arrayå’ŒMapç±»ä¼¼,è€ŒSTRUCTä¸Cè¯­è¨€ä¸­çš„Structç±»ä¼¼,å®ƒå°è£…äº†ä¸€ä¸ªå‘½åå­—æ®µé›†åˆ,å¤æ‚æ•°æ®ç±»å‹å…è®¸ä»»æ„å±‚æ¬¡çš„åµŒå¥—.
> 
| æ•°æ®ç±»å‹      |     æè¿° |   è¯­æ³•ç¤ºä¾‹   |
| :--------: | :--------:| :------: |
| STRUCT    |   å’Œcè¯­è¨€ä¸­çš„structç±»ä¼¼,éƒ½å¯ä»¥é€šè¿‡â€œç‚¹â€ç¬¦å·è®¿é—®å…ƒç´ å†…å®¹,ä¾‹å¦‚å¦‚æœæŸä¸ªåˆ—çš„æ•°æ®ç±»å‹æ˜¯STRUCT{first  STRING,last STRING},é‚£ä¹ˆç¬¬1ä¸ªå…ƒç´ å¯ä»¥é€šè¿‡å­—æ®µ.firstæ¥å¼•ç”¨. |  struct()  |
| MAP | MAPæ˜¯ä¸€ç»„é”®-å€¼å¯¹å…ƒç»„é›†åˆ,ä½¿ç”¨æ•°ç»„è¡¨ç¤ºæ³•å¯ä»¥è®¿é—®æ•°æ®,ä¾‹å¦‚å¦‚æœæŸä¸ªåˆ—çš„æ•°æ®ç±»å‹æ˜¯MAP,å…¶ä¸­é”®->å€¼å¯¹æ˜¯â€™firstâ€™->â€™Johnâ€™å’Œâ€™lastâ€™->â€™Doeâ€™,é‚£ä¹ˆå¯ä»¥é€šè¿‡å­—æ®µå[â€˜lastâ€™]è·å–æœ€åä¸€ä¸ªå…ƒç´ . | map() |
| ARRAY | æ•°ç»„æ˜¯ä¸€ç»„å…·æœ‰ç›¸åŒç±»å‹å’Œåç§°çš„å˜é‡çš„é›†åˆ,è¿™äº›å˜é‡ç§°ä¸ºæ•°ç»„çš„å…ƒç´ ,æ¯ä¸ªæ•°ç»„å…ƒç´ éƒ½æœ‰ä¸€ä¸ªç¼–å·,ç¼–å·ä»é›¶å¼€å§‹,ä¾‹å¦‚æ•°ç»„å€¼ä¸º[â€˜Johnâ€™, â€˜Doeâ€™],é‚£ä¹ˆç¬¬2ä¸ªå…ƒç´ å¯ä»¥é€šè¿‡æ•°ç»„å[1]è¿›è¡Œå¼•ç”¨. | Array() |

#### 3.2.1 æ¡ˆä¾‹å®æ“
##### 3.2.1.1 ç”¨JSONæ ¼å¼æ¥è¡¨ç¤ºå…¶æ•°æ®ç»“æ„.
``` json
{
    "name": "TestUser",
    // Array åˆ—è¡¨
    "friends": ["TestUser001" , "TestUser002"] ,
    // Map é”®å€¼
    "children": {
        "TestUser003": "003",
        "TestUser004": "004"
    },
    // Struct ç»“æ„
    "address": {
        "street": "china",
        "city": "beijing"
    }
}
```

##### 3.2.1.2 åŸºäºä¸Šè¿°æ•°æ®ç»“æ„,åœ¨Hiveé‡Œåˆ›å»ºå¯¹åº”çš„è¡¨,å¹¶å¯¼å…¥æ•°æ®.
> åˆ›å»ºæœ¬åœ°æµ‹è¯•æ–‡ä»¶test001.txt
> 
> æ³¨: MAP,STRUCTå’ŒARRAYé‡Œçš„å…ƒç´ é—´å…³ç³»éƒ½å¯ä»¥ç”¨åŒä¸€ä¸ªå­—ç¬¦`_`ä¸‹åˆ’çº¿è¡¨ç¤º.
```
TestUser,TestUser001_TestUser002,TestUser003:003_TestUser004:004,china_beijing
DemoUser,DemoUser001_DemoUser002,DemoUser003:003_DemoUser004:004,china_beijing
```
> åœ¨Hiveåˆ›å»ºtestæµ‹è¯•è¡¨
> 
> SQL File
``` sql
create table test001(
name string,
firends array<string>,
children map<string,int>,
address struct<street:string,city:string>
)
row format delimited fields terminated by ','
collection items terminated by '_'
map keys terminated by ':'
lines terminated by '\n';
```
> å­—æ®µè§£é‡Š
```
è¡¨ç¤ºåˆ—åˆ†éš”ç¬¦
row format delimited fields terminated by ','

è¡¨ç¤ºMAP STRUCT å’Œ ARRAY åˆ†éš”ç¬¦(æ•°æ®åˆ†å‰²ç¬¦å·)
collection items terminated by '_'

è¡¨ç¤ºMAPä¸­çš„keyä¸valueåˆ†éš”ç¬¦
map keys terminated by ':'

è¡¨ç¤ºè¡Œåˆ†éš”ç¬¦
lines terminated by '\n';
```
> create table
```
hive (default)> set hive.cli.print.current.db=true;
hive (default)> create table test001(
              > name string,
              > firends array<string>,
              > children map<string,int>,
              > address struct<street:string,city:string>
              > )
              > row format delimited fields terminated by ','
              > collection items terminated by '_'
              > map keys terminated by ':'
              > lines terminated by '\n';
OK
Time taken: 0.269 seconds
hive (default)> show tables;
OK
tab_name
test
test001
Time taken: 0.053 seconds, Fetched: 2 row(s)
hive (default)> 
```
> å¯¼å…¥æ–‡æœ¬æ•°æ®åˆ°æµ‹è¯•è¡¨
```
hive (default)> load data local inpath '/opt/module/datas/test001.txt' into table test001;
Loading data to table default.test001
Table default.test001 stats: [numFiles=1, totalSize=158]
OK
Time taken: 1.268 seconds
hive (default)> 
```
> æŸ¥è¯¢å…¨éƒ¨æ•°æ®
```
hive (default)> select * from test001;
OK
test001.name    test001.firends test001.children        test001.address
TestUser        ["TestUser001","TestUser002"]   {"TestUser003":3,"TestUser004":4}       {"street":"china","city":"beijing"}
DemoUser        ["DemoUser001","DemoUser002"]   {"DemoUser003":3,"DemoUser004":4}       {"street":"china","city":"beijing"}
Time taken: 0.121 seconds, Fetched: 2 row(s)
hive (default)>	
```
> æŸ¥è¯¢ä¸‰ç§é›†åˆåˆ—è¡¨æ•°æ®
> ä»¥ä¸‹åˆ†åˆ«æ˜¯ARRAY / MAP / STRUCTçš„è®¿é—®æ–¹å¼.
```
hive (default)> select firends[1],children['TestUser003'],address.city from test001 where name="TestUser";
OK
_c0     _c1     city
TestUser002     3       beijing
Time taken: 0.32 seconds, Fetched: 1 row(s)
hive (default)>
```

### 3.3 ç±»å‹è½¬åŒ–
> Hiveçš„åŸå­æ•°æ®ç±»å‹æ˜¯å¯ä»¥è¿›è¡Œéšå¼è½¬æ¢çš„,ç±»ä¼¼äºJavaçš„ç±»å‹è½¬æ¢.
> 
> ä¾‹å¦‚æŸè¡¨è¾¾å¼ä½¿ç”¨INTç±»å‹,TINYINTä¼šè‡ªåŠ¨è½¬æ¢ä¸ºINTç±»å‹,ä½†æ˜¯Hiveä¸ä¼šè¿›è¡Œåå‘è½¬åŒ–.
> 
> ä¾‹å¦‚,æŸè¡¨è¾¾å¼ä½¿ç”¨TINYINTç±»å‹,INTä¸ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºTINYINTç±»å‹,å®ƒä¼šè¿”å›é”™è¯¯,é™¤éä½¿ç”¨`CAST`æ“ä½œ.
#### 3.3.1 éšå¼ç±»å‹è½¬æ¢è§„åˆ™
> 1.ä»»ä½•æ•´æ•°ç±»å‹éƒ½å¯ä»¥éšå¼åœ°è½¬æ¢ä¸ºä¸€ä¸ªèŒƒå›´æ›´å¹¿çš„ç±»å‹,å¦‚TINYINTå¯ä»¥è½¬æ¢æˆINT,INTå¯ä»¥è½¬æ¢æˆBIGINT.
> 
> 2.æ‰€æœ‰æ•´æ•°ç±»å‹ã€FLOATå’ŒSTRINGç±»å‹éƒ½å¯ä»¥éšå¼åœ°è½¬æ¢æˆDOUBLE.
> 
> 3.TINYINT,SMALLINT,INTéƒ½å¯ä»¥è½¬æ¢ä¸ºFLOAT.
> 
> 4.BOOLEANç±»å‹ä¸å¯ä»¥è½¬æ¢ä¸ºä»»ä½•å…¶å®ƒçš„ç±»å‹.

#### 3.3.2 ä½¿ç”¨CASTæ˜¾ç¤ºè¿›è¡Œæ•°æ®ç±»å‹è½¬æ¢
> ä¾‹å¦‚`CAST('1' AS INT)`å°†æŠŠå­—ç¬¦ä¸²`'1'` è½¬æ¢æˆæ•´æ•°1,å¦‚æœå¼ºåˆ¶ç±»å‹è½¬æ¢å¤±è´¥,å¦‚æ‰§è¡Œ`CAST('X' AS INT)`,è¡¨è¾¾å¼è¿”å›ç©ºå€¼NULL.

## 4. DDL æ•°æ®å®šä¹‰
> DDL(Data Definition Language)æ•°æ®åº“æ¨¡å¼å®šä¹‰è¯­è¨€,æ˜¯ç”¨äºæè¿°æ•°æ®åº“ä¸­è¦å­˜å‚¨çš„ç°å®ä¸–ç•Œå®ä½“çš„è¯­è¨€.

### 4.1 åˆ›å»ºæ•°æ®åº“
> åˆ›å»ºä¸€ä¸ªæ•°æ®åº“,æ•°æ®åº“åœ¨HDFSä¸Šçš„é»˜è®¤å­˜å‚¨è·¯å¾„æ˜¯/user/hive/warehouse/*.db
> 
> é¿å…è¦åˆ›å»ºçš„æ•°æ®åº“å·²ç»å­˜åœ¨é”™è¯¯,å¢åŠ if not existsåˆ¤æ–­.
```
hive (default)> create database if not exists hive_db;
OK
Time taken: 0.131 seconds
hive (default)> 
```
> å½“å‰åˆ›å»ºçš„æ•°æ®åº“ä¼šå­˜æ”¾æŒ‡å®šåœ¨HDFSè·¯å¾„.
![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hive/start_003.jpg)

### 4.2 æŸ¥è¯¢æ•°æ®åº“
#### 4.2.1 æ˜¾ç¤ºæ•°æ®åº“
> 1.æ˜¾ç¤ºæ•°æ®åº“
```
hive (default)> show databases;
OK
database_name
default
hive_db
Time taken: 0.131 seconds, Fetched: 2 row(s)
hive (default)> 
```
> 2.è¿‡æ»¤æ˜¾ç¤ºæŸ¥è¯¢çš„æ•°æ®åº“
```
hive (default)> show databases like 'hive_db*';
OK
database_name
hive_db
Time taken: 0.039 seconds, Fetched: 1 row(s)
hive (default)> 
```
#### 4.2.2 æŸ¥çœ‹æ•°æ®åº“è¯¦æƒ…
> 1.æ˜¾ç¤ºæ•°æ®åº“ä¿¡æ¯
```
hive (default)> desc database hive_db;
OK
db_name comment location        owner_name      owner_type      parameters
hive_db         hdfs://systemhub511:9000/user/hive/warehouse/hive_db.db root    USER    
Time taken: 0.042 seconds, Fetched: 1 row(s)
hive (default)> 
```
> 2.æ˜¾ç¤ºæ•°æ®åº“è¯¦ç»†ä¿¡æ¯
```
hive (default)> desc database extended hive_db;
OK
db_name comment location        owner_name      owner_type      parameters
hive_db         hdfs://systemhub511:9000/user/hive/warehouse/hive_db.db root    USER    
Time taken: 0.027 seconds, Fetched: 1 row(s)
hive (default)> 
```
#### 4.2.3 åˆ‡æ¢å½“å‰æ•°æ®åº“
```
hive (default)> use hive_db;
OK
Time taken: 0.028 seconds
hive (hive_db)> 
```

### 4.3 ä¿®æ”¹æ•°æ®åº“
> ç”¨æˆ·å¯ä»¥ä½¿ç”¨`ALTER  DATABASE`å‘½ä»¤ä¸ºæŸä¸ªæ•°æ®åº“çš„`DBPROPERTIES`è®¾ç½®é”®-å€¼å¯¹å±æ€§å€¼,æ¥æè¿°è¿™ä¸ªæ•°æ®åº“çš„å±æ€§ä¿¡æ¯.
> 
> æ•°æ®åº“çš„å…¶ä»–å…ƒæ•°æ®ä¿¡æ¯éƒ½æ˜¯ä¸å¯æ›´æ”¹çš„,åŒ…æ‹¬æ•°æ®åº“åå’Œæ•°æ®åº“æ‰€åœ¨çš„ç›®å½•ä½ç½®.
```
hive (hive_db)> alter database hive_db set dbproperties('createtime'='2090-00-00');
OK
Time taken: 0.073 seconds
hive (hive_db)> desc database extended hive_db;
OK
db_name comment location        owner_name      owner_type      parameters
hive_db         hdfs://systemhub511:9000/user/hive/warehouse/hive_db.db root    USER    {createtime=2090-00-00}
Time taken: 0.034 seconds, Fetched: 1 row(s)
hive (hive_db)> 
```

### 4.4 åˆ é™¤æ•°æ®åº“
> å¦‚æœæ•°æ®åº“ä¸ä¸ºç©º,å¯ä»¥é‡‡ç”¨`cascade`å‘½ä»¤,å¼ºåˆ¶åˆ é™¤.
```
hive (default)> drop database hive_db cascade;
Time taken: 0.034 seconds
```

### 4.5 åˆ›å»ºè¡¨
#### 4.5.1 å»ºè¡¨è¯­æ³•
``` sql
CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name 
[(col_name data_type [COMMENT col_comment], ...)] 
[COMMENT table_comment] 
[PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] 
[CLUSTERED BY (col_name, col_name, ...) 
[SORTED BY (col_name [ASC|DESC], ...)] 
INTO num_buckets BUCKETS] 
[ROW FORMAT row_format] 
[STORED AS file_format] 
[LOCATION hdfs_path]
```
> å­—æ®µè§£é‡Šè¯´æ˜
> 
> 1.`CREATE  TABLE` åˆ›å»ºä¸€ä¸ªæŒ‡å®šåå­—çš„è¡¨,å¦‚æœç›¸åŒåå­—çš„è¡¨å·²ç»å­˜åœ¨,åˆ™æŠ›å‡ºå¼‚å¸¸,ç”¨æˆ·å¯ä»¥ç”¨`IF NOT EXISTS` é€‰é¡¹æ¥å¿½ç•¥è¿™ä¸ªå¼‚å¸¸.
> 
> 2.`EXTERNAL`å…³é”®å­—å¯ä»¥è®©ç”¨æˆ·åˆ›å»ºä¸€ä¸ªå¤–éƒ¨è¡¨,åœ¨å»ºè¡¨çš„åŒæ—¶æŒ‡å®šä¸€ä¸ªæŒ‡å‘å®é™…æ•°æ®çš„è·¯å¾„(LOCATION)Hiveåˆ›å»ºå†…éƒ¨è¡¨æ—¶,ä¼šå°†æ•°æ®ç§»åŠ¨åˆ°æ•°æ®ä»“åº“æŒ‡å‘çš„è·¯å¾„,è‹¥åˆ›å»ºå¤–éƒ¨è¡¨,ä»…è®°å½•æ•°æ®æ‰€åœ¨çš„è·¯å¾„,ä¸å¯¹æ•°æ®çš„ä½ç½®åšä»»ä½•æ”¹å˜,åœ¨åˆ é™¤è¡¨çš„æ—¶å€™,å†…éƒ¨è¡¨çš„å…ƒæ•°æ®å’Œæ•°æ®ä¼šè¢«ä¸€èµ·åˆ é™¤,è€Œå¤–éƒ¨è¡¨åªåˆ é™¤å…ƒæ•°æ®,ä¸åˆ é™¤æ•°æ®.
> 
> 3.`COMMENT`: ä¸ºè¡¨å’Œåˆ—æ·»åŠ æ³¨é‡Š.
> 
> 4.`PARTITIONED BY`åˆ›å»ºåˆ†åŒºè¡¨.
> 
> 5.`CLUSTERED BY`åˆ›å»ºåˆ†æ¡¶è¡¨.
> 
> 6.`SORTED BY`ä¸å¸¸ç”¨.
> 
> 7.`ROW FORMAT DELIMITED  [FIELDS TERMINATED BY char] [COLLECTIONITEMS TERMINATED BY char]`
> `[MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]  SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]`
> 
> å¼€å‘è€…åœ¨å»ºè¡¨çš„æ—¶å€™å¯ä»¥è‡ªå®šä¹‰SerDeæˆ–è€…ä½¿ç”¨è‡ªå¸¦çš„SerDe,å¦‚æœæ²¡æœ‰æŒ‡å®šROW FORMAT æˆ–è€…ROW FORMAT DELIMITED,å°†ä¼šä½¿ç”¨è‡ªå¸¦çš„SerDe,åœ¨å»ºè¡¨çš„æ—¶å€™,ç”¨æˆ·è¿˜éœ€è¦ä¸ºè¡¨æŒ‡å®šåˆ—,å¼€å‘è€…åœ¨æŒ‡å®šè¡¨çš„åˆ—çš„åŒæ—¶ä¹Ÿä¼šæŒ‡å®šè‡ªå®šä¹‰çš„SerDe,Hiveé€šè¿‡SerDeç¡®å®šè¡¨çš„å…·ä½“çš„åˆ—çš„æ•°æ®.
> 
> 8.`STORED AS` æŒ‡å®šå­˜å‚¨æ–‡ä»¶ç±»å‹.
> å¸¸ç”¨çš„å­˜å‚¨æ–‡ä»¶ç±»å‹: `SEQUENCEFILE(äºŒè¿›åˆ¶åºåˆ—æ–‡ä»¶)`,`TEXTFILE(æ–‡æœ¬)`,`RCFILE(åˆ—å¼å­˜å‚¨æ ¼å¼æ–‡ä»¶)`,å¦‚æœæ–‡ä»¶æ•°æ®æ˜¯çº¯æ–‡æœ¬,å¯ä»¥ä½¿ç”¨`STORED  AS  TEXTFILE`,å¦‚æœæ•°æ®éœ€è¦å‹ç¼©,ä½¿ç”¨`STORED AS SEQUENCEFILE`.
> 
> 9.`LOCATION`: æŒ‡å®šè¡¨åœ¨HDFSä¸Šçš„å­˜å‚¨ä½ç½®.
> 
> 10.`LIKE`å…è®¸å¼€å‘è€…å¤åˆ¶ç°æœ‰çš„è¡¨ç»“æ„,ä½†æ˜¯ä¸å¤åˆ¶æ•°æ®.

#### 4.5.2 ç®¡ç†è¡¨
##### 4.5.2.1 ç†è®º
> é»˜è®¤åˆ›å»ºçš„è¡¨éƒ½æ˜¯æ‰€è°“çš„ç®¡ç†è¡¨,æœ‰æ—¶ä¹Ÿè¢«ç§°ä¸ºå†…éƒ¨è¡¨.
> 
> å› ä¸ºè¿™ç§è¡¨,Hiveä¼šæˆ–å¤šæˆ–å°‘åœ°åˆ¶ç€æ•°æ®çš„ç”Ÿå‘½å‘¨æœŸ.
> 
> Hiveé»˜è®¤æƒ…å†µä¸‹ä¼šå°†è¿™äº›è¡¨çš„æ•°æ®å­˜å‚¨åœ¨ç”±é…ç½®é¡¹`hive.metastore.warehouse.dir`(ä¾‹å¦‚/user/hive/warehouse)æ‰€å®šä¹‰çš„ç›®å½•çš„å­ç›®å½•ä¸‹,å½“åˆ é™¤ä¸€ä¸ªç®¡ç†è¡¨æ—¶,Hiveä¹Ÿä¼šåˆ é™¤è¿™ä¸ªè¡¨ä¸­æ•°æ®,ç®¡ç†è¡¨ä¸é€‚åˆå’Œå…¶ä»–å·¥å…·å…±äº«æ•°æ®.

##### 4.5.2.2 æ¡ˆä¾‹å®æ“
> 1.æ™®é€šåˆ›å»ºè¡¨.
```
hive (default)> create table if not exists test004(id int, name string)row format delimited fields terminated by '\t' stored as textfile location '/user/hive/warehouse/test004';
OK
Time taken: 0.098 seconds
hive (default)> 
```
> 2.æ ¹æ®æŸ¥è¯¢ç»“æœåˆ›å»ºè¡¨(æŸ¥è¯¢çš„ç»“æœä¼šæ·»åŠ åˆ°æ–°åˆ›å»ºçš„è¡¨ä¸­).
```
hive (default)> show tables;
OK
tab_name
test
test001
Time taken: 0.056 seconds, Fetched: 2 row(s)
hive (default)> create table test002 as select * from test001;
Query ID = root_20190328000840_11ef1852-3fee-44f5-a4d4-a15042411c6a
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1553696946343_0001, Tracking URL = http://systemhub611:8088/proxy/application_1553696946343_0001/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553696946343_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
Stage-1 map = 0%,  reduce = 0%
Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.34 sec
MapReduce Total cumulative CPU time: 1 seconds 340 msec
Ended Job = job_1553696946343_0001
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to: hdfs://systemhub511:9000/user/hive/warehouse/.hive-staging_hive_2019-03-28_00-08-40_557_7477541425251721483-1/-ext-10001
Moving data to: hdfs://systemhub511:9000/user/hive/warehouse/test002
Table default.test002 stats: [numFiles=1, numRows=2, totalSize=150, rawDataSize=148]
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1   Cumulative CPU: 1.34 sec   HDFS Read: 3913 HDFS Write: 222 SUCCESS
Total MapReduce CPU Time Spent: 1 seconds 340 msec
OK
test001.name    test001.firends test001.children        test001.address
Time taken: 33.974 seconds
hive (default)> show tables;
OK
tab_name
test
test001
test002
Time taken: 0.041 seconds, Fetched: 3 row(s)
hive (default)> select * from test002;
OK
test002.name    test002.firends test002.children        test002.address
TestUser        ["TestUser001","TestUser002"]   {"TestUser003":3,"TestUser004":4}       {"street":"china","city":"beijing"}
DemoUser        ["DemoUser001","DemoUser002"]   {"DemoUser003":3,"DemoUser004":4}       {"street":"china","city":"beijing"}
Time taken: 0.157 seconds, Fetched: 2 row(s)
hive (default)> 
```
> 3.æ ¹æ®å·²ç»å­˜åœ¨çš„è¡¨ç»“æ„åˆ›å»ºè¡¨.
```
hive (default)> create table test003 like test;
OK
Time taken: 0.116 seconds
hive (default)> select * from test003;
OK
test003.id      test003.name
Time taken: 0.066 seconds
hive (default)> 
```
> 4.æŸ¥è¯¢è¡¨çš„ç±»å‹.
```
hive (default)> desc formatted test002;
OK
col_name        data_type       comment
# col_name              data_type               comment             
                 
name                    string                                      
firends                 array<string>                               
children                map<string,int>                             
address                 struct<street:string,city:string>                           
                 
# Detailed Table Information             
Database:               default                  
Owner:                  root                         
LastAccessTime:         UNKNOWN                  
Protect Mode:           None                     
Retention:              0                        
Location:               hdfs://systemhub511:9000/user/hive/warehouse/test002     
Table Type:             MANAGED_TABLE            
Table Parameters:                
        COLUMN_STATS_ACCURATE   true                
        numFiles                1                   
        numRows                 2                   
        rawDataSize             148                 
        totalSize               150                 
        transient_lastDdlTime   1553702954          
                 
# Storage Information            
SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe       
InputFormat:            org.apache.hadoop.mapred.TextInputFormat         
OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat       
Compressed:             No                       
Num Buckets:            -1                       
Bucket Columns:         []                       
Sort Columns:           []                       
Storage Desc Params:             
        serialization.format    1                   
Time taken: 0.179 seconds, Fetched: 34 row(s)
hive (default)> 
```
#### 4.5.3 å¤–éƒ¨è¡¨
##### 4.5.3.1 ç†è®º
> å› ä¸ºè¡¨æ˜¯å¤–éƒ¨è¡¨,æ‰€æœ‰Hiveå¹¶éè®¤ä¸ºå…¶å®Œå…¨æ‹¥æœ‰è¿™ä»½æ•°æ®,åˆ é™¤è¯¥è¡¨å¹¶ä¸ä¼šåˆ é™¤æ‰è¿™ä»½æ•°æ®,ä¸è¿‡æè¿°è¡¨çš„å…ƒæ•°æ®ä¿¡æ¯ä¼šè¢«åˆ é™¤æ‰.
##### 4.5.3.2 ç®¡ç†è¡¨å’Œå¤–éƒ¨è¡¨çš„ä½¿ç”¨åœºæ™¯
> æ¯å¤©å°†æ”¶é›†åˆ°çš„ç½‘ç«™æ—¥å¿—å®šæœŸæµå…¥HDFSæ–‡æœ¬æ–‡ä»¶,åœ¨å¤–éƒ¨è¡¨(åŸå§‹æ—¥å¿—è¡¨)åŸºç¡€ä¸Šåšå¤§é‡çš„ç»Ÿè®¡åˆ†æ,ç”¨åˆ°çš„ä¸­é—´è¡¨ã€ç»“æœè¡¨ä½¿ç”¨å†…éƒ¨è¡¨å­˜å‚¨,æ•°æ®é€šè¿‡SELECT+INSERTè¿›å…¥å†…éƒ¨è¡¨.


##### 4.5.3.3 æ¡ˆä¾‹å®æ“
> åˆ†åˆ«åˆ›å»ºéƒ¨é—¨å’Œå‘˜å·¥å¤–éƒ¨è¡¨,å¹¶å‘è¡¨ä¸­å¯¼å…¥æ•°æ®.
###### 1.åŸå§‹æ•°æ®
> dept.txt & emp.txt
```
[root@systemhub711 ~]# cd /opt/module/datas/
[root@systemhub711 datas]# vim dept.txt

50      ACCOUNTING      1900
60      RESEARCH        1800
70      SALES           1700
80      OPERATIONS      1700
```
###### 2.å»ºè¡¨è¯­å¥
```
[root@systemhub711 datas]# vim emp.txt

7369    SMITH   CLERKSKLD       7902    1980-12-17      800.00  20
7499    ALLTE   SALESMANS       7689    1987-02-23      1600.00 300.00  30
7521    WAROS   SJDHHJDJX       7869    1984-06-12      1250.18 500.00  30
7566    JOSSS   JDHYHDSDS       4545    1874-05-15      2894.25 20
7654    SOCTD   MANSJUSSD       4855    1996-02-14      2852.30 30
7698    ADAMS   JUSHHWESD       4552    1985-05-16      25524.02        30
7782    JAMSK   KIHNGSEHN       7769    1991-06-23      1100.00 20
7788    FOESS   CLAEDFDFD       7698    1994-09-17      950.00  30
7939    KINGS   CLADDJHEW       7566    1993-07-12      3000.00 20
```
> åˆ›å»ºéƒ¨é—¨è¡¨
```
hive (default)> create external table dept(deptid int,dname string,loc int)
> row format delimited fields terminated by '\t';
OK
Time taken: 0.137 seconds
hive (default)> 
```
> åˆ›å»ºå‘˜å·¥è¡¨
```
hive (default)> create external table if not exists emp(empno int,ename string,job string,mgr int,hiredate string,sal double,comm double,deptno int)
> row format delimited fields terminated by '\t';
OK
Time taken: 0.121 seconds
hive (default)> 
```
###### 3.å‘å¤–éƒ¨è¡¨ä¸­å¯¼å…¥æ•°æ®
```
hive (default)> load data local inpath '/opt/module/datas/dept.txt' into table dept;
Loading data to table default.dept
Table default.dept stats: [numFiles=1, totalSize=70]
OK
Time taken: 0.535 seconds
hive (default)>
```
```
hive (default)> load data local inpath '/opt/module/datas/emp.txt' into table emp;
Loading data to table default.emp
Table default.emp stats: [numFiles=1, totalSize=445]
OK
Time taken: 0.302 seconds
hive (default)> 
```
###### 4.æŸ¥çœ‹åˆ›å»ºçš„è¡¨
```
hive (default)> select * from dept;
OK
dept.deptid     dept.dname      dept.loc
50      ACCOUNTING      1900
60      RESEARCH        1800
70      SALES   NULL
80      OPERATIONS      1700
Time taken: 0.098 seconds, Fetched: 4 row(s)
hive (default)> select * from emp;
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7369    SMITH   CLERKSKLD       7902    1980-12-17      800.0   20.0    NULL
7499    ALLTE   SALESMANS       7689    1987-02-23      1600.0  300.0   30
7521    WAROS   SJDHHJDJX       7869    1984-06-12      1250.18 500.0   30
7566    JOSSS   JDHYHDSDS       4545    1874-05-15      2894.25 20.0    NULL
7654    SOCTD   MANSJUSSD       4855    1996-02-14      2852.3  30.0    NULL
7698    ADAMS   JUSHHWESD       4552    1985-05-16      25524.02        30.0    NULL
7782    JAMSK   KIHNGSEHN       7769    1991-06-23      1100.0  20.0    NULL
7788    FOESS   CLAEDFDFD       7698    1994-09-17      950.0   30.0    NULL
7939    KINGS   CLADDJHEW       7566    1993-07-12      3000.0  20.0    NULL
Time taken: 0.063 seconds, Fetched: 9 row(s)
hive (default)> 
```
###### 5.æŸ¥çœ‹è¡¨æ ¼å¼åŒ–æ•°æ®
```
hive (default)> desc formatted dept;
OK
col_name        data_type       comment
# col_name              data_type               comment             
                 
deptid                  int                                         
dname                   string                                      
loc                     int                                         
                 
# Detailed Table Information             
Database:               default                  
Owner:                  root                        
LastAccessTime:         UNKNOWN                  
Protect Mode:           None                     
Retention:              0                        
Location:               hdfs://systemhub511:9000/user/hive/warehouse/dept        
Table Type:             EXTERNAL_TABLE           
Table Parameters:                
        COLUMN_STATS_ACCURATE   true                
        EXTERNAL                TRUE                
        numFiles                1                   
        totalSize               70                  
        transient_lastDdlTime   1553705763          
                 
# Storage Information            
SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe       
InputFormat:            org.apache.hadoop.mapred.TextInputFormat         
OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat       
Compressed:             No                       
Num Buckets:            -1                       
Bucket Columns:         []                       
Sort Columns:           []                       
Storage Desc Params:             
        field.delim             \t                  
        serialization.format    \t                  
Time taken: 0.159 seconds, Fetched: 33 row(s)
hive (default)> 
```
###### 6.åˆ é™¤å¤–éƒ¨deptæ•°æ®è¡¨,å¹¶æŸ¥çœ‹ç»“æœ
> é€šè¿‡æŸ¥çœ‹ç»“æœæ¥çœ‹,åªæ˜¯åˆ é™¤äº†æè¿°è¡¨çš„å…ƒæ•°æ®ä¿¡æ¯,è€Œä¸ä¼šåˆ é™¤è¯¥æ•°æ®è¡¨çš„å…ƒæ•°æ®.
![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hive/start_004.jpg)
> å¯é€šè¿‡å†æ¬¡åˆ›å»ºå¤–éƒ¨deptæ•°æ®è¡¨,ä¾æ—§å¯ä»¥æŸ¥çœ‹åˆ°deptå…ƒæ•°æ®æ‰€åœ¨.
```
hive (default)> create external table if not exists dept(deptid int,dname string,loc int)row format delimited fields terminated by '\t';
OK
Time taken: 0.039 seconds
hive (default)> select * from dept;
OK
dept.deptid     dept.dname      dept.loc
50      ACCOUNTING      1900
60      RESEARCH        1800
70      SALES   NULL
80      OPERATIONS      1700
Time taken: 0.06 seconds, Fetched: 4 row(s)
hive (default)> 
```
#### 4.5.4 ç®¡ç†éƒ¨ä¸å¤–éƒ¨è¡¨ç›¸äº’è½¬æ¢ 
> æ³¨: ('EXTERNAL'='TRUE') & ('EXTERNAL'='FALSE') ä¸ºå›ºå®šå†™æ³•,åŒºåˆ†å¤§å°å†™.
##### æŸ¥è¯¢å†…éƒ¨è¡¨æ•°æ®è¡¨ç±»å‹
```
hive (default)> desc formatted test001;
Table Type:             MANAGED_TABLE  
```
##### ä¿®æ”¹å†…éƒ¨è¡¨ä¸ºå¤–éƒ¨è¡¨
```
alter table test001 set tblproperties('EXTERNAL'='TRUE');
```
##### æŸ¥è¯¢å¤–éƒ¨è¡¨æ•°æ®è¡¨ç±»å‹
```
hive (default)> desc formatted test001;
Table Type:             EXTERNAL_TABLE  
```
##### ä¿®æ”¹å¤–éƒ¨è¡¨ä¸ºå†…éƒ¨è¡¨
```
alter table test001 set tblproperties('EXTERNAL'='FALSE');
```
##### æŸ¥è¯¢å†…éƒ¨è¡¨æ•°æ®è¡¨ç±»å‹
```
hive (default)> desc formatted test001;
Table Type:             MANAGED_TABLE  
```


### 4.6 åˆ†åŒºè¡¨
> åˆ†åŒºè¡¨å®é™…ä¸Šå°±æ˜¯å¯¹åº”ä¸€ä¸ªHDFSæ–‡ä»¶ç³»ç»Ÿä¸Šçš„ç‹¬ç«‹çš„æ–‡ä»¶å¤¹,è¯¥æ–‡ä»¶å¤¹ä¸‹æ˜¯è¯¥åˆ†åŒºæ‰€æœ‰çš„æ•°æ®æ–‡ä»¶,Hiveä¸­çš„åˆ†åŒºå°±æ˜¯åˆ†ç›®å½•,æŠŠä¸€ä¸ªå¤§çš„æ•°æ®é›†æ ¹æ®ä¸šåŠ¡éœ€è¦åˆ†å‰²æˆå°çš„æ•°æ®é›†,åœ¨æŸ¥è¯¢æ—¶é€šè¿‡WHEREå­å¥ä¸­çš„è¡¨è¾¾å¼é€‰æ‹©æŸ¥è¯¢æ‰€éœ€è¦çš„æŒ‡å®šçš„åˆ†åŒº,è¿™æ ·çš„æŸ¥è¯¢æ•ˆç‡ä¼šæé«˜å¾ˆå¤š.
#### 4.6.1 åˆ›å»ºåˆ†åŒºè¡¨è¯­æ³•
```
hive (default)> create table dept_partition(deptno int, dname string, loc string)
              > partitioned by (month string)
              > row format delimited fields terminated by '\t';
OK
Time taken: 0.614 seconds
hive (default)> 
```
#### 4.6.2 åŠ è½½æ•°æ®åˆ°åˆ†åŒºè¡¨ä¸­
```
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition partition(month='2020-00-00');
Loading data to table default.dept_partition partition (month=2020-00-00)
Partition default.dept_partition{month=2020-00-00} stats: [numFiles=1, numRows=0, totalSize=70, rawDataSize=0]
OK
Time taken: 2.37 seconds
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition partition(month='2020-00-01');
Loading data to table default.dept_partition partition (month=2020-00-01)
Partition default.dept_partition{month=2020-00-01} stats: [numFiles=1, numRows=0, totalSize=70, rawDataSize=0]
OK
Time taken: 0.701 seconds
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition partition(month='2020-00-02');
Loading data to table default.dept_partition partition (month=2020-00-02)
Partition default.dept_partition{month=2020-00-02} stats: [numFiles=1, numRows=0, totalSize=70, rawDataSize=0]
OK
Time taken: 0.558 seconds
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition partition(month='2020-00-03');
Loading data to table default.dept_partition partition (month=2020-00-03)
Partition default.dept_partition{month=2020-00-03} stats: [numFiles=1, numRows=0, totalSize=70, rawDataSize=0]
OK
Time taken: 0.46 seconds
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition partition(month='2020-00-04');
Loading data to table default.dept_partition partition (month=2020-00-04)
Partition default.dept_partition{month=2020-00-04} stats: [numFiles=1, numRows=0, totalSize=70, rawDataSize=0]
OK
Time taken: 0.461 seconds
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition partition(month='2020-00-05');
Loading data to table default.dept_partition partition (month=2020-00-05)
Partition default.dept_partition{month=2020-00-05} stats: [numFiles=1, numRows=0, totalSize=70, rawDataSize=0]
OK
Time taken: 0.422 seconds
hive (default)>
```
#### 4.6.3 æŸ¥è¯¢åˆ†åŒºè¡¨ä¸­æ•°æ®
##### 4.6.3.1 å•åˆ†åŒºæŸ¥è¯¢
```
hive (default)> select * from dept_partition where month='2020-00-05';
OK
dept_partition.deptno   dept_partition.dname    dept_partition.loc      dept_partition.month
50      ACCOUNTING      1900    2020-00-05
60      RESEARCH        1800    2020-00-05
70      SALES           2020-00-05
80      OPERATIONS      1700    2020-00-05
Time taken: 1.186 seconds, Fetched: 4 row(s)
hive (default)>
```
##### 4.6.3.2 å¤šåˆ†åŒºè”åˆæŸ¥è¯¢
```
hive (default)> select * from dept_partition where month='2020-00-05'
              > union
              > select * from dept_partition where month='2020-00-04'
              > union
              > select * from dept_partition where month='2020-00-03'
              > union
              > select * from dept_partition where month='2020-00-02'
              > union
              > select * from dept_partition where month='2020-00-01';
Query ID = root_20190328145346_e7c134f9-1082-4bd6-9588-951592861d78
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553737906374_0001, Tracking URL = http://systemhub611:8088/proxy/application_1553737906374_0001/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553737906374_0001
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 1
Stage-1 map = 0%,  reduce = 0%
Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 1.5 sec
Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.42 sec
Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.2 sec
MapReduce Total cumulative CPU time: 5 seconds 200 msec
Ended Job = job_1553737906374_0001
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553737906374_0002, Tracking URL = http://systemhub611:8088/proxy/application_1553737906374_0002/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553737906374_0002
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
Stage-2 map = 0%,  reduce = 0%
Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.87 sec
Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 4.42 sec
MapReduce Total cumulative CPU time: 4 seconds 420 msec
Ended Job = job_1553737906374_0002
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553737906374_0003, Tracking URL = http://systemhub611:8088/proxy/application_1553737906374_0003/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553737906374_0003
Hadoop job information for Stage-3: number of mappers: 2; number of reducers: 1
Stage-3 map = 0%,  reduce = 0%
Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.67 sec
Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.41 sec
MapReduce Total cumulative CPU time: 4 seconds 410 msec
Ended Job = job_1553737906374_0003
Launching Job 4 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553737906374_0004, Tracking URL = http://systemhub611:8088/proxy/application_1553737906374_0004/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553737906374_0004
Hadoop job information for Stage-4: number of mappers: 2; number of reducers: 1
Stage-4 map = 0%,  reduce = 0%
Stage-4 map = 50%,  reduce = 0%, Cumulative CPU 1.21 sec
Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 2.61 sec
Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 4.5 sec
MapReduce Total cumulative CPU time: 4 seconds 500 msec
Ended Job = job_1553737906374_0004
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 1   Cumulative CPU: 5.2 sec   HDFS Read: 15645 HDFS Write: 434 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 4.42 sec   HDFS Read: 14689 HDFS Write: 603 SUCCESS
Stage-Stage-3: Map: 2  Reduce: 1   Cumulative CPU: 4.41 sec   HDFS Read: 14810 HDFS Write: 772 SUCCESS
Stage-Stage-4: Map: 2  Reduce: 1   Cumulative CPU: 4.5 sec   HDFS Read: 15517 HDFS Write: 545 SUCCESS
Total MapReduce CPU Time Spent: 18 seconds 530 msec
OK
_u5.deptno      _u5.dname       _u5.loc _u5.month
50      ACCOUNTING      1900    2020-00-01
50      ACCOUNTING      1900    2020-00-02
50      ACCOUNTING      1900    2020-00-03
50      ACCOUNTING      1900    2020-00-04
50      ACCOUNTING      1900    2020-00-05
60      RESEARCH        1800    2020-00-01
60      RESEARCH        1800    2020-00-02
60      RESEARCH        1800    2020-00-03
60      RESEARCH        1800    2020-00-04
60      RESEARCH        1800    2020-00-05
70      SALES           2020-00-01
70      SALES           2020-00-02
70      SALES           2020-00-03
70      SALES           2020-00-04
70      SALES           2020-00-05
80      OPERATIONS      1700    2020-00-01
80      OPERATIONS      1700    2020-00-02
80      OPERATIONS      1700    2020-00-03
80      OPERATIONS      1700    2020-00-04
80      OPERATIONS      1700    2020-00-05
Time taken: 164.191 seconds, Fetched: 20 row(s)
hive (default)>
```

#### 4.6.4 å¢åŠ åˆ†åŒº
##### 4.6.4.1 åˆ›å»ºå•ä¸ªåˆ†åŒº
```
hive (default)> alter table dept_partition add partition(month='2020-00-06');
OK
Time taken: 0.501 seconds
hive (default)> 	
```
##### 4.6.4.2 åŒæ—¶åˆ›å»ºå¤šä¸ªåˆ†åŒº
```
hive (default)> alter table dept_partition add partition(month='2020-00-07') partition(month='2020-00-08');
OK
Time taken: 0.184 seconds
hive (default)> 
```
#### 4.6.5 åˆ é™¤åˆ†åŒº
##### 4.6.1 åˆ é™¤å•ä¸ªåˆ†åŒº
```
hive (default)> alter table dept_partition drop partition(month='2020-00-06');
Dropped the partition month=2020-00-06
OK
Time taken: 0.273 seconds
hive (default)> 
```
##### 4.6.2 åŒæ—¶åˆ é™¤å¤šä¸ªåˆ†åŒº
```
hive (default)> alter table dept_partition drop partition(month='2020-00-07'),partition(month='2020-00-08');
Dropped the partition month=2020-00-07
Dropped the partition month=2020-00-08
OK
Time taken: 0.837 seconds
hive (default)> 
```
#### 4.6.6 æŸ¥çœ‹åˆ†åŒºè¡¨æœ‰å¤šå°‘åˆ†åŒº
```
hive (default)> show partitions dept_partition;
OK
partition
month=2020-00-00
month=2020-00-01
month=2020-00-02
month=2020-00-03
month=2020-00-04
month=2020-00-05
Time taken: 0.155 seconds, Fetched: 6 row(s)
hive (default)> 
```

#### 4.6.7 æŸ¥çœ‹åˆ†åŒºè¡¨ç»“æ„
```
hive (default)> desc formatted dept_partition;
OK
col_name        data_type       comment
# col_name              data_type               comment             
                 
deptno                  int                                         
dname                   string                                      
loc                     string                                      
                 
# Partition Information          
# col_name              data_type               comment             
                 
month                   string                                      
                 
# Detailed Table Information             
Database:               default                  
Owner:                  root                        
LastAccessTime:         UNKNOWN                  
Protect Mode:           None                     
Retention:              0                        
Location:               hdfs://systemhub511:9000/user/hive/warehouse/dept_partition      
Table Type:             MANAGED_TABLE            
Table Parameters:                
        transient_lastDdlTime   1553753699          
                 
# Storage Information            
SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe       
InputFormat:            org.apache.hadoop.mapred.TextInputFormat         
OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat       
Compressed:             No                       
Num Buckets:            -1                       
Bucket Columns:         []                       
Sort Columns:           []                       
Storage Desc Params:             
        field.delim             \t                  
        serialization.format    \t                  
Time taken: 0.183 seconds, Fetched: 34 row(s)
hive (default)>
```

#### 4.6.8 åˆ†åŒºè¡¨æ³¨æ„äº‹é¡¹
##### 4.6.8.1 åˆ›å»ºäºŒçº§åˆ†åŒºè¡¨
```
hive (default)> create table dept_partition002(deptno int, dname string, loc string)
              > partitioned by (month string,day string)
              > row format delimited fields terminated by '\t';
OK
Time taken: 0.215 seconds
hive (default)> 
```
##### 4.6.8.2 åŠ è½½æ•°æ®
###### 4.6.8.2.1 åŠ è½½æ•°æ®åˆ°äºŒçº§åˆ†åŒºè¡¨
```
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition002 partition(month='2020-00-06', day='0101');
Loading data to table default.dept_partition002 partition (month=2020-00-06, day=0101)
Partition default.dept_partition002{month=2020-00-06, day=0101} stats: [numFiles=1, numRows=0, totalSize=70, rawDataSize=0]
OK
Time taken: 1.914 seconds
hive (default)> 
```
###### 4.6.8.2.2 æŸ¥è¯¢åˆ†åŒºæ•°æ®
```
hive (default)> select * from dept_partition002 where month='2020-00-06' and day='0101';
OK
dept_partition002.deptno        dept_partition002.dname dept_partition002.loc   dept_partition002.month dept_partition002.day
50      ACCOUNTING      1900    2020-00-06      0101
60      RESEARCH        1800    2020-00-06      0101
70      SALES           2020-00-06      0101
80      OPERATIONS      1700    2020-00-06      0101
Time taken: 0.284 seconds, Fetched: 4 row(s)
hive (default)>  
```
##### 4.6.8.3 å°†æ•°æ®ç›´æ¥ä¸Šä¼ åˆ°åˆ†åŒºç›®å½•,è®©åˆ†åŒºè¡¨ä¸æ•°æ®äº§ç”Ÿå…³è”çš„æ–¹å¼
###### 4.6.8.3.1 æ–¹å¼ä¸€: ä¸Šä¼ æ•°æ®åä¿®å¤
> ä¸Šä¼ æ•°æ®
```
hive (default)> dfs -mkdir -p /user/hive/warehouse/dept_partition/month=2020-00-10;
hive (default)> 
```
> æŸ¥è¯¢æ•°æ®(æŸ¥è¯¢ä¸åˆ°åˆšä¸Šä¼ çš„æ•°æ®)
```
hive (default)> select * from dept_partition where month='2020-00-10';
OK
dept_partition.deptno   dept_partition.dname    dept_partition.loc      dept_partition.month
Time taken: 0.147 seconds
hive (default)> 
```
> æ‰§è¡Œä¿®å¤å‘½ä»¤
```
hive (default)> msck repair table dept_partition;
OK
Partitions not in metastore:    dept_partition:month=2020-00-10
Repair: Added partition to metastore dept_partition:month=2020-00-10
Time taken: 0.297 seconds, Fetched: 2 row(s)
hive (default)> 
```

###### 4.6.8.3.2 æ–¹å¼äºŒ: ä¸Šä¼ æ•°æ®åæ·»åŠ åˆ†åŒº
> ä¸Šä¼ æ•°æ®
```
hive (default)> dfs -mkdir -p /user/hive/warehouse/dept_partition/month=2020-00-12;
hive (default)> 
```
> æ‰§è¡Œæ·»åŠ åˆ†åŒº
```
alter table dept_partition drop partition(month='2020-00-06',day='0101');
OK
Time taken: 0.273 seconds
hive (default)> 
```
> æŸ¥è¯¢æ•°æ®
```
hive (default)> select * from dept_partition002 where month='2020-00-06' and day='0101';
OK
dept_partition002.deptno        dept_partition002.dname dept_partition002.loc   dept_partition002.month dept_partition002.day
50      ACCOUNTING      1900    2020-00-06      0101
60      RESEARCH        1800    2020-00-06      0101
70      SALES           2020-00-06      0101
80      OPERATIONS      1700    2020-00-06      0101
Time taken: 0.284 seconds, Fetched: 4 row(s)
hive (default)>  
```
###### 4.6.8.3.3 æ–¹å¼ä¸‰: ä¸Šä¼ æ•°æ®åloadæ•°æ®åˆ°åˆ†åŒº
> åˆ›å»ºç›®å½•
```
hive (default)> dfs -mkdir -p /user/hive/warehouse/dept_partition/month=2020-00-06/day=0101;
hive (default)> 
```
> ä¸Šä¼ æ•°æ®
```
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition partition(month='2020-00-06', day='0101');
```
> æŸ¥è¯¢æ•°æ®
```
hive (default)> select * from dept_partition where month='2020-00-06' and day='0101';
OK
dept_partition002.deptno        dept_partition002.dname dept_partition002.loc   dept_partition002.month dept_partition002.day
50      ACCOUNTING      1900    2020-00-06      0101
60      RESEARCH        1800    2020-00-06      0101
70      SALES           2020-00-06      0101
80      OPERATIONS      1700    2020-00-06      0101
Time taken: 0.284 seconds, Fetched: 4 row(s)
hive (default)>  
```

### 4.7 ä¿®æ”¹è¡¨
#### 4.7.1 é‡å‘½åè¡¨
##### 4.7.1.1 è¯­æ³•
``` sql
ALTER TABLE table_name RENAME TO new_table_name;
```
##### 4.7.1.2 å®æ“æ¡ˆä¾‹
```
hive (default)> alter table dept_partition002 rename to dept_partition003;
OK
Time taken: 0.324 seconds
hive (default)> 
```
#### 4.7.2 å¢åŠ /ä¿®æ”¹/æ›¿æ¢åˆ—ä¿¡æ¯
##### 4.7.2.1 è¯­æ³•
###### 4.7.2.1.1 æ›´æ–°åˆ—
```
ALTER   TABLE   table_name   CHANGE   [COLUMN]   col_old_name   col_new_name column_type [COMMENT col_comment] [FIRST|AFTER column_name]
```
###### 4.7.2.1.2 å¢åŠ å’Œæ›¿æ¢åˆ—
```
ALTER    TABLE    table_name    ADD|REPLACE    COLUMNS    (col_name    data_type [COMMENT col_comment], ...)
```
> æ³¨ï¼šADDæ˜¯ä»£è¡¨æ–°å¢ä¸€å­—æ®µ,å­—æ®µä½ç½®åœ¨æ‰€æœ‰åˆ—åé¢(partitionåˆ—å‰),REPLACEåˆ™æ˜¯è¡¨ç¤ºæ›¿æ¢è¡¨ä¸­æ‰€æœ‰å­—æ®µ.

##### 4.7.2.2 å®æ“æ¡ˆä¾‹
###### 4.7.2.2.1 æŸ¥è¯¢è¡¨ç»“æ„
```
hive (default)> desc dept_partition;
OK
col_name        data_type       comment
deptno                  int                                         
dname                   string                                      
loc                     string                                      
month                   string                                      
                 
# Partition Information          
# col_name              data_type               comment             
                 
month                   string                                      
Time taken: 0.122 seconds, Fetched: 9 row(s)
hive (default)> 
```
###### 4.7.2.2.2 æ·»åŠ åˆ—
```
hive (default)> alter table dept_partition add columns(deptdesc string);
OK
Time taken: 0.133 seconds
hive (default)>
```
> æŸ¥è¯¢è¡¨ç»“æ„
```
hive (default)> desc dept_partition;
OK
col_name        data_type       comment
deptno                  int                                         
dname                   string                                      
loc                     string                                      
deptdesc                string                                      
month                   string                                      
                 
# Partition Information          
# col_name              data_type               comment             
                 
month                   string                                      
Time taken: 0.09 seconds, Fetched: 10 row(s)
hive (default)> 
```
###### 4.7.2.2.3 æ›´æ–°åˆ—
```
hive (default)> alter table dept_partition change column deptdesc desc int;
OK
Time taken: 0.113 seconds
hive (default)> 
```
> æŸ¥è¯¢è¡¨ç»“æ„
```
hive (default)> desc dept_partition;
OK
col_name        data_type       comment
deptno                  int                                         
dname                   string                                      
loc                     string                                      
desc                    int                                         
month                   string                                      
                 
# Partition Information          
# col_name              data_type               comment             
                 
month                   string                                      
Time taken: 0.093 seconds, Fetched: 10 row(s)
hive (default)> 
```
###### 4.7.2.2.4 æ›¿æ¢åˆ—
```
hive (default)> alter table dept_partition replace columns(deptno string,dname string,loc string);
OK
Time taken: 0.084 seconds
hive (default)> 
```
> æŸ¥è¯¢è¡¨ç»“æ„
```
hive (default)> desc dept_partition;
OK
col_name        data_type       comment
deptno                  string                                      
dname                   string                                      
loc                     string                                      
month                   string                                      
                 
# Partition Information          
# col_name              data_type               comment             
                 
month                   string                                      
Time taken: 0.094 seconds, Fetched: 9 row(s)
hive (default)> 
```
###### 4.7.2.2.5 åˆ é™¤è¡¨
```
hive (default)> drop table dept_partition003;
OK
Time taken: 0.343 seconds
hive (default)> 
```

## ğŸ”’ å°šæœªè§£é” æ­£åœ¨å­¦ä¹ æ¢ç´¢ä¸­... å°½æƒ…æœŸå¾… Blogæ›´æ–°! ğŸ”’


## 5. DML æ•°æ®æ“ä½œ
> DML(Data Manipulation Language)æ•°æ®æ“çºµè¯­è¨€,è´Ÿè´£å¯¹æ•°æ®åº“å¯¹è±¡è¿è¡Œæ•°æ®è®¿é—®å·¥ä½œçš„æŒ‡ä»¤é›†.

### 5.1 æ•°æ®å¯¼å…¥
### 5.2 æ•°æ®å¯¼å‡º
### 5.3 æ¸…é™¤è¡¨ä¸­æ•°æ® (Truncate)


## 6. æŸ¥è¯¢
## 7. å‡½æ•°
## 8. å‹ç¼© & å­˜å‚¨
## 9. ä¼ä¸šçº§è°ƒä¼˜


## 10. ä¿®ä»™ä¹‹é“ æŠ€æœ¯æ¶æ„è¿­ä»£ ç™»å³°é€ æä¹‹åŠ¿
![Alt text](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/main/technical_framework.jpg)


-----

## ğŸ’¡å¦‚ä½•å¯¹è¯¥å¼€æºæ–‡æ¡£è¿›è¡Œè´¡çŒ®ğŸ’¡

1. Blogå†…å®¹å¤§å¤šæ˜¯æ‰‹æ•²,æ‰€ä»¥éš¾å…ä¼šæœ‰ç¬”è¯¯,ä½ å¯ä»¥å¸®æˆ‘æ‰¾é”™åˆ«å­—ã€‚
2. å¾ˆå¤šçŸ¥è¯†ç‚¹æˆ‘å¯èƒ½æ²¡æœ‰æ¶‰åŠåˆ°,æ‰€ä»¥ä½ å¯ä»¥å¯¹å…¶ä»–çŸ¥è¯†ç‚¹è¿›è¡Œè¡¥å……ã€‚
3. ç°æœ‰çš„çŸ¥è¯†ç‚¹éš¾å…å­˜åœ¨ä¸å®Œå–„æˆ–è€…é”™è¯¯,æ‰€ä»¥ä½ å¯ä»¥å¯¹å·²æœ‰çŸ¥è¯†ç‚¹çš„ä¿®æ”¹/è¡¥å……ã€‚
4. ğŸ’¡æ¬¢è¿è´¡çŒ®`å„é¢†åŸŸå¼€æºé‡ç”ŸBlog`&`ç¬”è®°`&`æ–‡ç« `&`ç‰‡æ®µ`&`åˆ†äº«`&`åˆ›æƒ³`&`OpenSource Project`&`Code`&`Code Review`
5. ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ issues: [geekparkhub.github.io/issues](https://github.com/geekparkhub/geekparkhub.github.io/issues) ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ

### å¸Œæœ›æ¯ä¸€ç¯‡æ–‡ç« éƒ½èƒ½å¤Ÿå¯¹è¯»è€…ä»¬æä¾›å¸®åŠ©ä¸æå‡,è¿™ä¹ƒæ˜¯æ¯ä¸€ä½ç¬”è€…çš„åˆè¡·                          


-----


## ğŸ’Œæ„Ÿè°¢æ‚¨çš„é˜…è¯» æ¬¢è¿æ‚¨çš„ç•™è¨€ä¸å»ºè®®ğŸ’Œ

- FaceBookï¼š[JEEP SevenEleven](https://www.facebook.com/profile.php?id=100018099483403)
- Twitterï¼š[@JEEP7ll](https://twitter.com/JEEP7ll)
- Sina Weibo: [@JEEP-711](https://weibo.com/JEEP511)
- GeekParkHub GithubHomeï¼š<https://github.com/geekparkhub>
- GeekParkHub GiteeHomeï¼š<https://gitee.com/geekparkhub>
- Blog GardenHomeï¼š<http://www.cnblogs.com/JEEP711/>
- W3C/BlogHomeï¼š<https://www.w3cschool.cn/jeep711blog/>
- CSDN/BlogHomeï¼š<http://blog.csdn.net/jeep911>
- 51CTO/BlogHomeï¼š<http://jeep711.blog.51cto.com/>
- **`Official Public Email`**
- Group Emailï¼š<geekparkhub@outlook.com> â€”â€” <hackerparkhub@outlook.com> â€”â€” <hackerpark@hotmail.com>
- User Emailï¼š<jeep711.home.@gmail.com> â€”â€” <jeep-711@outlook.com>
- System Emailï¼š<systemhub-711@outlook.com>
- Service Emailï¼š<servicehub-711@outlook.com>



### æåŠ© é¡¹ç›®çš„å‘å±•ç¦»ä¸å¼€ä½ çš„æ”¯æŒ,è¯·å¼€å‘è€…å–æ¯â˜•Coffeeâ˜•å§!
![enter image description here](https://www.geekparkhub.com/docs/images/pay.jpg)

#### `è‡´è°¢`ï¼š
**æåŠ©æ—¶è¯·å¤‡æ³¨ UserName**
| ID| UserName | Donation | Money | Consume |
|:-| :-------- | --------:| :--: |:--: |
|1 | Object | WeChatPay |  5RMB | ä¸€æ¯å¯ä¹ | 
|2| æ³°è¿ªç†Šçœ‹æœˆäº®  | AliPay |  20RMB  | ä¸€æ¯å’–å•¡ | 
|3| ä¿®ä»™é“é•¿  | WeChatPay |  10RMB | ä¸¤æ¯å¯ä¹ | 


## License å¼€æºåè®®
[Apache License Version 2.0](https://github.com/geekparkhub/geekparkhub.github.io/blob/master/LICENSE)

---------