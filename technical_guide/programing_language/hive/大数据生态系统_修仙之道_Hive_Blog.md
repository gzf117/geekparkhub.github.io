	
# å¤§æ•°æ®ç”Ÿæ€ç³»ç»Ÿ ä¿®ä»™ä¹‹é“ Hive Blog

@(2019-03-18)[ Docs Language:ç®€ä½“ä¸­æ–‡ & English|Programing Language:Hive|Website:[www.geekparkhub.com](https://www.geekparkhub.com/)|![OpenSource](https://img.shields.io/badge/Open%20Source-%E2%9D%A4-brightgreen.svg) | ![GitHub repo size in bytes](https://img.shields.io/github/repo-size/geekparkhub/geekparkhub.github.io.svg) | GeekDeveloper:[JEEP-711](https://github.com/jeep711)|Github:[github.com/geekparkhub](https://github.com/geekparkhub)|Gitee:[gitee.com/geekparkhub](https://gitee.com/geekparkhub) ]

##  ğŸ˜ Hive Technology ä¿®ä»™ä¹‹é“ ç‚¼æ°”åŒ–ç¥ ğŸ˜

![Alt text](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hive/hive.jpg)

- **æå®¢å®éªŒå®¤æ˜¯æå®¢å›½é™…å…¬å›­æ——ä¸‹ä¸ºæœªæ¥è€Œæ„å»ºçš„æå®¢ç¤¾åŒº;**
- **æˆ‘ä»¬æ­£åœ¨æ„å»ºä¸€ä¸ªæ´»è·ƒçš„å°ä¼—ç¤¾åŒº,æ±‡èšä¼—å¤šä¼˜ç§€å¼€å‘è€…ä¸è®¾è®¡å¸ˆ;**
- **å…³æ³¨æå…·åˆ›æ–°ç²¾ç¥çš„å‰æ²¿æŠ€æœ¯&åˆ†äº«äº¤æµ&é¡¹ç›®åˆä½œæœºä¼šç­‰äº’è”ç½‘è¡Œä¸šæœåŠ¡;**
- **Openå¼€æ”¾ `Â·` Creationåˆ›æƒ³ `|` OpenSourceå¼€æ”¾æˆå°±æ¢¦æƒ³ GeekParkHubå…±å»ºå‰æ‰€æœªè§!**
- **Future Vision : Establishment of the Geek Foundation;**
- **GeekParkHub GithubHome:**<https://github.com/geekparkhub>
- **GeekParkHub GiteeHome:**<https://gitee.com/geekparkhub>
- **æ¬¢è¿è´¡çŒ®`å„é¢†åŸŸå¼€æºé‡ç”ŸBlog`&`ç¬”è®°`&`æ–‡ç« `&`ç‰‡æ®µ`&`åˆ†äº«`&`åˆ›æƒ³`&`OpenSource Project`&`Code`&`Code Review`**
- ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ issues: [geekparkhub.github.io/issues](https://github.com/geekparkhub/geekparkhub.github.io/issues) ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ
- **`Official Public Email`**
- Group Emailï¼š<geekparkhub@outlook.com> â€”â€” <hackerparkhub@outlook.com> â€”â€” <hackerpark@hotmail.com>
- User Emailï¼š<jeep711.home.@gmail.com> â€”â€” <jeep-711@outlook.com>
- System Emailï¼š<systemhub-711@outlook.com>
- Service Emailï¼š<servicehub-711@outlook.com>


-------------------

[TOC]


## 1. Hive åŸºæœ¬æ¦‚è¿°
### 1.1 ğŸ¤” ä»€ä¹ˆæ˜¯Hive ğŸ¤”
> Hive ç”±FaceBookå¼€æºå¹¶ç”¨äºè§£å†³æµ·é‡ç»“æ„åŒ–æ—¥å¿—çš„æ•°æ®ç»Ÿè®¡åˆ†æ.
> 
> Hiveæ˜¯åŸºäºHadoopçš„ä¸€ä¸ªæ•°æ®ä»“åº“å·¥å…·,å¯ä»¥å°†ç»“æ„åŒ–çš„æ•°æ®æ–‡ä»¶æ˜ å°„ä¸ºä¸€å¼ æ•°æ®è¡¨,å¹¶æä¾›ç±»SQLæŸ¥è¯¢åŠŸèƒ½.
> 
> æœ¬è´¨æ˜¯: å°†HQLè½¬åŒ–æˆMapReduceç¨‹åº.
> ![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hive/start_001.jpg)
> 
> 1.Hiveå¤„ç†çš„æ•°æ®å­˜å‚¨åœ¨HDFS.
> 
> 2.Hiveåˆ†ææ•°æ®åº•å±‚çš„å®ç°æ˜¯MapReduce.
> 
> 3.æ‰§è¡Œç¨‹åºè¿è¡Œåœ¨Yarnä¸Š.

### 1.1.2 Hive ç‰¹æ€§
> Hiveä½œä¸ºæ•°æ®ä»“åº“è½¯ä»¶,ä½¿ç”¨ç±»SQLçš„HiveQLè¯­è¨€å®ç°æ•°æ®æŸ¥è¯¢,æ‰€æœ‰Hiveæ•°æ®å‡å­˜å‚¨åœ¨Hadoopåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿä¸­,Hiveå…·æœ‰ä»¥ä¸‹ç‰¹å¾.
> 
> ä½¿ç”¨HiveQLä»¥ç±»ä¼¼SQLæŸ¥è¯¢æ–¹å¼è½»æ¾è®¿é—®æ•°æ®,å°†HQLæŸ¥è¯¢è½¬æ¢ä¸ºMapReduceçš„ä»»åŠ¡åœ¨Hadoopé›†ç¾¤ä¸Šæ‰§è¡Œ,å®ŒæˆETL(æå– / è½¬æ¢ / åŠ è½½ / æŠ¥è¡¨ / æ•°æ®åˆ†æ)ç­‰æ•°æ®ä»“åº“ä»»åŠ¡.
> 
> å¤šç§æ–‡ä»¶æ ¼å¼çš„å…ƒæ•°æ®æœåŠ¡,åŒ…æ‹¬TextFile / SequuenceFile / RCFile / ORCFile,å…¶ä¸­é»˜è®¤æ ¼å¼ä¸ºTextFile.
> 
> ç›´æ¥è®¿é—®HDFSæ–‡ä»¶æˆ–å…¶ä»–æ•°æ®å­˜å‚¨ç³»ç»Ÿ(å¦‚: HBase)ä¸­çš„æ–‡ä»¶.
> 
> æ”¯æŒMapReduce / Teza / Spark ç­‰å¤šç§è®¡ç®—å¼•æ“,å¼€å‘è€…å¯æ ¹æ®ä¸åŒçš„æ•°æ®å¤„ç†åœºæ™¯é€‰æ‹©åˆé€‚çš„è®¡ç®—å¼•æ“.
> 
> æ”¯æŒHPL/SQLç¨‹åºè¯­è¨€,HPL/SQLæ˜¯ä¸€ç§æ··åˆå¼‚æ„çš„è¯­è¨€,å¯ä»¥ç†è§£å‡ ä¹ä»»ä½•ç°æœ‰çš„è¿‡ç¨‹æ€§SQLè¯­è¨€çš„è¯­æ³•å’Œè¯­ä¹‰,æœ‰åŠ©äºå°†ä¼ ç»Ÿæ•°æ®ä»“åº“çš„ä¸šåŠ¡é€»è¾‘è¿ç§»åˆ°Hadoopä¸Š,åœ¨Hadoopä¸Šå®ç°ETLæµç¨‹çš„æœ‰æ•ˆæ–¹å¼.
> 
> å¯ä»¥é€šè¿‡HiveLLAP,Yarnè¿›è¡Œç§’çº§åˆ«çš„æŸ¥è¯¢æ£€ç´¢,LLAPç»“åˆäº†æŒä¹…æŸ¥è¯¢æœåŠ¡å™¨å’Œä¼˜åŒ–çš„å†…å­˜ç¼“å­˜,ä½¿Hiveèƒ½å¤Ÿç«‹å³å¯åŠ¨æŸ¥è¯¢,é¿å…ä¸å¿…è¦çš„ç£ç›˜å¼€é”€,æä¾›è¾ƒä½³çš„æŸ¥è¯¢æ£€ç´¢æ•ˆç‡.


### 1.1.3 Hive åº”ç”¨åœºæ™¯
> Hiveæ„å»ºåœ¨Hadoopæ–‡ä»¶ç³»ç»Ÿä¹‹ä¸Š,Hiveä¸æä¾›å®æ—¶çš„æŸ¥è¯¢å’ŒåŸºäºè¡Œçº§æ•°æ®çš„æ›´æ–°æ“ä½œ,ä¸é€‚åˆéœ€è¦ä½å»¶æ—¶ä½œç”¨çš„åº”ç”¨,å¦‚è”æœºäº‹åŠ¡å¤„ç†ç›¸å…³åº”ç”¨.
| ç±»åˆ«       | å…·ä½“åº”ç”¨åœºæ™¯ |
| :-------- | :--------:|
| æ•°æ®æŒ–æ˜    |   ç”¨æˆ·è¡Œä¸ºåˆ†æ / å…´è¶£åˆ†åŒº / åŒºåŸŸå±•ç¤º |
| éå®æ—¶åˆ†ææŒ–æ˜    |   æ—¥å¿—åˆ†æ / æ–‡æœ¬åˆ†æ |
| æ•°æ®æ±‡æ€»   |   ç”¨æˆ·ç‚¹å‡»é‡ç»Ÿè®¡ / æµé‡ç»Ÿè®¡  |
| æ•°æ®ä»“åº“   |   æ•°æ®æŠ½å– / æ•°æ®åŠ è½½ / æ•°æ®è½¬æ¢ |

### 1.2 HIve ä¼˜ç¼ºç‚¹
#### ä¼˜ç‚¹
> 1.æ“ä½œæ¥å£é‡‡ç”¨ç±»SQLè¯­æ³•,æä¾›å¿«é€Ÿå¼€å‘çš„èƒ½åŠ›(ç®€å•å®¹æ˜“ä¸Šæ‰‹).
> 2.é¿å…äº†å»å†™MapReduce,å‡å°‘å¼€å‘äººå‘˜çš„å­¦ä¹ æˆæœ¬.
> 3.Hiveçš„æ‰§è¡Œå»¶è¿Ÿæ¯”è¾ƒé«˜,å› æ­¤Hiveå¸¸ç”¨äºæ•°æ®åˆ†æ,å¯¹å®æ—¶æ€§è¦æ±‚ä¸é«˜çš„åœºåˆ.
> 4.Hiveä¼˜åŠ¿åœ¨äºå¤„ç†å¤§æ•°æ®,å¯¹äºå¤„ç†å°æ•°æ®æ²¡æœ‰ä¼˜åŠ¿,å› ä¸ºHiveçš„æ‰§è¡Œå»¶è¿Ÿæ¯”è¾ƒé«˜.
> 5.Hiveæ”¯æŒå¼€å‘è€…è‡ªå®šä¹‰å‡½æ•°,å¼€å‘è€…å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚æ¥å®ç°è‡ªå·±çš„å‡½æ•°.
#### ç¼ºç‚¹
> 1.Hiveçš„HQLè¡¨è¾¾èƒ½åŠ›æœ‰é™
> (1) è¿­ä»£å¼ç®—æ³•æ— æ³•è¡¨è¾¾.
> (2) æ•°æ®æŒ–æ˜æ–¹é¢ä¸æ“…é•¿.
> 
> 2.Hiveçš„æ•ˆç‡æ¯”è¾ƒä½
> (1) Hiveè‡ªåŠ¨ç”Ÿæˆçš„MapReduceä½œä¸š,é€šå¸¸æƒ…å†µä¸‹ä¸å¤Ÿæ™ºèƒ½åŒ–.
> (2) Hiveè°ƒä¼˜æ¯”è¾ƒå›°éš¾,ç²’åº¦è¾ƒç²—.

### 1.3 HIve æ¶æ„åŸç† ğŸ¤”ğŸ¤”ğŸ¤”

![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hive/start_002.jpg)

> Hiveé€šè¿‡ç»™å¼€å‘è€…æä¾›çš„ä¸€ç³»åˆ—äº¤äº’æ¥å£,æ¥æ”¶åˆ°å¼€å‘è€…çš„æŒ‡ä»¤(SQL),ä½¿ç”¨è‡ªå·±çš„Driver,ç»“åˆå…ƒæ•°æ®(MetaStore),å°†è¿™äº›æŒ‡ä»¤ç¿»è¯‘æˆMapReduce,æäº¤åˆ°Hadoopä¸­æ‰§è¡Œ,æœ€å,å°†æ‰§è¡Œè¿”å›çš„ç»“æœè¾“å‡ºåˆ°å¼€å‘è€…äº¤äº’æ¥å£.
> 
#### 1.ç”¨æˆ·æ¥å£: Client
> CLI (Hive Shell) / JDBC/ODBC (Javaè®¿é—®Hive) / WEBUI (æµè§ˆå™¨è®¿é—®Hive).
#### 2.å…ƒæ•°æ®: Metastore
> å…ƒæ•°æ®åŒ…æ‹¬: è¡¨åã€è¡¨æ‰€å±çš„æ•°æ®åº“(é»˜è®¤æ˜¯default)ã€è¡¨çš„æ‹¥æœ‰è€…,åˆ—/åˆ†åŒºå­—æ®µ/è¡¨çš„ç±»å‹(æ˜¯å¦æ˜¯å¤–éƒ¨è¡¨),è¡¨çš„æ•°æ®æ‰€åœ¨ç›®å½•ç­‰.
> 
> é»˜è®¤å­˜å‚¨åœ¨è‡ªå¸¦çš„derbyæ•°æ®åº“ä¸­,æ¨èä½¿ç”¨MySQLå­˜å‚¨Metastore.
#### 3.Hadoop
> ä½¿ç”¨HDFSè¿›è¡Œå­˜å‚¨,ä½¿ç”¨MapReduceè¿›è¡Œè®¡ç®—.
#### 4.é©±åŠ¨å™¨: Driver
> (1) è§£æå™¨(SQL  Parser): å°†SQLå­—ç¬¦ä¸²è½¬æ¢æˆæŠ½è±¡è¯­æ³•æ ‘AST,è¿™ä¸€æ­¥ä¸€èˆ¬éƒ½ç”¨ç¬¬ä¸‰æ–¹å·¥å…·åº“å®Œæˆ,æ¯”å¦‚antlr,å¯¹ASTè¿›è¡Œè¯­æ³•åˆ†æ,æ¯”å¦‚è¡¨æ˜¯å¦å­˜åœ¨ã€å­—æ®µæ˜¯å¦å­˜åœ¨ã€SQLè¯­ä¹‰æ˜¯å¦æœ‰è¯¯.
> 
> (2) ç¼–è¯‘å™¨(Physical Plan): å°†ASTç¼–è¯‘ç”Ÿæˆé€»è¾‘æ‰§è¡Œè®¡åˆ’.
> 
> (3) ä¼˜åŒ–å™¨(Query Optimizer): å¯¹é€»è¾‘æ‰§è¡Œè®¡åˆ’è¿›è¡Œä¼˜åŒ–.
> 
> (4) æ‰§è¡Œå™¨(Execution): æŠŠé€»è¾‘æ‰§è¡Œè®¡åˆ’è½¬æ¢æˆå¯ä»¥è¿è¡Œçš„ç‰©ç†è®¡åˆ’,å¯¹äºHiveæ¥è¯´,å°±æ˜¯MR & Spark.

### 1.4 HIve & æ•°æ®åº“æ¯”è¾ƒ
> ç”±äºHiveé‡‡ç”¨äº†ç±»ä¼¼SQLçš„æŸ¥è¯¢è¯­è¨€HQL(Hive Query Language),å› æ­¤å¾ˆå®¹æ˜“å°†Hiveç†è§£ä¸ºæ•°æ®åº“.
> 
> å…¶å®ä»ç»“æ„ä¸Šæ¥çœ‹,Hiveå’Œæ•°æ®åº“é™¤äº†æ‹¥æœ‰ç±»ä¼¼çš„æŸ¥è¯¢è¯­è¨€,å†æ— ç±»ä¼¼ä¹‹å¤„,æ•°æ®åº“å¯ä»¥ç”¨åœ¨Onlineçš„åº”ç”¨ä¸­,ä½†æ˜¯Hiveæ˜¯ä¸ºæ•°æ®ä»“åº“è€Œè®¾è®¡çš„,æ¸…æ¥šè¿™ä¸€ç‚¹,æœ‰åŠ©äºä»åº”ç”¨è§’åº¦ç†è§£Hiveçš„ç‰¹æ€§.
#### 1.4.1 æŸ¥è¯¢è¯­è¨€
> ç”±äºSQLè¢«å¹¿æ³›çš„åº”ç”¨åœ¨æ•°æ®ä»“åº“ä¸­,å› æ­¤,ä¸“é—¨é’ˆå¯¹Hiveçš„ç‰¹æ€§è®¾è®¡äº†ç±»SQLçš„æŸ¥è¯¢è¯­è¨€HQL,ç†Ÿæ‚‰SQLå¼€å‘çš„å¼€å‘è€…å¯ä»¥å¾ˆæ–¹ä¾¿çš„ä½¿ç”¨Hiveè¿›è¡Œå¼€å‘.
#### 1.4.2 æ•°æ®å­˜å‚¨ä½ç½®
> Hiveæ˜¯å»ºç«‹åœ¨Hadoopä¹‹ä¸Šçš„,æ‰€æœ‰Hiveçš„æ•°æ®éƒ½æ˜¯å­˜å‚¨åœ¨HDFSä¸­çš„,è€Œæ•°æ®åº“åˆ™å¯ä»¥å°†æ•°æ®ä¿å­˜åœ¨å—è®¾å¤‡æˆ–è€…æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿä¸­.
#### 1.4.3 æ•°æ®æ›´æ–°
> ç”±äºHiveæ˜¯é’ˆå¯¹æ•°æ®ä»“åº“åº”ç”¨è®¾è®¡çš„,è€Œæ•°æ®ä»“åº“çš„å†…å®¹æ˜¯è¯»å¤šå†™å°‘çš„,å› æ­¤Hiveä¸­ä¸å»ºè®®å¯¹æ•°æ®çš„æ”¹å†™,æ‰€æœ‰çš„æ•°æ®éƒ½æ˜¯åœ¨åŠ è½½çš„æ—¶å€™ç¡®å®šå¥½çš„.
> 
> è€Œæ•°æ®åº“ä¸­çš„æ•°æ®é€šå¸¸æ˜¯éœ€è¦ç»å¸¸è¿›è¡Œä¿®æ”¹çš„,å› æ­¤å¯ä»¥ä½¿ç”¨`INSERTINTO...VALUES`æ·»åŠ æ•°æ®,ä½¿ç”¨`UPDATE...SET`ä¿®æ”¹æ•°æ®.
#### 1.4.4 ç´¢å¼•
> Hiveåœ¨åŠ è½½æ•°æ®çš„è¿‡ç¨‹ä¸­ä¸ä¼šå¯¹æ•°æ®è¿›è¡Œä»»ä½•å¤„ç†,ç”šè‡³ä¸ä¼šå¯¹æ•°æ®è¿›è¡Œæ‰«æ,å› æ­¤ä¹Ÿæ²¡æœ‰å¯¹æ•°æ®ä¸­çš„æŸäº›Keyå»ºç«‹ç´¢å¼•.
> 
> Hiveè¦è®¿é—®æ•°æ®ä¸­æ»¡è¶³æ¡ä»¶çš„ç‰¹å®šå€¼æ—¶,éœ€è¦æš´åŠ›æ‰«ææ•´ä¸ªæ•°æ®,å› æ­¤è®¿é—®å»¶è¿Ÿè¾ƒé«˜.
> 
> ç”±äºMapReduceçš„å¼•å…¥,Hiveå¯ä»¥å¹¶è¡Œè®¿é—®æ•°æ®,å› æ­¤å³ä½¿æ²¡æœ‰ç´¢å¼•,å¯¹äºå¤§æ•°æ®é‡çš„è®¿é—®,Hiveä»ç„¶å¯ä»¥ä½“ç°å‡ºä¼˜åŠ¿.
> 
> æ•°æ®åº“ä¸­,é€šå¸¸ä¼šé’ˆå¯¹ä¸€ä¸ªæˆ–è€…å‡ ä¸ªåˆ—å»ºç«‹ç´¢å¼•,å› æ­¤å¯¹äºå°‘é‡çš„ç‰¹å®šæ¡ä»¶çš„æ•°æ®çš„è®¿é—®,æ•°æ®åº“å¯ä»¥æœ‰å¾ˆé«˜çš„æ•ˆç‡,è¾ƒä½çš„å»¶è¿Ÿ,ç”±äºæ•°æ®çš„è®¿é—®å»¶è¿Ÿè¾ƒé«˜,å†³å®šäº†Hiveä¸é€‚åˆåœ¨çº¿æ•°æ®æŸ¥è¯¢.
#### 1.4.5 æ‰§è¡Œ
> Hiveä¸­å¤§å¤šæ•°æŸ¥è¯¢çš„æ‰§è¡Œæ˜¯é€šè¿‡Hadoopæä¾›çš„MapReduceæ¥å®ç°çš„,è€Œæ•°æ®åº“é€šå¸¸æœ‰è‡ªå·±çš„æ‰§è¡Œå¼•æ“.
#### 1.4.6 æ‰§è¡Œå»¶è¿Ÿ
> Hiveåœ¨æŸ¥è¯¢æ•°æ®çš„æ—¶å€™,ç”±äºæ²¡æœ‰ç´¢å¼•,éœ€è¦æ‰«ææ•´ä¸ªæ•°æ®è¡¨,å› æ­¤å»¶è¿Ÿè¾ƒé«˜,å¦å¤–ä¸€ä¸ªå¯¼è‡´Hiveæ‰§è¡Œå»¶è¿Ÿé«˜çš„å› ç´ æ˜¯MapReduceæ¡†æ¶.
> 
> ç”±äºMapReduceæœ¬èº«å…·æœ‰è¾ƒé«˜çš„å»¶è¿Ÿ,å› æ­¤åœ¨åˆ©ç”¨MapReduceæ‰§è¡ŒHiveæŸ¥è¯¢æ—¶,ä¹Ÿä¼šæœ‰è¾ƒé«˜çš„å»¶è¿Ÿ,ç›¸å¯¹çš„æ•°æ®åº“çš„æ‰§è¡Œå»¶è¿Ÿè¾ƒä½,å½“ç„¶,è¿™ä¸ªä½æ˜¯æœ‰æ¡ä»¶çš„,å³æ•°æ®è§„æ¨¡è¾ƒå°,å½“æ•°æ®è§„æ¨¡å¤§åˆ°è¶…è¿‡æ•°æ®åº“çš„å¤„ç†èƒ½åŠ›çš„æ—¶å€™,Hiveçš„å¹¶è¡Œè®¡ç®—æ˜¾ç„¶èƒ½ä½“ç°å‡ºä¼˜åŠ¿.
#### 1.4.7 å¯æ‰©å±•æ€§
> ç”±äºHiveæ˜¯å»ºç«‹åœ¨Hadoopä¹‹ä¸Šçš„,å› æ­¤Hiveçš„å¯æ‰©å±•æ€§æ˜¯å’ŒHadoopçš„å¯æ‰©å±•æ€§æ˜¯ä¸€è‡´çš„(ä¸–ç•Œä¸Šæœ€å¤§çš„Hadoopé›†ç¾¤åœ¨Yahoo!,2009å¹´çš„è§„æ¨¡åœ¨4000å°èŠ‚ç‚¹å·¦å³),è€Œæ•°æ®åº“ç”±äºACIDè¯­ä¹‰çš„ä¸¥æ ¼é™åˆ¶,æ‰©å±•è¡Œéå¸¸æœ‰é™,ç›®å‰æœ€å…ˆè¿›çš„å¹¶è¡Œæ•°æ®åº“Oracleåœ¨ç†è®ºä¸Šçš„æ‰©å±•èƒ½åŠ›ä¹Ÿåªæœ‰100å°å·¦å³.
#### 1.4.8 æ•°æ®è§„æ¨¡
> ç”±äºHiveå»ºç«‹åœ¨é›†ç¾¤ä¸Šå¹¶å¯ä»¥åˆ©ç”¨MapReduceå¹¶è¡Œè®¡ç®—,å› æ­¤å¯ä»¥æ”¯æŒå¾ˆå¤§è§„æ¨¡çš„æ•°æ®,å¯¹åº”çš„æ•°æ®åº“å¯ä»¥æ”¯æŒçš„æ•°æ®è§„æ¨¡è¾ƒå°.

## 2. Hive å®‰è£…éƒ¨ç½²
### 2.1 Hive Download Link
> 1.Hiveå®˜ç½‘: [hive.apache.org/](http://hive.apache.org/)
> 
> 2.Hiveæ–‡æ¡£: [cwiki.apache.org/confluence/display/Hive/](https://cwiki.apache.org/confluence/display/Hive/GettingStarted)
> 
> 3.Github: [github.com/apache/hive](https://github.com/apache/hive)
> 
> 4.Download Link: [archive.apache.org/dist/hive/](http://archive.apache.org/dist/hive/)
> 
> 5.ä»¥apache-hive-1.2.1-bin.tar.gz ç¨³å®šç‰ˆæœ¬ ä¸ºå®ä¾‹è¿›è¡Œå®‰è£….

#### 1. å°†apache-hive-1.2.1-bin.tar.gzä¸Šä¼ è‡³ linux system/opt/softwareç›®å½•ä¸‹
``` powershell
[root@systemhub711 ~]# cd /opt/software/
[root@systemhub711 software]# ll
total 526728
-rw-r--r--. 1 root root  92834839 Mar 24 23:51 apache-hive-1.2.1-bin.tar.gz
-rwxrwxrwx. 1 root root   9621331 Jan 14 09:36 apache-tomcat-8.5.33.tar.gz
-rwxrwxrwx. 1 root root 212046774 Jan 24 20:37 hadoop-2.7.2.tar.gz
-rwxrwxrwx. 1 root root 189815615 Jan 14 10:22 jdk-8u162-linux-x64.tar.gz
-rwxrwxrwx. 1 root root  35042811 Jan 17 19:18 zookeeper-3.4.10.tar.gz
```
#### 2. è§£å‹apache-hive-1.2.1-bin.tar.gz è‡³ /opt/module/ç›®å½•ä¸‹
``` powershell
[root@systemhub711 software]# tar -zxvf apache-hive-1.2.1-bin.tar.gz -C /opt/module/
apache-hive-1.2.1-bin/NOTICE
apache-hive-1.2.1-bin/LICENSE
apache-hive-1.2.1-bin/README.txt
apache-hive-1.2.1-bin/RELEASE_NOTES.txt
apache-hive-1.2.1-bin/examples/files/emp.txt
apache-hive-1.2.1-bin/examples/files/type_evolution.avro
apache-hive-1.2.1-bin/examples/files/extrapolate_stats_partial.txt
apache-hive-1.2.1-bin/examples/files/lineitem.txt
```
#### 3. ä¿®æ”¹apache-hive-1.2.1-bin.tar.gzåŒ…åç§°æ›´æ”¹ä¸ºhive
``` powershell
[root@systemhub711 software]# cd ..
[root@systemhub711 opt]# cd module/
[root@systemhub711 module]# ll
total 20
drwxr-xr-x.  8 root root 4096 Mar 24 23:53 apache-hive-1.2.1-bin
drwxr-xr-x.  9 root root 4096 Feb 24 21:55 apache-tomcat
drwxr-xr-x. 12 root root 4096 Feb 27 14:24 hadoop
drwxr-xr-x.  8 uucp  143 4096 Dec 20  2017 jdk1.8.0_162
drwxr-xr-x. 10 1001 1001 4096 Mar 23  2017 zookeeper
[root@systemhub711 module]# mv apache-hive-1.2.1-bin hive
[root@systemhub711 module]# ll
total 20
drwxr-xr-x.  9 root root 4096 Feb 24 21:55 apache-tomcat
drwxr-xr-x. 12 root root 4096 Feb 27 14:24 hadoop
drwxr-xr-x.  8 root root 4096 Mar 24 23:53 hive
drwxr-xr-x.  8 uucp  143 4096 Dec 20  2017 jdk1.8.0_162
drwxr-xr-x. 10 1001 1001 4096 Mar 23  2017 zookeeper
[root@systemhub711 module]# 
```
#### 4. ä¿®æ”¹/opt/module/hive/confç›®å½•ä¸‹hive-env.sh.templateåç§°æ›´æ”¹ä¸ºhive-env.sh
``` powershell
[root@systemhub711 module]# cd /opt/module/hive/conf
[root@systemhub711 conf]# ll
total 188
-rw-rw-r--. 1 root root   1139 Apr 30  2015 beeline-log4j.properties.template
-rw-rw-r--. 1 root root 168431 Jun 19  2015 hive-default.xml.template
-rw-rw-r--. 1 root root   2378 Apr 30  2015 hive-env.sh.template
-rw-rw-r--. 1 root root   2662 Apr 30  2015 hive-exec-log4j.properties.template
-rw-rw-r--. 1 root root   3050 Apr 30  2015 hive-log4j.properties.template
-rw-rw-r--. 1 root root   1593 Apr 30  2015 ivysettings.xml
[root@systemhub711 conf]# mv hive-env.sh.template hive-env.sh
[root@systemhub711 conf]# ll
total 188
-rw-rw-r--. 1 root root   1139 Apr 30  2015 beeline-log4j.properties.template
-rw-rw-r--. 1 root root 168431 Jun 19  2015 hive-default.xml.template
-rw-rw-r--. 1 root root   2378 Apr 30  2015 hive-env.sh
-rw-rw-r--. 1 root root   2662 Apr 30  2015 hive-exec-log4j.properties.template
-rw-rw-r--. 1 root root   3050 Apr 30  2015 hive-log4j.properties.template
-rw-rw-r--. 1 root root   1593 Apr 30  2015 ivysettings.xml
[root@systemhub711 conf]# 
```

#### 5. é…ç½®ç¯å¢ƒå˜é‡
> åœ¨systemä¸­é…ç½®HIVE_HOME
``` powershell
[root@systemhub711 hive]# vim /etc/profile
```
``` powershell

## SET JAVA_HOME
JAVA_HOME=/opt/module/jdk1.8.0_162
PATH=/opt/module/jdk1.8.0_162/bin:$PATH
export JAVA_HOME PATH

## SET TOMCAT_HOME
TOMCAT_HOME=/opt/module/apache-tomcat
export TOMCAT_HOME

## SET HADOOP_HOME
HADOOP_HOME=/opt/module/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin

## SET HIVE_HOME
export HIVE_HOME=/opt/module/hive
export PATH=$PATH:$HIVE_HOME/bin
```
> é…ç½®å®Œæ¯•,æŒ‰ESC,è¾“å…¥:wq ä¿å­˜å¹¶é€€é€€å‡º.
> 
> æ›´æ–°é…ç½®ä¿¡æ¯
``` powershell
[root@systemhub711 hive]# source /etc/profile
```
> åœ¨hive-env.shé…ç½®HADOOP_HOMEè·¯å¾„ & é…ç½®HIVE_CONF_DIRè·¯å¾„
``` powershell
[root@systemhub711 conf]# echo $HADOOP_HOME
/opt/module/hadoop
[root@systemhub711 conf]# vim hive-env.sh
```
> é…ç½®å®Œæ¯•,æŒ‰ESC,è¾“å…¥:wq ä¿å­˜å¹¶é€€é€€å‡º.
``` powershell
#   fi
# fi

# The heap size of the jvm stared by hive shell script can be controlled via:
#
# export HADOOP_HEAPSIZE=1024
#
# Larger heap size may be required when running queries over large number of files or partitions. 
# By default hive shell scripts use a heap size of 256 (MB).  Larger heap size would also be 
# appropriate for hive server (hwi etc).

# Set HADOOP_HOME to point to a specific hadoop install directory
export HADOOP_HOME=/opt/module/hadoop

# Hive Configuration Directory can be controlled by:
export HIVE_CONF_DIR=/opt/module/hive/conf
```

### 2.2 å¯åŠ¨Hadoopé›†ç¾¤
#### 2.2.3 å¯åŠ¨ HDFS Service
``` powershell
[root@systemhub511 ~]# cd /opt/module/hadoop/
[root@systemhub511 hadoop]# start-dfs.sh
```
#### 2.2.4 å¯åŠ¨ Yarn Service
``` powershell
[root@systemhub611 ~]# cd /opt/module/hadoop/
[root@systemhub611 hadoop]# start-yarn.sh
```
#### 2.2.5 jps æŸ¥çœ‹é›†ç¾¤è¿›ç¨‹
``` powershell
[root@systemhub511 hadoop]# jps
11121 NameNode
15719 Jps
11323 DataNode
15118 NodeManager
[root@systemhub511 hadoop]# 

[root@systemhub611 hadoop]# jps
9106 NodeManager
5865 DataNode
10650 Jps
7629 ResourceManager
[root@systemhub611 hadoop]# 

[root@systemhub711 hadoop]# jps
3089 Jps
30667 DataNode
1629 NodeManager
30974 SecondaryNameNode
[root@systemhub711 hadoop]# 
```
#### 2.2.6 åœ¨HDFSä¸Šåˆ›å»ºç›®å½•
> åˆ›å»º/tmpå’Œ/user/hive/warehouseä¸¤ä¸ªç›®å½•å¹¶ä¿®æ”¹åŒç»„æƒé™ä¸ºå¯å†™
```
[root@systemhub611 hadoop]# hadoop fs -mkdir /tmp
[root@systemhub511 hadoop]# hadoop fs -mkdir -p  /user/hive/warehouse
```
```
[root@systemhub511 hadoop]# hadoop fs -chmod 777 /tmp
[root@systemhub511 hadoop]# hadoop fs -chmod 777 /user/hive/warehouse
```

#### 2.2.7 HiveåŸºæœ¬æ“ä½œ
##### 2.2.7.1 å¯åŠ¨ Hive Service
``` powershell
[root@systemhub711 hive]# bin/hive
Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
hive> 
```
##### 2.2.7.2 æŸ¥çœ‹æ•°æ®åº“
```
hive> show databases;
OK
default
Time taken: 0.039 seconds, Fetched: 1 row(s) 
```
##### 2.2.7.3 æ‰“å¼€é»˜è®¤æ•°æ®åº“
```
hive> use default;
OK
Time taken: 0.06 seconds
hive> 
```
##### 2.2.7.4 æ˜¾ç¤ºdefaultæ•°æ®åº“ä¸­çš„è¡¨
```
hive> show tables;
OK
Time taken: 0.136 seconds
hive> 
```
##### 2.2.7.5 åˆ›å»ºä¸€å¼ è¡¨
```
hive> create table test(id int,name string);
OK
Time taken: 0.584 seconds
```
##### 2.2.7.6 æ˜¾ç¤ºæ•°æ®åº“ä¸­æœ‰å‡ å¼ è¡¨
```
hive> show tables;
OK
test
Time taken: 0.043 seconds, Fetched: 1 row(s)
hive> 
```
##### 2.2.7.7 æŸ¥çœ‹è¡¨çš„ç»“æ„
```
hive> desc test;
OK
id                      int                                         
name                    string                                      
Time taken: 0.181 seconds, Fetched: 2 row(s)
hive> 
```
##### 2.2.7.8 å‘è¡¨ä¸­æ’å…¥æ•°æ®
```
hive> insert into test values(1,"TestUser001");
Query ID = root_20190325104557_f36e7f6e-0254-4e4e-9216-60f08042dabb
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1553477836311_0001, Tracking URL = http://systemhub611:8088/proxy/application_1553477836311_0001/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553477836311_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
2019-03-25 10:46:18,198 Stage-1 map = 0%,  reduce = 0%
2019-03-25 10:46:26,679 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.96 sec
MapReduce Total cumulative CPU time: 1 seconds 960 msec
Ended Job = job_1553477836311_0001
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to: hdfs://systemhub511:9000/user/hive/warehouse/test/.hive-staging_hive_2019-03-25_10-45-57_843_1729594574229184317-1/-ext-10000
Loading data to table default.test
Table default.test stats: [numFiles=1, numRows=1, totalSize=14, rawDataSize=13]
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1   Cumulative CPU: 1.96 sec   HDFS Read: 3566 HDFS Write: 82 SUCCESS
Total MapReduce CPU Time Spent: 1 seconds 960 msec
OK
Time taken: 31.477 seconds
hive> 
```
##### 2.2.7.9 æŸ¥è¯¢è¡¨ä¸­æ•°æ®
```
hive> select * from test;
OK
1       TestUser001
Time taken: 0.144 seconds, Fetched: 1 row(s)
hive>
```
##### 2.2.7.10 é€€å‡ºhive
```
hive> quit;
[root@systemhub711 hive]# 
```

#### 2.2.8 Hiveå®æ“æ¡ˆä¾‹
##### 2.2.8.1 å°†æœ¬åœ°æ–‡ä»¶å¯¼å…¥Hiveä¸­
> éœ€æ±‚: å°†æœ¬åœ° /opt/module/datas/test.txt,è¿™ä¸ªç›®å½•ä¸‹çš„æ•°æ®å¯¼å…¥åˆ°hiveçš„test(id int, name string)æ•°æ®è¡¨ä¸­.
###### 1.æ•°æ®å‡†å¤‡
> åœ¨/opt/module/ç›®å½•ä¸‹åˆ›å»ºdatas
> 
> åœ¨/opt/module/datas/ç›®å½•ä¸‹åˆ›å»ºtest.txtæ–‡ä»¶å¹¶æ·»åŠ æ•°æ®,ä»¥Tabé”®é—´éš”
```
[root@systemhub711 ~]# cd /opt/module/
[root@systemhub711 module]# mkdir datas
[root@systemhub711 module]# cd datas/
[root@systemhub711 datas]# touch test.txt
[root@systemhub711 datas]# ll
total 0
-rw-r--r--. 1 root root 0 Mar 25 16:02 test.txt
[root@systemhub711 datas]#
[root@systemhub711 datas]# vim test.txt
```
```
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
```
###### 2.å¯åŠ¨ Hadoopé›†ç¾¤ & Hive
```
[root@systemhub711 ~]# cd /opt/module/hive/
[root@systemhub711 hive]# bin/hive
Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
hive>
```
###### 3.åˆ›å»ºtest001æ•°æ®è¡¨,å¹¶å£°æ˜æ–‡ä»¶åˆ†éš”ç¬¦"\t"
```
hive> create table test001(id int,name string) row format delimited fields terminated by "\t";
OK
Time taken: 0.222 seconds
hive> 
```
###### 4.å°†æ–‡ä»¶åŠ è½½åˆ°æ•°æ®è¡¨ä¸­
```
hive> load data local inpath "/opt/module/datas/test.txt" into table test001;
Loading data to table default.test
Table default.test stats: [numFiles=1, totalSize=56]
OK
Time taken: 0.479 seconds
hive>
```
###### 5.æŸ¥è¯¢æ•°æ®
```
hive> select * from test;
OK
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
Time taken: 0.076 seconds, Fetched: 4 row(s)
hive> 
```
##### 2.2.8.2 MySqlå®‰è£…
###### 1.å®‰è£…åŒ…å‡†å¤‡
> æŸ¥çœ‹mysqlæ˜¯å¦å®‰è£…,å¦‚æœå®‰è£…äº†,å¸è½½mysql.
```
[root@systemhub711 ~]# rpm -qa|grep mysql
mysql-libs-5.1.71-1.el6.x86_64
[root@systemhub711 ~]# rpm -e --nodeps mysql-libs-5.1.71-1.el6.x86_64
[root@systemhub711 ~]# 
```
> è§£å‹mysql-libs.zipæ–‡ä»¶åˆ°å½“å‰ç›®å½•.
```
[root@systemhub711 ~]# cd /opt/software/
[root@systemhub711 software]# unzip mysql-libs.zip
Archive:  mysql-libs.zip
   creating: mysql-libs/
  inflating: mysql-libs/MySQL-client-5.6.24-1.el6.x86_64.rpm  
  inflating: mysql-libs/mysql-connector-java-5.1.27.tar.gz  
  inflating: mysql-libs/MySQL-server-5.6.24-1.el6.x86_64.rpm  
```

##### 2.2.8.3 å®‰è£…MySqlæœåŠ¡ç«¯
> å®‰è£…mysqlæœåŠ¡ç«¯
```
[root@systemhub711 mysql-libs]# rpm -ivh MySQL-server-5.6.24-1.el6.x86_64.rpm
Preparing...                ########################################### [100%]
   1:MySQL-server           ########################################### [100%]
```
> å®‰è£…mysqlå®¢æˆ·ç«¯
```
[root@systemhub711 mysql-libs]# rpm -ivh MySQL-client-5.6.24-1.el6.x86_64.rpm
Preparing...                ########################################### [100%]
   1:MySQL-client           ########################################### [100%]
[root@systemhub711 mysql-libs]# 
```
> æŸ¥çœ‹äº§ç”Ÿçš„éšæœºå¯†ç 
```
[root@systemhub711 mysql-libs]# cat /root/.mysql_secret
# The random password set for the root user at Mon Mar 25 17:28:10 2019 (local time): 3krFauiObIJZG_xd
[root@systemhub711 mysql-libs]# 
```
> æŸ¥çœ‹mysqlçŠ¶æ€ å¹¶ å¼€å¯æœåŠ¡
```
[root@systemhub711 mysql-libs]# service mysql status
MySQL is not running                                       [å¤±è´¥]
[root@systemhub711 mysql-libs]# service mysql start
Starting MySQL..                                           [ç¡®å®š]
```
> ç™»å½•mysql
```
[root@systemhub711 mysql-libs]# mysql -uroot -p3krFauiObIJZG_xd
Warning: Using a password on the command line interface can be insecure.
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 2
Server version: 5.6.24

Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
mysql> 
```
> è®¾ç½®è‡ªå®šä¹‰ç™»å½•å¯†ç 
```
mysql> set password=password("000000");
Query OK, 0 rows affected (0.01 sec)
mysql> 
```
##### 2.2.8.4 MySqlæ— ä¸»æœºé…ç½®
> é…ç½®åªè¦æ˜¯rootç”¨æˆ·+password,å³å¯åœ¨ä»»ä½•ä¸»æœºä¸Šéƒ½èƒ½ç™»å½•MySQLæ•°æ®åº“.
> 
> ç™»å½•mysql
```
[root@systemhub711 mysql-libs]# mysql -uroot -p
Enter password: 
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 3
Server version: 5.6.24 MySQL Community Server (GPL)

Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
mysql> 
```
> æ˜¾ç¤ºå½“å‰æ•°æ®åº“
```
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| test               |
+--------------------+
4 rows in set (0.01 sec)

mysql> 
```
> è¿›å…¥mysqlæ•°æ®åº“
```
mysql> use mysql;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A
Database changed
mysql>
```
> æŸ¥è¯¢mysqlæ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨
```
mysql> show tables;
+---------------------------+
| Tables_in_mysql           |
+---------------------------+
| columns_priv              |
| db                        |
| event                     |
| func                      |
| general_log               |
| help_category             |
| help_keyword              |
| help_relation             |
| help_topic                |
| innodb_index_stats        |
| innodb_table_stats        |
| ndb_binlog_index          |
| plugin                    |
| proc                      |
| procs_priv                |
| proxies_priv              |
| servers                   |
| slave_master_info         |
| slave_relay_log_info      |
| slave_worker_info         |
| slow_log                  |
| tables_priv               |
| time_zone                 |
| time_zone_leap_second     |
| time_zone_name            |
| time_zone_transition      |
| time_zone_transition_type |
| user                      |
+---------------------------+
28 rows in set (0.00 sec)
mysql>
```
> æŸ¥è¯¢useræ•°æ®è¡¨
```
mysql> select User, Host, Password from user;
+------+--------------+-------------------------------------------+
| User | Host         | Password                                  |
+------+--------------+-------------------------------------------+
| root | localhost    | *032197AE5731D4664921A6CCAC7CFCE6A0698693 |
| root | systemhub711 | *DB2C3C3C317DE3F3FEFF12C9A60985CA29A7BBCD |
| root | 127.0.0.1    | *DB2C3C3C317DE3F3FEFF12C9A60985CA29A7BBCD |
| root | ::1          | *DB2C3C3C317DE3F3FEFF12C9A60985CA29A7BBCD |
+------+--------------+-------------------------------------------+
4 rows in set (0.01 sec)
mysql> 
```
> ä¿®æ”¹userè¡¨,æŠŠHostè¡¨å†…å®¹ä¿®æ”¹ä¸º`%`
```
mysql> update user set host='%' where host='localhost';
Query OK, 1 row affected (0.00 sec)
Rows matched: 1  Changed: 1  Warnings: 0

mysql> select User, Host, Password from user;
+------+--------------+-------------------------------------------+
| User | Host         | Password                                  |
+------+--------------+-------------------------------------------+
| root | %            | *032197AE5731D4664921A6CCAC7CFCE6A0698693 |
| root | systemhub711 | *DB2C3C3C317DE3F3FEFF12C9A60985CA29A7BBCD |
| root | 127.0.0.1    | *DB2C3C3C317DE3F3FEFF12C9A60985CA29A7BBCD |
| root | ::1          | *DB2C3C3C317DE3F3FEFF12C9A60985CA29A7BBCD |
+------+--------------+-------------------------------------------+
4 rows in set (0.00 sec)
mysql> 
```
> åˆ é™¤rootç”¨æˆ·çš„å…¶ä»–host
```
mysql> delete from user where Host='systemhub711';
Query OK, 1 row affected (0.00 sec)

mysql> delete from user where Host='127.0.0.1';
Query OK, 1 row affected (0.00 sec)

mysql> delete from user where Host='::1';
Query OK, 1 row affected (0.00 sec)

mysql> select User, Host, Password from user;
+------+------+-------------------------------------------+
| User | Host | Password                                  |
+------+------+-------------------------------------------+
| root | %    | *032197AE5731D4664921A6CCAC7CFCE6A0698693 |
+------+------+-------------------------------------------+
1 row in set (0.00 sec)
mysql> 
```
> åˆ·æ–°
```
mysql> flush privileges;
Query OK, 0 rows affected (0.00 sec)
mysql> 
```
> é€€å‡º
```
mysql> exit;
Bye
[root@systemhub711 mysql-libs]# 
```

##### 2.2.8.5 é…ç½®Metastoreåˆ°MySql
> 1.åœ¨/opt/module/hive/confç›®å½•ä¸‹åˆ›å»ºhive-site.xmlé…ç½®æ–‡ä»¶.
```
[root@systemhub711 ~]# cd /opt/module/hive/conf/
[root@systemhub711 conf]# touch hive-site.xml
[root@systemhub711 conf]# vim hive-site.xml
```
> 2.æ ¹æ®å®˜æ–¹æ–‡æ¡£é…ç½®å‚æ•°,æ‹·è´æ•°æ®åˆ°hive-site.xmlé…ç½®æ–‡ä»¶ä¸­ | [Hiveå®˜æ–¹é…ç½®æ–‡æ¡£](https://cwiki.apache.org/confluence/display/Hive/AdminManual+Metastore+Administration).
``` xml
<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
      <name>javax.jdo.option.ConnectionURL</name>
      <value>jdbc:mysql://systemhub711:3306/metastore?createDatabaseIfNotExist=true</value>
      <description>JDBC connect string for a JDBC metastore</description>
    </property>

    <property>
      <name>javax.jdo.option.ConnectionDriverName</name>
      <value>com.mysql.jdbc.Driver</value>
      <description>Driver class name for a JDBC metastore</description>
    </property>

    <property>
       <name>javax.jdo.option.ConnectionUserName</name>
       <value>root</value>
       <description>username to use against metastore database</description>
    </property>

    <property>
       <name>javax.jdo.option.ConnectionPassword</name>
       <value>000000</value>
       <description>passwordto use against metastore database</description>
    </property>

</configuration>
```
> é©±åŠ¨æ‹·è´
> å°†/opt/software/mysql-libsç›®å½•ä¸‹è§£å‹mysql-connector-java-5.1.27.tar.gzé©±åŠ¨åŒ….
```
[root@systemhub711 opt]# cd software/mysql-libs
[root@systemhub711 mysql-libs]# tar -zvxf mysql-connector-java-5.1.27.tar.gz
mysql-connector-java-5.1.27/
mysql-connector-java-5.1.27/docs/
mysql-connector-java-5.1.27/src/
mysql-connector-java-5.1.27/src/com/
mysql-connector-java-5.1.27/src/com/mysql/
mysql-connector-java-5.1.27/src/com/mysql/jdbc/
mysql-connector-java-5.1.27/src/com/mysql/jdbc/authentication/
```
> å°†mysql-connector-java-5.1.27-bin.jaråˆ°/opt/module/hive/lib/
```
[root@systemhub711 mysql-libs]# cd mysql-connector-java-5.1.27
[root@systemhub711 mysql-connector-java-5.1.27]# ll
total 1272
-rw-r--r--. 1 root root  47173 Oct 24  2013 build.xml
-rw-r--r--. 1 root root 222520 Oct 24  2013 CHANGES
-rw-r--r--. 1 root root  18122 Oct 24  2013 COPYING
drwxr-xr-x. 2 root root   4096 Mar 25 20:56 docs
-rw-r--r--. 1 root root 872303 Oct 24  2013 mysql-connector-java-5.1.27-bin.jar
-rw-r--r--. 1 root root  61423 Oct 24  2013 README
-rw-r--r--. 1 root root  63674 Oct 24  2013 README.txt
drwxr-xr-x. 7 root root   4096 Oct 24  2013 src
[root@systemhub711 mysql-connector-java-5.1.27]# cp mysql-connector-java-5.1.27-bin.jar /opt/module/hive/lib/
[root@systemhub711 mysql-connector-java-5.1.27]# cd /opt/module/hive/lib/
[root@systemhub711 lib]# ll
-rw-r--r--.  1 root root   872303 Mar 25 20:58 mysql-connector-java-5.1.27-bin.jar
```
> é…ç½®å®Œæ¯•å,å…ˆå¯åŠ¨MySQL,æŸ¥çœ‹æœ‰å‡ ä¸ªæ•°æ®åº“,ä¾ç„¶è¿˜æ˜¯å››ä¸ª.
```
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| test               |
+--------------------+
4 rows in set (0.01 sec)
mysql> 
```
> å†æ¬¡æ‰“å¼€å¤šä¸ªçª—å£,åˆ†åˆ«å¯åŠ¨hive.
```
[root@systemhub711 hive]# bin/hive

Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
hive>
```
> å¯åŠ¨hiveå,å›åˆ°MySQLçª—å£æŸ¥çœ‹æ•°æ®åº“,æ˜¾ç¤ºå¢åŠ äº†metastoreæ•°æ®åº“.
```
mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| metastore          |
| mysql              |
| performance_schema |
| test               |
+--------------------+
5 rows in set (0.00 sec)
mysql> 
```
> å»metastoreæ•°æ®åº“ å–½ä¸€çœ¼.
```
mysql> use metastore;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A
Database changed
mysql> show tables;
+---------------------------+
| Tables_in_metastore       |
+---------------------------+
| BUCKETING_COLS            |
| CDS                       |
| COLUMNS_V2                |
| DATABASE_PARAMS           |
| DBS                       |
| FUNCS                     |
| FUNC_RU                   |
| GLOBAL_PRIVS              |
| PARTITIONS                |
| PARTITION_KEYS            |
| PARTITION_KEY_VALS        |
| PARTITION_PARAMS          |
| PART_COL_STATS            |
| ROLES                     |
| SDS                       |
| SD_PARAMS                 |
| SEQUENCE_TABLE            |
| SERDES                    |
| SERDE_PARAMS              |
| SKEWED_COL_NAMES          |
| SKEWED_COL_VALUE_LOC_MAP  |
| SKEWED_STRING_LIST        |
| SKEWED_STRING_LIST_VALUES |
| SKEWED_VALUES             |
| SORT_COLS                 |
| TABLE_PARAMS              |
| TAB_COL_STATS             |
| TBLS                      |
| VERSION                   |
+---------------------------+
29 rows in set (0.00 sec)
mysql>
```

##### 2.2.8.6 Hiveå¸¸ç”¨äº¤äº’å‘½ä»¤
###### 1. Hive å¸®åŠ©æŒ‡ä»¤
```
[root@systemhub711 hive]# bin/hive -help
usage: hive
 -d,--define <key=value>          Variable subsitution to apply to hive
                                  commands. e.g. -d A=B or --define A=B
    --database <databasename>     Specify the database to use
 -e <quoted-query-string>         SQL from command line
 -f <filename>                    SQL from files
 -H,--help                        Print help information
    --hiveconf <property=value>   Use value for given property
    --hivevar <key=value>         Variable subsitution to apply to hive
                                  commands. e.g. --hivevar A=B
 -i <filename>                    Initialization SQL file
 -S,--silent                      Silent mode in interactive shell
 -v,--verbose                     Verbose mode (echo executed SQL to the
                                  console)
[root@systemhub711 hive]# 
```

###### 2. -e ä¸è¿›å…¥hiveäº¤äº’çª—å£,å³å¯æ‰§è¡Œsqlè¯­å¥
```
[root@systemhub711 hive]# bin/hive -e "select * from test";

Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
OK
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
Time taken: 2.328 seconds, Fetched: 4 row(s)
[root@systemhub711 hive]# 
```

###### 3. -f æ‰§è¡Œè„šæœ¬ä¸­,æ‰§è¡Œsqlè¯­å¥
> åœ¨/opt/module/datasç›®å½•ä¸‹åˆ›å»º test_hivef.hqlæ–‡ä»¶
```
[root@systemhub711 hive]# cd ..
[root@systemhub711 module]# cd datas/
[root@systemhub711 datas]# touch test_hivef.hql
[root@systemhub711 datas]# ll
total 4
-rw-r--r--. 1 root root  0 Mar 25 22:24 test_hivef.hql
-rw-r--r--. 1 root root 56 Mar 25 16:46 test.txt
[root@systemhub711 datas]# vim test_hivef.hql
```
> æ–‡ä»¶ä¸­å†™å…¥æ­£ç¡®çš„sqlè¯­å¥
```
select * from test;
```
> æ‰§è¡Œæ–‡ä»¶ä¸­çš„sqlè¯­å¥
```
[root@systemhub711 datas]# cd /opt/module/hive/
[root@systemhub711 hive]# bin/hive -f /opt/module/datas/test_hivef.hql

Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
OK
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
Time taken: 2.012 seconds, Fetched: 4 row(s)
[root@systemhub711 hive]#
```
> æ‰§è¡Œæ–‡ä»¶ä¸­çš„sqlè¯­å¥å¹¶å°†ç»“æœå†™å…¥æ–‡ä»¶ä¸­
```
[root@systemhub711 hive]# bin/hive -f /opt/module/datas/test_hivef.hql > /opt/module/datas/test_hivef_result.txt

Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
OK
Time taken: 1.794 seconds, Fetched: 4 row(s)
[root@systemhub711 hive]# cat /opt/module/datas/test_hivef_result.txt
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
[root@systemhub711 hive]# 
```

##### 2.2.8.7 Hive å…¶ä»–å‘½ä»¤æ“ä½œ
###### 2.2.8.7.1 é€€å‡ºhiveçª—å£
> åœ¨æ–°ç‰ˆçš„oracleæ•°æ®åº“ä¸­ä¸¤ä¸ªé€€å‡ºæŒ‡ä»¤å·²ç»æ²¡æœ‰åŒºåˆ«äº†,åœ¨ä»¥å‰çš„ç‰ˆæœ¬æ˜¯æœ‰åŒºåˆ«.
> exit:å…ˆéšæ€§æäº¤æ•°æ®,å†é€€å‡º; quit:ä¸æäº¤æ•°æ®,é€€å‡º;
```
[root@systemhub711 hive]# bin/hive
Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
hive> quit;
[root@systemhub711 hive]# 
[root@systemhub711 hive]# bin/hive
Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-1.2.1.jar!/hive-log4j.properties
hive> exit;
[root@systemhub711 hive]# 
```
###### 2.2.8.7.2 åœ¨Hive CLIå‘½ä»¤çª—å£ä¸­æŸ¥çœ‹hdfsæ–‡ä»¶ç³»ç»Ÿ
```
hive> dfs -ls / ;
Found 3 items
drwxr-xr-x   - root supergroup          0 2019-01-27 14:35 /group
drwxrwxrwx   - root supergroup          0 2019-01-25 10:09 /tmp
drwxr-xr-x   - root supergroup          0 2019-01-25 09:58 /user
hive> 
```
###### 2.2.8.7.3 åœ¨Hive CLIå‘½ä»¤çª—å£ä¸­æŸ¥çœ‹hdfsæœ¬åœ°ç³»ç»Ÿ
```
hive> ! ls /opt/module;
apache-tomcat
datas
hadoop
hive
jdk1.8.0_162
zookeeper
hive> 
```
###### 2.2.8.7.4 æŸ¥çœ‹åœ¨Hiveä¸­è¾“å…¥æ‰€æœ‰å†å²å‘½ä»¤
> è¿›å…¥åˆ°å½“å‰ç”¨æˆ·çš„æ ¹ç›®å½•æ‰§è¡Œå†å²å‘½ä»¤.
```
[root@systemhub711 module]# cd
[root@systemhub711 ~]# cat .hivehistory
show databases;
show databases;
use default;
show tables;
create table test(id int,name string);
show tables;
insert into test(1,"TestUser001");
insert into test value(1,"TestUser001");
insert into test values(1,"TestUser001");
select * form test;
select * from test;
desc test;
quit;
load data local inpath "/opt/module/datas/test.txt" into table test;
select * form test;
select * from test;
drop table test;
create table test(id int,name string) row format delimited fields terminated by "\t";
load data local inpath "/opt/module/datas/test.txt" into table test;
select * from test;
exit;
[root@systemhub711 ~]# 
```

##### 2.2.8.8 Hiveå¸¸è§å±æ€§é…ç½®
###### 2.2.8.8.1 Hiveæ•°æ®ä»“åº“ä½ç½®é…ç½®
> 1.Defaultæ•°æ®ä»“åº“æœ€åŸå§‹ä½ç½®æ˜¯åœ¨hdfsä¸Šçš„: /user/hive/warehouseè·¯å¾„ä¸‹.
> 
> 2.åœ¨ä»“åº“ç›®å½•ä¸‹,æ²¡æœ‰å¯¹é»˜è®¤çš„æ•°æ®åº“defaultåˆ›å»ºæ–‡ä»¶å¤¹,å¦‚æœæŸå¼ æ•°æ®è¡¨å±äºdefaultæ•°æ®åº“,ç›´æ¥ä¼šåœ¨æ•°æ®ä»“åº“ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªæ–‡ä»¶å¤¹.
> 
> 3.ä¿®æ”¹defaultæ•°æ®ä»“åº“åŸå§‹ä½ç½®.
> 1.åœ¨hive-site.xmlé…ç½®æ–‡ä»¶ä¸­è¿½åŠ ä¸€ä¸‹é…ç½®ä¿¡æ¯.
``` xml
<property>
  <name>hive.metastore.warehouse.dir</name>
  <value>/user/hive/warehouse</value>
  <description>location of default database for the warehouse</description>
</property>
```
###### 2.2.8.8.2 é…ç½®æŸ¥è¯¢åä¿¡æ¯æ˜¾ç¤º
> 1.åœ¨hive-site.xmlæ–‡ä»¶ä¸­æ·»åŠ å¦‚ä¸‹é…ç½®ä¿¡æ¯,å°±å¯ä»¥å®ç°æ˜¾ç¤ºå½“å‰æ•°æ®åº“,ä»¥åŠæŸ¥è¯¢è¡¨çš„å¤´ä¿¡æ¯é…ç½®.
``` xml
<property> 
  <name>hive.cli.print.header</name>  
  <value>true</value> 
</property>

<property> 
  <name>hive.cli.print.current.db</name>  
  <value>true</value> 
</property>
```
> 2.é‡æ–°å¯åŠ¨hive,å¯¹æ¯”é…ç½®å‰åå·®å¼‚.
> 
> é…ç½®å‰.
```
hive> select * from test;
OK
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
Time taken: 0.808 seconds, Fetched: 4 row(s)
hive> 
```

> é…ç½®å.
```
hive (default)> select * from test;
OK
test.id test.name
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
Time taken: 1.708 seconds, Fetched: 4 row(s)
hive (default)> 
```

###### 2.2.8.8.3 Hiveè¿è¡Œæ—¥å¿—ä¿¡æ¯é…ç½®
> 1.Hiveçš„logé»˜è®¤å­˜æ”¾åœ¨/tmp/root/hive.logç›®å½•ä¸‹(å½“å‰ç”¨æˆ·åä¸‹).
> 2.ä¿®æ”¹hiveçš„logå­˜æ”¾æ—¥å¿—åˆ°/opt/module/hive/logs
> 2.1å°†hive-log4j.properties.templateæ–‡ä»¶åç§°ä¿®æ”¹ä¸ºhive-log4j.properties
```
[root@systemhub711 conf]# pwd
/opt/module/hive/conf
[root@systemhub711 conf]# ll
total 192
-rw-rw-r--. 1 root root   1139 Apr 30  2015 beeline-log4j.properties.template
-rw-rw-r--. 1 root root 168431 Jun 19  2015 hive-default.xml.template
-rw-rw-r--. 1 root root   2401 Mar 25 00:10 hive-env.sh
-rw-rw-r--. 1 root root   2662 Apr 30  2015 hive-exec-log4j.properties.template
-rw-rw-r--. 1 root root   3050 Apr 30  2015 hive-log4j.properties.template
-rw-r--r--. 1 root root   1416 Mar 25 23:11 hive-site.xml
-rw-rw-r--. 1 root root   1593 Apr 30  2015 ivysettings.xml
[root@systemhub711 conf]# mv hive-log4j.properties.template hive-log4j.properties
[root@systemhub711 conf]# ll
total 192
-rw-rw-r--. 1 root root   1139 Apr 30  2015 beeline-log4j.properties.template
-rw-rw-r--. 1 root root 168431 Jun 19  2015 hive-default.xml.template
-rw-rw-r--. 1 root root   2401 Mar 25 00:10 hive-env.sh
-rw-rw-r--. 1 root root   2662 Apr 30  2015 hive-exec-log4j.properties.template
-rw-rw-r--. 1 root root   3050 Apr 30  2015 hive-log4j.properties
-rw-r--r--. 1 root root   1416 Mar 25 23:11 hive-site.xml
-rw-rw-r--. 1 root root   1593 Apr 30  2015 ivysettings.xml
[root@systemhub711 conf]# 
```
> åœ¨hive-log4j.propertiesé…ç½®æ–‡ä»¶ä¸­ä¿®æ”¹logå­˜æ”¾ä½ç½®.
```
[root@systemhub711 conf]# vim hive-log4j.properties
```

```
-rw-r--r--. 1 root root   1416 Mar 25 23:11 hive-site.xml
-rw-rw-r--. 1 root root   1593 Apr 30  2015 ivysettings.xml
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Define some default values that can be overridden by system properties
hive.log.threshold=ALL
hive.root.logger=INFO,DRFA
hive.log.dir=/opt/module/hive/logs
```

###### 2.2.8.8.4 å‚æ•°é…ç½®æ–¹å¼
> 1.æŸ¥çœ‹å½“å‰æ‰€æœ‰çš„é…ç½®ä¿¡æ¯.
```
hive (default)> set;
_hive.hdfs.session.path=/tmp/hive/root/3227b090-9545-485f-bae7-b9b31cadc61d
_hive.local.session.path=/tmp/root/3227b090-9545-485f-bae7-b9b31cadc61d
_hive.tmp_table_space=/tmp/hive/root/3227b090-9545-485f-bae7-b9b31cadc61d/_tmp_space.db
datanucleus.autoCreateSchema=true
datanucleus.autoStartMechanismMode=checked
datanucleus.cache.level2=false
datanucleus.cache.level2.type=none
datanucleus.connectionPoolingType=BONECP
datanucleus.fixedDatastore=false
```

> 2.å‚æ•°çš„é…ç½®ä¸‰ç§æ–¹å¼.
> 
> 2.1 é…ç½®æ–‡ä»¶æ–¹å¼
> 
> é»˜è®¤é…ç½®æ–‡ä»¶: hive-default.xml
> 
> å¼€å‘è€…è‡ªå®šä¹‰é…ç½®æ–‡ä»¶: hive-site.xml
> 
> æ³¨æ„: å¼€å‘è€…è‡ªå®šä¹‰é…ç½®ä¼šè¦†ç›–é»˜è®¤é…ç½®,å¦å¤–,Hiveä¹Ÿä¼šè¯»å…¥Hadoopçš„é…ç½®,å› ä¸ºHiveæ˜¯ä½œä¸ºHadoopçš„å®¢æˆ·ç«¯å¯åŠ¨çš„,Hiveçš„é…ç½®ä¼šè¦†ç›–Hadoopçš„é…ç½®,é…ç½®æ–‡ä»¶çš„è®¾å®šå¯¹æœ¬æœºå¯åŠ¨çš„æ‰€æœ‰Hiveè¿›ç¨‹éƒ½æœ‰æ•ˆ.
> 
> 2.2 å‘½ä»¤è¡Œå‚æ•°æ–¹å¼
> 
> å¯åŠ¨Hiveæ—¶,å¯ä»¥åœ¨å‘½ä»¤è¡Œæ·»åŠ `-hiveconf param=value`æ¥è®¾å®šå‚æ•°.
> `ä»…å¯¹æœ¬æ¬¡hiveå¯åŠ¨æœ‰æ•ˆ`
```
[root@systemhub711 hive]# bin/hive -hiveconf mapred.reduce.tasks=10
Logging initialized using configuration in file:/opt/module/hive/conf/hive-log4j.properties
hive (default)> 
```
> æŸ¥çœ‹å‚æ•°è®¾ç½®
```
hive (default)> set mapred.reduce.tasks;
mapred.reduce.tasks=10
hive (default)> 
```
> 2.3 å‚æ•°å£°æ˜æ–¹å¼
> å¯ä»¥åœ¨HQLä¸­ä½¿ç”¨SETå…³é”®å­—è®¾å®šå‚æ•°.
> `ä»…å¯¹æœ¬æ¬¡hiveå¯åŠ¨æœ‰æ•ˆ`
```
[root@systemhub711 hive]# bin/hive -hiveconf mapred.reduce.tasks=100
Logging initialized using configuration in file:/opt/module/hive/conf/hive-log4j.properties
hive (default)> 
```
> æŸ¥çœ‹å‚æ•°è®¾ç½®
```
hive (default)> set mapred.reduce.tasks;
mapred.reduce.tasks=100
hive (default)> 
```
> ä¸Šè¿°ä¸‰ç§è®¾å®šæ–¹å¼çš„ä¼˜å…ˆçº§ä¾æ¬¡é€’å¢.
> 
> å³é…ç½®æ–‡ä»¶ `<` å‘½ä»¤è¡Œå‚æ•° `<` å‚æ•°å£°æ˜.
> 
> æ³¨æ„æŸäº›ç³»ç»Ÿçº§çš„å‚æ•°,ä¾‹å¦‚log4jç›¸å…³çš„è®¾å®š,å¿…é¡»ç”¨å‰ä¸¤ç§æ–¹å¼è®¾å®š,å› ä¸ºé‚£äº›å‚æ•°çš„è¯»å–åœ¨ä¼šè¯å»ºç«‹ä»¥å‰å·²ç»å®Œæˆäº†.


## 3. Hive æ•°æ®ç±»å‹
### 3.1 åŸºæœ¬æ•°æ®ç±»å‹
> å¯¹äºHiveçš„Stringç±»å‹ç›¸å½“äºæ•°æ®åº“çš„varcharç±»å‹,è¯¥ç±»å‹æ˜¯ä¸€ä¸ªå¯å˜çš„å­—ç¬¦ä¸²,ä¸è¿‡å®ƒä¸èƒ½å£°æ˜å…¶ä¸­æœ€å¤šèƒ½å­˜å‚¨å¤šå°‘ä¸ªå­—ç¬¦,ç†è®ºä¸Šå®ƒå¯ä»¥å­˜å‚¨2GBçš„å­—ç¬¦æ•°.

| Hive æ•°æ®ç±»å‹      |  Java æ•°æ®ç±»å‹ |   é•¿åº¦   |   æ•°å€¼   |
| :--------: | :--------:| :------: | :------: |
| TINYINT    |   byte |  1byteæœ‰ç¬¦å·æ•´æ•°  |  20  |
| SMALINT    |   short |  2byteæœ‰ç¬¦å·æ•´æ•°  |  20  |
| INT    |   int |  4byteæœ‰ç¬¦å·æ•´æ•°  |  20  |
| BIGINT    |   long |  8byteæœ‰ç¬¦å·æ•´æ•°  |  20  |
| BOOLEAN    |   boolean |  å¸ƒå°”ç±»å‹,trueæˆ–è€…false  |  TRUE / FALSE  |
| FLOAT    |   float |  å•ç²¾åº¦æµ®ç‚¹æ•°  |  3.14159  |
| DOUBLE    |   double |  åŒç²¾åº¦æµ®ç‚¹æ•°  |  3.14159  |
| STRING    |   string |  å­—ç¬¦ä¸²ç±»å‹,å¯ä»¥æŒ‡å®šå­—ç¬¦é›†,å¯ä»¥ä½¿ç”¨å•å¼•å·æˆ–è€…åŒå¼•å·  |  'now is the time' /  "for all good men"  |
| TIMESTAMP    |   |  æ—¶é—´ç±»å‹  |   |
| BINARY    |   |  å­—èŠ‚æ•°ç»„  |    |

### 3.2 é›†åˆæ•°æ®ç±»å‹
> Hiveæœ‰ä¸‰ç§å¤æ‚æ•°æ®ç±»å‹ARRAYã€MAP å’ŒSTRUCT,ARRAYå’ŒMAPä¸Javaä¸­çš„Arrayå’ŒMapç±»ä¼¼,è€ŒSTRUCTä¸Cè¯­è¨€ä¸­çš„Structç±»ä¼¼,å®ƒå°è£…äº†ä¸€ä¸ªå‘½åå­—æ®µé›†åˆ,å¤æ‚æ•°æ®ç±»å‹å…è®¸ä»»æ„å±‚æ¬¡çš„åµŒå¥—.
> 
| æ•°æ®ç±»å‹      |     æè¿° |   è¯­æ³•ç¤ºä¾‹   |
| :--------: | :--------:| :------: |
| STRUCT    |   å’Œcè¯­è¨€ä¸­çš„structç±»ä¼¼,éƒ½å¯ä»¥é€šè¿‡â€œç‚¹â€ç¬¦å·è®¿é—®å…ƒç´ å†…å®¹,ä¾‹å¦‚å¦‚æœæŸä¸ªåˆ—çš„æ•°æ®ç±»å‹æ˜¯STRUCT{first  STRING,last STRING},é‚£ä¹ˆç¬¬1ä¸ªå…ƒç´ å¯ä»¥é€šè¿‡å­—æ®µ.firstæ¥å¼•ç”¨. |  struct()  |
| MAP | MAPæ˜¯ä¸€ç»„é”®-å€¼å¯¹å…ƒç»„é›†åˆ,ä½¿ç”¨æ•°ç»„è¡¨ç¤ºæ³•å¯ä»¥è®¿é—®æ•°æ®,ä¾‹å¦‚å¦‚æœæŸä¸ªåˆ—çš„æ•°æ®ç±»å‹æ˜¯MAP,å…¶ä¸­é”®->å€¼å¯¹æ˜¯â€™firstâ€™->â€™Johnâ€™å’Œâ€™lastâ€™->â€™Doeâ€™,é‚£ä¹ˆå¯ä»¥é€šè¿‡å­—æ®µå[â€˜lastâ€™]è·å–æœ€åä¸€ä¸ªå…ƒç´ . | map() |
| ARRAY | æ•°ç»„æ˜¯ä¸€ç»„å…·æœ‰ç›¸åŒç±»å‹å’Œåç§°çš„å˜é‡çš„é›†åˆ,è¿™äº›å˜é‡ç§°ä¸ºæ•°ç»„çš„å…ƒç´ ,æ¯ä¸ªæ•°ç»„å…ƒç´ éƒ½æœ‰ä¸€ä¸ªç¼–å·,ç¼–å·ä»é›¶å¼€å§‹,ä¾‹å¦‚æ•°ç»„å€¼ä¸º[â€˜Johnâ€™, â€˜Doeâ€™],é‚£ä¹ˆç¬¬2ä¸ªå…ƒç´ å¯ä»¥é€šè¿‡æ•°ç»„å[1]è¿›è¡Œå¼•ç”¨. | Array() |

#### 3.2.1 æ¡ˆä¾‹å®æ“
##### 3.2.1.1 ç”¨JSONæ ¼å¼æ¥è¡¨ç¤ºå…¶æ•°æ®ç»“æ„.
``` json
{
    "name": "TestUser",
    // Array åˆ—è¡¨
    "friends": ["TestUser001" , "TestUser002"] ,
    // Map é”®å€¼
    "children": {
        "TestUser003": "003",
        "TestUser004": "004"
    },
    // Struct ç»“æ„
    "address": {
        "street": "china",
        "city": "beijing"
    }
}
```

##### 3.2.1.2 åŸºäºä¸Šè¿°æ•°æ®ç»“æ„,åœ¨Hiveé‡Œåˆ›å»ºå¯¹åº”çš„è¡¨,å¹¶å¯¼å…¥æ•°æ®.
> åˆ›å»ºæœ¬åœ°æµ‹è¯•æ–‡ä»¶test001.txt
> 
> æ³¨: MAP,STRUCTå’ŒARRAYé‡Œçš„å…ƒç´ é—´å…³ç³»éƒ½å¯ä»¥ç”¨åŒä¸€ä¸ªå­—ç¬¦`_`ä¸‹åˆ’çº¿è¡¨ç¤º.
```
TestUser,TestUser001_TestUser002,TestUser003:003_TestUser004:004,china_beijing
DemoUser,DemoUser001_DemoUser002,DemoUser003:003_DemoUser004:004,china_beijing
```
> åœ¨Hiveåˆ›å»ºtestæµ‹è¯•è¡¨
> 
> SQL File
``` sql
create table test001(
name string,
firends array<string>,
children map<string,int>,
address struct<street:string,city:string>
)
row format delimited fields terminated by ','
collection items terminated by '_'
map keys terminated by ':'
lines terminated by '\n';
```
> å­—æ®µè§£é‡Š
```
è¡¨ç¤ºåˆ—åˆ†éš”ç¬¦
row format delimited fields terminated by ','

è¡¨ç¤ºMAP STRUCT å’Œ ARRAY åˆ†éš”ç¬¦(æ•°æ®åˆ†å‰²ç¬¦å·)
collection items terminated by '_'

è¡¨ç¤ºMAPä¸­çš„keyä¸valueåˆ†éš”ç¬¦
map keys terminated by ':'

è¡¨ç¤ºè¡Œåˆ†éš”ç¬¦
lines terminated by '\n';
```
> create table
```
hive (default)> set hive.cli.print.current.db=true;
hive (default)> create table test001(
              > name string,
              > firends array<string>,
              > children map<string,int>,
              > address struct<street:string,city:string>
              > )
              > row format delimited fields terminated by ','
              > collection items terminated by '_'
              > map keys terminated by ':'
              > lines terminated by '\n';
OK
Time taken: 0.269 seconds
hive (default)> show tables;
OK
tab_name
test
test001
Time taken: 0.053 seconds, Fetched: 2 row(s)
hive (default)> 
```
> å¯¼å…¥æ–‡æœ¬æ•°æ®åˆ°æµ‹è¯•è¡¨
```
hive (default)> load data local inpath '/opt/module/datas/test001.txt' into table test001;
Loading data to table default.test001
Table default.test001 stats: [numFiles=1, totalSize=158]
OK
Time taken: 1.268 seconds
hive (default)> 
```
> æŸ¥è¯¢å…¨éƒ¨æ•°æ®
```
hive (default)> select * from test001;
OK
test001.name    test001.firends test001.children        test001.address
TestUser        ["TestUser001","TestUser002"]   {"TestUser003":3,"TestUser004":4}       {"street":"china","city":"beijing"}
DemoUser        ["DemoUser001","DemoUser002"]   {"DemoUser003":3,"DemoUser004":4}       {"street":"china","city":"beijing"}
Time taken: 0.121 seconds, Fetched: 2 row(s)
hive (default)>	
```
> æŸ¥è¯¢ä¸‰ç§é›†åˆåˆ—è¡¨æ•°æ®
> ä»¥ä¸‹åˆ†åˆ«æ˜¯ARRAY / MAP / STRUCTçš„è®¿é—®æ–¹å¼.
```
hive (default)> select firends[1],children['TestUser003'],address.city from test001 where name="TestUser";
OK
_c0     _c1     city
TestUser002     3       beijing
Time taken: 0.32 seconds, Fetched: 1 row(s)
hive (default)>
```

### 3.3 ç±»å‹è½¬åŒ–
> Hiveçš„åŸå­æ•°æ®ç±»å‹æ˜¯å¯ä»¥è¿›è¡Œéšå¼è½¬æ¢çš„,ç±»ä¼¼äºJavaçš„ç±»å‹è½¬æ¢.
> 
> ä¾‹å¦‚æŸè¡¨è¾¾å¼ä½¿ç”¨INTç±»å‹,TINYINTä¼šè‡ªåŠ¨è½¬æ¢ä¸ºINTç±»å‹,ä½†æ˜¯Hiveä¸ä¼šè¿›è¡Œåå‘è½¬åŒ–.
> 
> ä¾‹å¦‚,æŸè¡¨è¾¾å¼ä½¿ç”¨TINYINTç±»å‹,INTä¸ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºTINYINTç±»å‹,å®ƒä¼šè¿”å›é”™è¯¯,é™¤éä½¿ç”¨`CAST`æ“ä½œ.
#### 3.3.1 éšå¼ç±»å‹è½¬æ¢è§„åˆ™
> 1.ä»»ä½•æ•´æ•°ç±»å‹éƒ½å¯ä»¥éšå¼åœ°è½¬æ¢ä¸ºä¸€ä¸ªèŒƒå›´æ›´å¹¿çš„ç±»å‹,å¦‚TINYINTå¯ä»¥è½¬æ¢æˆINT,INTå¯ä»¥è½¬æ¢æˆBIGINT.
> 
> 2.æ‰€æœ‰æ•´æ•°ç±»å‹ã€FLOATå’ŒSTRINGç±»å‹éƒ½å¯ä»¥éšå¼åœ°è½¬æ¢æˆDOUBLE.
> 
> 3.TINYINT,SMALLINT,INTéƒ½å¯ä»¥è½¬æ¢ä¸ºFLOAT.
> 
> 4.BOOLEANç±»å‹ä¸å¯ä»¥è½¬æ¢ä¸ºä»»ä½•å…¶å®ƒçš„ç±»å‹.

#### 3.3.2 ä½¿ç”¨CASTæ˜¾ç¤ºè¿›è¡Œæ•°æ®ç±»å‹è½¬æ¢
> ä¾‹å¦‚`CAST('1' AS INT)`å°†æŠŠå­—ç¬¦ä¸²`'1'` è½¬æ¢æˆæ•´æ•°1,å¦‚æœå¼ºåˆ¶ç±»å‹è½¬æ¢å¤±è´¥,å¦‚æ‰§è¡Œ`CAST('X' AS INT)`,è¡¨è¾¾å¼è¿”å›ç©ºå€¼NULL.

## 4. DDL æ•°æ®å®šä¹‰
> DDL(Data Definition Language)æ•°æ®åº“æ¨¡å¼å®šä¹‰è¯­è¨€,æ˜¯ç”¨äºæè¿°æ•°æ®åº“ä¸­è¦å­˜å‚¨çš„ç°å®ä¸–ç•Œå®ä½“çš„è¯­è¨€.

### 4.1 åˆ›å»ºæ•°æ®åº“
> åˆ›å»ºä¸€ä¸ªæ•°æ®åº“,æ•°æ®åº“åœ¨HDFSä¸Šçš„é»˜è®¤å­˜å‚¨è·¯å¾„æ˜¯/user/hive/warehouse/*.db
> 
> é¿å…è¦åˆ›å»ºçš„æ•°æ®åº“å·²ç»å­˜åœ¨é”™è¯¯,å¢åŠ if not existsåˆ¤æ–­.
```
hive (default)> create database if not exists hive_db;
OK
Time taken: 0.131 seconds
hive (default)> 
```
> å½“å‰åˆ›å»ºçš„æ•°æ®åº“ä¼šå­˜æ”¾æŒ‡å®šåœ¨HDFSè·¯å¾„.
![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hive/start_003.jpg)

### 4.2 æŸ¥è¯¢æ•°æ®åº“
#### 4.2.1 æ˜¾ç¤ºæ•°æ®åº“
> 1.æ˜¾ç¤ºæ•°æ®åº“
```
hive (default)> show databases;
OK
database_name
default
hive_db
Time taken: 0.131 seconds, Fetched: 2 row(s)
hive (default)> 
```
> 2.è¿‡æ»¤æ˜¾ç¤ºæŸ¥è¯¢çš„æ•°æ®åº“
```
hive (default)> show databases like 'hive_db*';
OK
database_name
hive_db
Time taken: 0.039 seconds, Fetched: 1 row(s)
hive (default)> 
```
#### 4.2.2 æŸ¥çœ‹æ•°æ®åº“è¯¦æƒ…
> 1.æ˜¾ç¤ºæ•°æ®åº“ä¿¡æ¯
```
hive (default)> desc database hive_db;
OK
db_name comment location        owner_name      owner_type      parameters
hive_db         hdfs://systemhub511:9000/user/hive/warehouse/hive_db.db root    USER    
Time taken: 0.042 seconds, Fetched: 1 row(s)
hive (default)> 
```
> 2.æ˜¾ç¤ºæ•°æ®åº“è¯¦ç»†ä¿¡æ¯
```
hive (default)> desc database extended hive_db;
OK
db_name comment location        owner_name      owner_type      parameters
hive_db         hdfs://systemhub511:9000/user/hive/warehouse/hive_db.db root    USER    
Time taken: 0.027 seconds, Fetched: 1 row(s)
hive (default)> 
```
#### 4.2.3 åˆ‡æ¢å½“å‰æ•°æ®åº“
```
hive (default)> use hive_db;
OK
Time taken: 0.028 seconds
hive (hive_db)> 
```

### 4.3 ä¿®æ”¹æ•°æ®åº“
> ç”¨æˆ·å¯ä»¥ä½¿ç”¨`ALTER  DATABASE`å‘½ä»¤ä¸ºæŸä¸ªæ•°æ®åº“çš„`DBPROPERTIES`è®¾ç½®é”®-å€¼å¯¹å±æ€§å€¼,æ¥æè¿°è¿™ä¸ªæ•°æ®åº“çš„å±æ€§ä¿¡æ¯.
> 
> æ•°æ®åº“çš„å…¶ä»–å…ƒæ•°æ®ä¿¡æ¯éƒ½æ˜¯ä¸å¯æ›´æ”¹çš„,åŒ…æ‹¬æ•°æ®åº“åå’Œæ•°æ®åº“æ‰€åœ¨çš„ç›®å½•ä½ç½®.
```
hive (hive_db)> alter database hive_db set dbproperties('createtime'='2090-00-00');
OK
Time taken: 0.073 seconds
hive (hive_db)> desc database extended hive_db;
OK
db_name comment location        owner_name      owner_type      parameters
hive_db         hdfs://systemhub511:9000/user/hive/warehouse/hive_db.db root    USER    {createtime=2090-00-00}
Time taken: 0.034 seconds, Fetched: 1 row(s)
hive (hive_db)> 
```

### 4.4 åˆ é™¤æ•°æ®åº“
> å¦‚æœæ•°æ®åº“ä¸ä¸ºç©º,å¯ä»¥é‡‡ç”¨`cascade`å‘½ä»¤,å¼ºåˆ¶åˆ é™¤.
```
hive (default)> drop database hive_db cascade;
Time taken: 0.034 seconds
```

### 4.5 åˆ›å»ºè¡¨
#### 4.5.1 å»ºè¡¨è¯­æ³•
``` sql
CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name 
[(col_name data_type [COMMENT col_comment], ...)] 
[COMMENT table_comment] 
[PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] 
[CLUSTERED BY (col_name, col_name, ...) 
[SORTED BY (col_name [ASC|DESC], ...)] 
INTO num_buckets BUCKETS] 
[ROW FORMAT row_format] 
[STORED AS file_format] 
[LOCATION hdfs_path]
```
> å­—æ®µè§£é‡Šè¯´æ˜
> 
> 1.`CREATE  TABLE` åˆ›å»ºä¸€ä¸ªæŒ‡å®šåå­—çš„è¡¨,å¦‚æœç›¸åŒåå­—çš„è¡¨å·²ç»å­˜åœ¨,åˆ™æŠ›å‡ºå¼‚å¸¸,ç”¨æˆ·å¯ä»¥ç”¨`IF NOT EXISTS` é€‰é¡¹æ¥å¿½ç•¥è¿™ä¸ªå¼‚å¸¸.
> 
> 2.`EXTERNAL`å…³é”®å­—å¯ä»¥è®©ç”¨æˆ·åˆ›å»ºä¸€ä¸ªå¤–éƒ¨è¡¨,åœ¨å»ºè¡¨çš„åŒæ—¶æŒ‡å®šä¸€ä¸ªæŒ‡å‘å®é™…æ•°æ®çš„è·¯å¾„(LOCATION)Hiveåˆ›å»ºå†…éƒ¨è¡¨æ—¶,ä¼šå°†æ•°æ®ç§»åŠ¨åˆ°æ•°æ®ä»“åº“æŒ‡å‘çš„è·¯å¾„,è‹¥åˆ›å»ºå¤–éƒ¨è¡¨,ä»…è®°å½•æ•°æ®æ‰€åœ¨çš„è·¯å¾„,ä¸å¯¹æ•°æ®çš„ä½ç½®åšä»»ä½•æ”¹å˜,åœ¨åˆ é™¤è¡¨çš„æ—¶å€™,å†…éƒ¨è¡¨çš„å…ƒæ•°æ®å’Œæ•°æ®ä¼šè¢«ä¸€èµ·åˆ é™¤,è€Œå¤–éƒ¨è¡¨åªåˆ é™¤å…ƒæ•°æ®,ä¸åˆ é™¤æ•°æ®.
> 
> 3.`COMMENT`: ä¸ºè¡¨å’Œåˆ—æ·»åŠ æ³¨é‡Š.
> 
> 4.`PARTITIONED BY`åˆ›å»ºåˆ†åŒºè¡¨.
> 
> 5.`CLUSTERED BY`åˆ›å»ºåˆ†æ¡¶è¡¨.
> 
> 6.`SORTED BY`ä¸å¸¸ç”¨.
> 
> 7.`ROW FORMAT DELIMITED  [FIELDS TERMINATED BY char] [COLLECTIONITEMS TERMINATED BY char]`
> `[MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]  SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]`
> 
> å¼€å‘è€…åœ¨å»ºè¡¨çš„æ—¶å€™å¯ä»¥è‡ªå®šä¹‰SerDeæˆ–è€…ä½¿ç”¨è‡ªå¸¦çš„SerDe,å¦‚æœæ²¡æœ‰æŒ‡å®šROW FORMAT æˆ–è€…ROW FORMAT DELIMITED,å°†ä¼šä½¿ç”¨è‡ªå¸¦çš„SerDe,åœ¨å»ºè¡¨çš„æ—¶å€™,ç”¨æˆ·è¿˜éœ€è¦ä¸ºè¡¨æŒ‡å®šåˆ—,å¼€å‘è€…åœ¨æŒ‡å®šè¡¨çš„åˆ—çš„åŒæ—¶ä¹Ÿä¼šæŒ‡å®šè‡ªå®šä¹‰çš„SerDe,Hiveé€šè¿‡SerDeç¡®å®šè¡¨çš„å…·ä½“çš„åˆ—çš„æ•°æ®.
> 
> 8.`STORED AS` æŒ‡å®šå­˜å‚¨æ–‡ä»¶ç±»å‹.
> å¸¸ç”¨çš„å­˜å‚¨æ–‡ä»¶ç±»å‹: `SEQUENCEFILE(äºŒè¿›åˆ¶åºåˆ—æ–‡ä»¶)`,`TEXTFILE(æ–‡æœ¬)`,`RCFILE(åˆ—å¼å­˜å‚¨æ ¼å¼æ–‡ä»¶)`,å¦‚æœæ–‡ä»¶æ•°æ®æ˜¯çº¯æ–‡æœ¬,å¯ä»¥ä½¿ç”¨`STORED  AS  TEXTFILE`,å¦‚æœæ•°æ®éœ€è¦å‹ç¼©,ä½¿ç”¨`STORED AS SEQUENCEFILE`.
> 
> 9.`LOCATION`: æŒ‡å®šè¡¨åœ¨HDFSä¸Šçš„å­˜å‚¨ä½ç½®.
> 
> 10.`LIKE`å…è®¸å¼€å‘è€…å¤åˆ¶ç°æœ‰çš„è¡¨ç»“æ„,ä½†æ˜¯ä¸å¤åˆ¶æ•°æ®.

#### 4.5.2 ç®¡ç†è¡¨
##### 4.5.2.1 ç†è®º
> é»˜è®¤åˆ›å»ºçš„è¡¨éƒ½æ˜¯æ‰€è°“çš„ç®¡ç†è¡¨,æœ‰æ—¶ä¹Ÿè¢«ç§°ä¸ºå†…éƒ¨è¡¨.
> 
> å› ä¸ºè¿™ç§è¡¨,Hiveä¼šæˆ–å¤šæˆ–å°‘åœ°åˆ¶ç€æ•°æ®çš„ç”Ÿå‘½å‘¨æœŸ.
> 
> Hiveé»˜è®¤æƒ…å†µä¸‹ä¼šå°†è¿™äº›è¡¨çš„æ•°æ®å­˜å‚¨åœ¨ç”±é…ç½®é¡¹`hive.metastore.warehouse.dir`(ä¾‹å¦‚/user/hive/warehouse)æ‰€å®šä¹‰çš„ç›®å½•çš„å­ç›®å½•ä¸‹,å½“åˆ é™¤ä¸€ä¸ªç®¡ç†è¡¨æ—¶,Hiveä¹Ÿä¼šåˆ é™¤è¿™ä¸ªè¡¨ä¸­æ•°æ®,ç®¡ç†è¡¨ä¸é€‚åˆå’Œå…¶ä»–å·¥å…·å…±äº«æ•°æ®.

##### 4.5.2.2 æ¡ˆä¾‹å®æ“
> 1.æ™®é€šåˆ›å»ºè¡¨.
```
hive (default)> create table if not exists test004(id int, name string)row format delimited fields terminated by '\t' stored as textfile location '/user/hive/warehouse/test004';
OK
Time taken: 0.098 seconds
hive (default)> 
```
> 2.æ ¹æ®æŸ¥è¯¢ç»“æœåˆ›å»ºè¡¨(æŸ¥è¯¢çš„ç»“æœä¼šæ·»åŠ åˆ°æ–°åˆ›å»ºçš„è¡¨ä¸­).
```
hive (default)> show tables;
OK
tab_name
test
test001
Time taken: 0.056 seconds, Fetched: 2 row(s)
hive (default)> create table test002 as select * from test001;
Query ID = root_20190328000840_11ef1852-3fee-44f5-a4d4-a15042411c6a
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1553696946343_0001, Tracking URL = http://systemhub611:8088/proxy/application_1553696946343_0001/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553696946343_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
Stage-1 map = 0%,  reduce = 0%
Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.34 sec
MapReduce Total cumulative CPU time: 1 seconds 340 msec
Ended Job = job_1553696946343_0001
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to: hdfs://systemhub511:9000/user/hive/warehouse/.hive-staging_hive_2019-03-28_00-08-40_557_7477541425251721483-1/-ext-10001
Moving data to: hdfs://systemhub511:9000/user/hive/warehouse/test002
Table default.test002 stats: [numFiles=1, numRows=2, totalSize=150, rawDataSize=148]
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1   Cumulative CPU: 1.34 sec   HDFS Read: 3913 HDFS Write: 222 SUCCESS
Total MapReduce CPU Time Spent: 1 seconds 340 msec
OK
test001.name    test001.firends test001.children        test001.address
Time taken: 33.974 seconds
hive (default)> show tables;
OK
tab_name
test
test001
test002
Time taken: 0.041 seconds, Fetched: 3 row(s)
hive (default)> select * from test002;
OK
test002.name    test002.firends test002.children        test002.address
TestUser        ["TestUser001","TestUser002"]   {"TestUser003":3,"TestUser004":4}       {"street":"china","city":"beijing"}
DemoUser        ["DemoUser001","DemoUser002"]   {"DemoUser003":3,"DemoUser004":4}       {"street":"china","city":"beijing"}
Time taken: 0.157 seconds, Fetched: 2 row(s)
hive (default)> 
```
> 3.æ ¹æ®å·²ç»å­˜åœ¨çš„è¡¨ç»“æ„åˆ›å»ºè¡¨.
```
hive (default)> create table test003 like test;
OK
Time taken: 0.116 seconds
hive (default)> select * from test003;
OK
test003.id      test003.name
Time taken: 0.066 seconds
hive (default)> 
```
> 4.æŸ¥è¯¢è¡¨çš„ç±»å‹.
```
hive (default)> desc formatted test002;
OK
col_name        data_type       comment
# col_name              data_type               comment             
                 
name                    string                                      
firends                 array<string>                               
children                map<string,int>                             
address                 struct<street:string,city:string>                           
                 
# Detailed Table Information             
Database:               default                  
Owner:                  root                         
LastAccessTime:         UNKNOWN                  
Protect Mode:           None                     
Retention:              0                        
Location:               hdfs://systemhub511:9000/user/hive/warehouse/test002     
Table Type:             MANAGED_TABLE            
Table Parameters:                
        COLUMN_STATS_ACCURATE   true                
        numFiles                1                   
        numRows                 2                   
        rawDataSize             148                 
        totalSize               150                 
        transient_lastDdlTime   1553702954          
                 
# Storage Information            
SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe       
InputFormat:            org.apache.hadoop.mapred.TextInputFormat         
OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat       
Compressed:             No                       
Num Buckets:            -1                       
Bucket Columns:         []                       
Sort Columns:           []                       
Storage Desc Params:             
        serialization.format    1                   
Time taken: 0.179 seconds, Fetched: 34 row(s)
hive (default)> 
```
#### 4.5.3 å¤–éƒ¨è¡¨
##### 4.5.3.1 ç†è®º
> å› ä¸ºè¡¨æ˜¯å¤–éƒ¨è¡¨,æ‰€æœ‰Hiveå¹¶éè®¤ä¸ºå…¶å®Œå…¨æ‹¥æœ‰è¿™ä»½æ•°æ®,åˆ é™¤è¯¥è¡¨å¹¶ä¸ä¼šåˆ é™¤æ‰è¿™ä»½æ•°æ®,ä¸è¿‡æè¿°è¡¨çš„å…ƒæ•°æ®ä¿¡æ¯ä¼šè¢«åˆ é™¤æ‰.
##### 4.5.3.2 ç®¡ç†è¡¨å’Œå¤–éƒ¨è¡¨çš„ä½¿ç”¨åœºæ™¯
> æ¯å¤©å°†æ”¶é›†åˆ°çš„ç½‘ç«™æ—¥å¿—å®šæœŸæµå…¥HDFSæ–‡æœ¬æ–‡ä»¶,åœ¨å¤–éƒ¨è¡¨(åŸå§‹æ—¥å¿—è¡¨)åŸºç¡€ä¸Šåšå¤§é‡çš„ç»Ÿè®¡åˆ†æ,ç”¨åˆ°çš„ä¸­é—´è¡¨ã€ç»“æœè¡¨ä½¿ç”¨å†…éƒ¨è¡¨å­˜å‚¨,æ•°æ®é€šè¿‡SELECT+INSERTè¿›å…¥å†…éƒ¨è¡¨.


##### 4.5.3.3 æ¡ˆä¾‹å®æ“
> åˆ†åˆ«åˆ›å»ºéƒ¨é—¨å’Œå‘˜å·¥å¤–éƒ¨è¡¨,å¹¶å‘è¡¨ä¸­å¯¼å…¥æ•°æ®.
###### 1.åŸå§‹æ•°æ®
> dept.txt & emp.txt
```
[root@systemhub711 ~]# cd /opt/module/datas/
[root@systemhub711 datas]# vim dept.txt

50      ACCOUNTING      1900
60      RESEARCH        1800
70      SALES           1700
80      OPERATIONS      1700
```
###### 2.å»ºè¡¨è¯­å¥
```
[root@systemhub711 datas]# vim emp.txt

7369    SMITH   CLERKSKLD       7902    1980-12-17      800.00  20
7499    ALLTE   SALESMANS       7689    1987-02-23      1600.00 300.00  30
7521    WAROS   SJDHHJDJX       7869    1984-06-12      1250.18 500.00  30
7566    JOSSS   JDHYHDSDS       4545    1874-05-15      2894.25 20
7654    SOCTD   MANSJUSSD       4855    1996-02-14      2852.30 30
7698    ADAMS   JUSHHWESD       4552    1985-05-16      25524.02        30
7782    JAMSK   KIHNGSEHN       7769    1991-06-23      1100.00 20
7788    FOESS   CLAEDFDFD       7698    1994-09-17      950.00  30
7939    KINGS   CLADDJHEW       7566    1993-07-12      3000.00 20
```
> åˆ›å»ºéƒ¨é—¨è¡¨
```
hive (default)> create external table dept(deptid int,dname string,loc int)
> row format delimited fields terminated by '\t';
OK
Time taken: 0.137 seconds
hive (default)> 
```
> åˆ›å»ºå‘˜å·¥è¡¨
```
hive (default)> create external table if not exists emp(empno int,ename string,job string,mgr int,hiredate string,sal double,comm double,deptno int)
> row format delimited fields terminated by '\t';
OK
Time taken: 0.121 seconds
hive (default)> 
```
###### 3.å‘å¤–éƒ¨è¡¨ä¸­å¯¼å…¥æ•°æ®
```
hive (default)> load data local inpath '/opt/module/datas/dept.txt' into table dept;
Loading data to table default.dept
Table default.dept stats: [numFiles=1, totalSize=70]
OK
Time taken: 0.535 seconds
hive (default)>
```
```
hive (default)> load data local inpath '/opt/module/datas/emp.txt' into table emp;
Loading data to table default.emp
Table default.emp stats: [numFiles=1, totalSize=445]
OK
Time taken: 0.302 seconds
hive (default)> 
```
###### 4.æŸ¥çœ‹åˆ›å»ºçš„è¡¨
```
hive (default)> select * from dept;
OK
dept.deptid     dept.dname      dept.loc
50      ACCOUNTING      1900
60      RESEARCH        1800
70      SALES   NULL
80      OPERATIONS      1700
Time taken: 0.098 seconds, Fetched: 4 row(s)
hive (default)> select * from emp;
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7369    SMITH   CLERKSKLD       7902    1980-12-17      800.0   20.0    NULL
7499    ALLTE   SALESMANS       7689    1987-02-23      1600.0  300.0   30
7521    WAROS   SJDHHJDJX       7869    1984-06-12      1250.18 500.0   30
7566    JOSSS   JDHYHDSDS       4545    1874-05-15      2894.25 20.0    NULL
7654    SOCTD   MANSJUSSD       4855    1996-02-14      2852.3  30.0    NULL
7698    ADAMS   JUSHHWESD       4552    1985-05-16      25524.02        30.0    NULL
7782    JAMSK   KIHNGSEHN       7769    1991-06-23      1100.0  20.0    NULL
7788    FOESS   CLAEDFDFD       7698    1994-09-17      950.0   30.0    NULL
7939    KINGS   CLADDJHEW       7566    1993-07-12      3000.0  20.0    NULL
Time taken: 0.063 seconds, Fetched: 9 row(s)
hive (default)> 
```
###### 5.æŸ¥çœ‹è¡¨æ ¼å¼åŒ–æ•°æ®
```
hive (default)> desc formatted dept;
OK
col_name        data_type       comment
# col_name              data_type               comment             
                 
deptid                  int                                         
dname                   string                                      
loc                     int                                         
                 
# Detailed Table Information             
Database:               default                  
Owner:                  root                        
LastAccessTime:         UNKNOWN                  
Protect Mode:           None                     
Retention:              0                        
Location:               hdfs://systemhub511:9000/user/hive/warehouse/dept        
Table Type:             EXTERNAL_TABLE           
Table Parameters:                
        COLUMN_STATS_ACCURATE   true                
        EXTERNAL                TRUE                
        numFiles                1                   
        totalSize               70                  
        transient_lastDdlTime   1553705763          
                 
# Storage Information            
SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe       
InputFormat:            org.apache.hadoop.mapred.TextInputFormat         
OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat       
Compressed:             No                       
Num Buckets:            -1                       
Bucket Columns:         []                       
Sort Columns:           []                       
Storage Desc Params:             
        field.delim             \t                  
        serialization.format    \t                  
Time taken: 0.159 seconds, Fetched: 33 row(s)
hive (default)> 
```
###### 6.åˆ é™¤å¤–éƒ¨deptæ•°æ®è¡¨,å¹¶æŸ¥çœ‹ç»“æœ
> é€šè¿‡æŸ¥çœ‹ç»“æœæ¥çœ‹,åªæ˜¯åˆ é™¤äº†æè¿°è¡¨çš„å…ƒæ•°æ®ä¿¡æ¯,è€Œä¸ä¼šåˆ é™¤è¯¥æ•°æ®è¡¨çš„å…ƒæ•°æ®.
![enter image description here](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/hive/start_004.jpg)
> å¯é€šè¿‡å†æ¬¡åˆ›å»ºå¤–éƒ¨deptæ•°æ®è¡¨,ä¾æ—§å¯ä»¥æŸ¥çœ‹åˆ°deptå…ƒæ•°æ®æ‰€åœ¨.
```
hive (default)> create external table if not exists dept(deptid int,dname string,loc int)row format delimited fields terminated by '\t';
OK
Time taken: 0.039 seconds
hive (default)> select * from dept;
OK
dept.deptid     dept.dname      dept.loc
50      ACCOUNTING      1900
60      RESEARCH        1800
70      SALES   NULL
80      OPERATIONS      1700
Time taken: 0.06 seconds, Fetched: 4 row(s)
hive (default)> 
```
#### 4.5.4 ç®¡ç†éƒ¨ä¸å¤–éƒ¨è¡¨ç›¸äº’è½¬æ¢ 
> æ³¨: ('EXTERNAL'='TRUE') & ('EXTERNAL'='FALSE') ä¸ºå›ºå®šå†™æ³•,åŒºåˆ†å¤§å°å†™.
##### æŸ¥è¯¢å†…éƒ¨è¡¨æ•°æ®è¡¨ç±»å‹
```
hive (default)> desc formatted test001;
Table Type:             MANAGED_TABLE  
```
##### ä¿®æ”¹å†…éƒ¨è¡¨ä¸ºå¤–éƒ¨è¡¨
```
alter table test001 set tblproperties('EXTERNAL'='TRUE');
```
##### æŸ¥è¯¢å¤–éƒ¨è¡¨æ•°æ®è¡¨ç±»å‹
```
hive (default)> desc formatted test001;
Table Type:             EXTERNAL_TABLE  
```
##### ä¿®æ”¹å¤–éƒ¨è¡¨ä¸ºå†…éƒ¨è¡¨
```
alter table test001 set tblproperties('EXTERNAL'='FALSE');
```
##### æŸ¥è¯¢å†…éƒ¨è¡¨æ•°æ®è¡¨ç±»å‹
```
hive (default)> desc formatted test001;
Table Type:             MANAGED_TABLE  
```


### 4.6 åˆ†åŒºè¡¨
> åˆ†åŒºè¡¨å®é™…ä¸Šå°±æ˜¯å¯¹åº”ä¸€ä¸ªHDFSæ–‡ä»¶ç³»ç»Ÿä¸Šçš„ç‹¬ç«‹çš„æ–‡ä»¶å¤¹,è¯¥æ–‡ä»¶å¤¹ä¸‹æ˜¯è¯¥åˆ†åŒºæ‰€æœ‰çš„æ•°æ®æ–‡ä»¶,Hiveä¸­çš„åˆ†åŒºå°±æ˜¯åˆ†ç›®å½•,æŠŠä¸€ä¸ªå¤§çš„æ•°æ®é›†æ ¹æ®ä¸šåŠ¡éœ€è¦åˆ†å‰²æˆå°çš„æ•°æ®é›†,åœ¨æŸ¥è¯¢æ—¶é€šè¿‡WHEREå­å¥ä¸­çš„è¡¨è¾¾å¼é€‰æ‹©æŸ¥è¯¢æ‰€éœ€è¦çš„æŒ‡å®šçš„åˆ†åŒº,è¿™æ ·çš„æŸ¥è¯¢æ•ˆç‡ä¼šæé«˜å¾ˆå¤š.
#### 4.6.1 åˆ›å»ºåˆ†åŒºè¡¨è¯­æ³•
```
hive (default)> create table dept_partition(deptno int, dname string, loc string)
              > partitioned by (month string)
              > row format delimited fields terminated by '\t';
OK
Time taken: 0.614 seconds
hive (default)> 
```
#### 4.6.2 åŠ è½½æ•°æ®åˆ°åˆ†åŒºè¡¨ä¸­
```
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition partition(month='2020-00-00');
Loading data to table default.dept_partition partition (month=2020-00-00)
Partition default.dept_partition{month=2020-00-00} stats: [numFiles=1, numRows=0, totalSize=70, rawDataSize=0]
OK
Time taken: 2.37 seconds
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition partition(month='2020-00-01');
Loading data to table default.dept_partition partition (month=2020-00-01)
Partition default.dept_partition{month=2020-00-01} stats: [numFiles=1, numRows=0, totalSize=70, rawDataSize=0]
OK
Time taken: 0.701 seconds
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition partition(month='2020-00-02');
Loading data to table default.dept_partition partition (month=2020-00-02)
Partition default.dept_partition{month=2020-00-02} stats: [numFiles=1, numRows=0, totalSize=70, rawDataSize=0]
OK
Time taken: 0.558 seconds
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition partition(month='2020-00-03');
Loading data to table default.dept_partition partition (month=2020-00-03)
Partition default.dept_partition{month=2020-00-03} stats: [numFiles=1, numRows=0, totalSize=70, rawDataSize=0]
OK
Time taken: 0.46 seconds
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition partition(month='2020-00-04');
Loading data to table default.dept_partition partition (month=2020-00-04)
Partition default.dept_partition{month=2020-00-04} stats: [numFiles=1, numRows=0, totalSize=70, rawDataSize=0]
OK
Time taken: 0.461 seconds
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition partition(month='2020-00-05');
Loading data to table default.dept_partition partition (month=2020-00-05)
Partition default.dept_partition{month=2020-00-05} stats: [numFiles=1, numRows=0, totalSize=70, rawDataSize=0]
OK
Time taken: 0.422 seconds
hive (default)>
```
#### 4.6.3 æŸ¥è¯¢åˆ†åŒºè¡¨ä¸­æ•°æ®
##### 4.6.3.1 å•åˆ†åŒºæŸ¥è¯¢
```
hive (default)> select * from dept_partition where month='2020-00-05';
OK
dept_partition.deptno   dept_partition.dname    dept_partition.loc      dept_partition.month
50      ACCOUNTING      1900    2020-00-05
60      RESEARCH        1800    2020-00-05
70      SALES           2020-00-05
80      OPERATIONS      1700    2020-00-05
Time taken: 1.186 seconds, Fetched: 4 row(s)
hive (default)>
```
##### 4.6.3.2 å¤šåˆ†åŒºè”åˆæŸ¥è¯¢
```
hive (default)> select * from dept_partition where month='2020-00-05'
              > union
              > select * from dept_partition where month='2020-00-04'
              > union
              > select * from dept_partition where month='2020-00-03'
              > union
              > select * from dept_partition where month='2020-00-02'
              > union
              > select * from dept_partition where month='2020-00-01';
Query ID = root_201346_e7c134f9-1082-4bd6-9588-951592861d78
Total jobs = 4
Launching Job 1 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553737906374_0001, Tracking URL = http://systemhub611:8088/proxy/application_1553737906374_0001/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553737906374_0001
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 1
Stage-1 map = 0%,  reduce = 0%
Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 1.5 sec
Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.42 sec
Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.2 sec
MapReduce Total cumulative CPU time: 5 seconds 200 msec
Ended Job = job_1553737906374_0001
Launching Job 2 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553737906374_0002, Tracking URL = http://systemhub611:8088/proxy/application_1553737906374_0002/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553737906374_0002
Hadoop job information for Stage-2: number of mappers: 2; number of reducers: 1
Stage-2 map = 0%,  reduce = 0%
Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.87 sec
Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 4.42 sec
MapReduce Total cumulative CPU time: 4 seconds 420 msec
Ended Job = job_1553737906374_0002
Launching Job 3 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553737906374_0003, Tracking URL = http://systemhub611:8088/proxy/application_1553737906374_0003/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553737906374_0003
Hadoop job information for Stage-3: number of mappers: 2; number of reducers: 1
Stage-3 map = 0%,  reduce = 0%
Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.67 sec
Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 4.41 sec
MapReduce Total cumulative CPU time: 4 seconds 410 msec
Ended Job = job_1553737906374_0003
Launching Job 4 out of 4
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553737906374_0004, Tracking URL = http://systemhub611:8088/proxy/application_1553737906374_0004/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553737906374_0004
Hadoop job information for Stage-4: number of mappers: 2; number of reducers: 1
Stage-4 map = 0%,  reduce = 0%
Stage-4 map = 50%,  reduce = 0%, Cumulative CPU 1.21 sec
Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 2.61 sec
Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 4.5 sec
MapReduce Total cumulative CPU time: 4 seconds 500 msec
Ended Job = job_1553737906374_0004
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 1   Cumulative CPU: 5.2 sec   HDFS Read: 15645 HDFS Write: 434 SUCCESS
Stage-Stage-2: Map: 2  Reduce: 1   Cumulative CPU: 4.42 sec   HDFS Read: 14689 HDFS Write: 603 SUCCESS
Stage-Stage-3: Map: 2  Reduce: 1   Cumulative CPU: 4.41 sec   HDFS Read: 14810 HDFS Write: 772 SUCCESS
Stage-Stage-4: Map: 2  Reduce: 1   Cumulative CPU: 4.5 sec   HDFS Read: 15517 HDFS Write: 545 SUCCESS
Total MapReduce CPU Time Spent: 18 seconds 530 msec
OK
_u5.deptno      _u5.dname       _u5.loc _u5.month
50      ACCOUNTING      1900    2020-00-01
50      ACCOUNTING      1900    2020-00-02
50      ACCOUNTING      1900    2020-00-03
50      ACCOUNTING      1900    2020-00-04
50      ACCOUNTING      1900    2020-00-05
60      RESEARCH        1800    2020-00-01
60      RESEARCH        1800    2020-00-02
60      RESEARCH        1800    2020-00-03
60      RESEARCH        1800    2020-00-04
60      RESEARCH        1800    2020-00-05
70      SALES           2020-00-01
70      SALES           2020-00-02
70      SALES           2020-00-03
70      SALES           2020-00-04
70      SALES           2020-00-05
80      OPERATIONS      1700    2020-00-01
80      OPERATIONS      1700    2020-00-02
80      OPERATIONS      1700    2020-00-03
80      OPERATIONS      1700    2020-00-04
80      OPERATIONS      1700    2020-00-05
Time taken: 164.191 seconds, Fetched: 20 row(s)
hive (default)>
```

#### 4.6.4 å¢åŠ åˆ†åŒº
##### 4.6.4.1 åˆ›å»ºå•ä¸ªåˆ†åŒº
```
hive (default)> alter table dept_partition add partition(month='2020-00-06');
OK
Time taken: 0.501 seconds
hive (default)> 	
```
##### 4.6.4.2 åŒæ—¶åˆ›å»ºå¤šä¸ªåˆ†åŒº
```
hive (default)> alter table dept_partition add partition(month='2020-00-07') partition(month='2020-00-08');
OK
Time taken: 0.184 seconds
hive (default)> 
```
#### 4.6.5 åˆ é™¤åˆ†åŒº
##### 4.6.1 åˆ é™¤å•ä¸ªåˆ†åŒº
```
hive (default)> alter table dept_partition drop partition(month='2020-00-06');
Dropped the partition month=2020-00-06
OK
Time taken: 0.273 seconds
hive (default)> 
```
##### 4.6.2 åŒæ—¶åˆ é™¤å¤šä¸ªåˆ†åŒº
```
hive (default)> alter table dept_partition drop partition(month='2020-00-07'),partition(month='2020-00-08');
Dropped the partition month=2020-00-07
Dropped the partition month=2020-00-08
OK
Time taken: 0.837 seconds
hive (default)> 
```
#### 4.6.6 æŸ¥çœ‹åˆ†åŒºè¡¨æœ‰å¤šå°‘åˆ†åŒº
```
hive (default)> show partitions dept_partition;
OK
partition
month=2020-00-00
month=2020-00-01
month=2020-00-02
month=2020-00-03
month=2020-00-04
month=2020-00-05
Time taken: 0.155 seconds, Fetched: 6 row(s)
hive (default)> 
```

#### 4.6.7 æŸ¥çœ‹åˆ†åŒºè¡¨ç»“æ„
```
hive (default)> desc formatted dept_partition;
OK
col_name        data_type       comment
# col_name              data_type               comment             
                 
deptno                  int                                         
dname                   string                                      
loc                     string                                      
                 
# Partition Information          
# col_name              data_type               comment             
                 
month                   string                                      
                 
# Detailed Table Information             
Database:               default                  
Owner:                  root                        
LastAccessTime:         UNKNOWN                  
Protect Mode:           None                     
Retention:              0                        
Location:               hdfs://systemhub511:9000/user/hive/warehouse/dept_partition      
Table Type:             MANAGED_TABLE            
Table Parameters:                
        transient_lastDdlTime   1553753699          
                 
# Storage Information            
SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe       
InputFormat:            org.apache.hadoop.mapred.TextInputFormat         
OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat       
Compressed:             No                       
Num Buckets:            -1                       
Bucket Columns:         []                       
Sort Columns:           []                       
Storage Desc Params:             
        field.delim             \t                  
        serialization.format    \t                  
Time taken: 0.183 seconds, Fetched: 34 row(s)
hive (default)>
```

#### 4.6.8 åˆ†åŒºè¡¨æ³¨æ„äº‹é¡¹
##### 4.6.8.1 åˆ›å»ºäºŒçº§åˆ†åŒºè¡¨
```
hive (default)> create table dept_partition002(deptno int, dname string, loc string)
              > partitioned by (month string,day string)
              > row format delimited fields terminated by '\t';
OK
Time taken: 0.215 seconds
hive (default)> 
```
##### 4.6.8.2 åŠ è½½æ•°æ®
###### 4.6.8.2.1 åŠ è½½æ•°æ®åˆ°äºŒçº§åˆ†åŒºè¡¨
```
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition002 partition(month='2020-00-06', day='0101');
Loading data to table default.dept_partition002 partition (month=2020-00-06, day=0101)
Partition default.dept_partition002{month=2020-00-06, day=0101} stats: [numFiles=1, numRows=0, totalSize=70, rawDataSize=0]
OK
Time taken: 1.914 seconds
hive (default)> 
```
###### 4.6.8.2.2 æŸ¥è¯¢åˆ†åŒºæ•°æ®
```
hive (default)> select * from dept_partition002 where month='2020-00-06' and day='0101';
OK
dept_partition002.deptno        dept_partition002.dname dept_partition002.loc   dept_partition002.month dept_partition002.day
50      ACCOUNTING      1900    2020-00-06      0101
60      RESEARCH        1800    2020-00-06      0101
70      SALES           2020-00-06      0101
80      OPERATIONS      1700    2020-00-06      0101
Time taken: 0.284 seconds, Fetched: 4 row(s)
hive (default)>  
```
##### 4.6.8.3 å°†æ•°æ®ç›´æ¥ä¸Šä¼ åˆ°åˆ†åŒºç›®å½•,è®©åˆ†åŒºè¡¨ä¸æ•°æ®äº§ç”Ÿå…³è”çš„æ–¹å¼
###### 4.6.8.3.1 æ–¹å¼ä¸€: ä¸Šä¼ æ•°æ®åä¿®å¤
> ä¸Šä¼ æ•°æ®
```
hive (default)> dfs -mkdir -p /user/hive/warehouse/dept_partition/month=2020-00-10;
hive (default)> 
```
> æŸ¥è¯¢æ•°æ®(æŸ¥è¯¢ä¸åˆ°åˆšä¸Šä¼ çš„æ•°æ®)
```
hive (default)> select * from dept_partition where month='2020-00-10';
OK
dept_partition.deptno   dept_partition.dname    dept_partition.loc      dept_partition.month
Time taken: 0.147 seconds
hive (default)> 
```
> æ‰§è¡Œä¿®å¤å‘½ä»¤
```
hive (default)> msck repair table dept_partition;
OK
Partitions not in metastore:    dept_partition:month=2020-00-10
Repair: Added partition to metastore dept_partition:month=2020-00-10
Time taken: 0.297 seconds, Fetched: 2 row(s)
hive (default)> 
```

###### 4.6.8.3.2 æ–¹å¼äºŒ: ä¸Šä¼ æ•°æ®åæ·»åŠ åˆ†åŒº
> ä¸Šä¼ æ•°æ®
```
hive (default)> dfs -mkdir -p /user/hive/warehouse/dept_partition/month=2020-00-12;
hive (default)> 
```
> æ‰§è¡Œæ·»åŠ åˆ†åŒº
```
alter table dept_partition drop partition(month='2020-00-06',day='0101');
OK
Time taken: 0.273 seconds
hive (default)> 
```
> æŸ¥è¯¢æ•°æ®
```
hive (default)> select * from dept_partition002 where month='2020-00-06' and day='0101';
OK
dept_partition002.deptno        dept_partition002.dname dept_partition002.loc   dept_partition002.month dept_partition002.day
50      ACCOUNTING      1900    2020-00-06      0101
60      RESEARCH        1800    2020-00-06      0101
70      SALES           2020-00-06      0101
80      OPERATIONS      1700    2020-00-06      0101
Time taken: 0.284 seconds, Fetched: 4 row(s)
hive (default)>  
```
###### 4.6.8.3.3 æ–¹å¼ä¸‰: ä¸Šä¼ æ•°æ®åloadæ•°æ®åˆ°åˆ†åŒº
> åˆ›å»ºç›®å½•
```
hive (default)> dfs -mkdir -p /user/hive/warehouse/dept_partition/month=2020-00-06/day=0101;
hive (default)> 
```
> ä¸Šä¼ æ•°æ®
```
hive (default)> load data local inpath '/opt/module/datas/dept.txt'into table default.dept_partition partition(month='2020-00-06', day='0101');
```
> æŸ¥è¯¢æ•°æ®
```
hive (default)> select * from dept_partition where month='2020-00-06' and day='0101';
OK
dept_partition002.deptno        dept_partition002.dname dept_partition002.loc   dept_partition002.month dept_partition002.day
50      ACCOUNTING      1900    2020-00-06      0101
60      RESEARCH        1800    2020-00-06      0101
70      SALES           2020-00-06      0101
80      OPERATIONS      1700    2020-00-06      0101
Time taken: 0.284 seconds, Fetched: 4 row(s)
hive (default)>  
```

### 4.7 ä¿®æ”¹è¡¨
#### 4.7.1 é‡å‘½åè¡¨
##### 4.7.1.1 è¯­æ³•
``` sql
ALTER TABLE table_name RENAME TO new_table_name;
```
##### 4.7.1.2 å®æ“æ¡ˆä¾‹
```
hive (default)> alter table dept_partition002 rename to dept_partition003;
OK
Time taken: 0.324 seconds
hive (default)> 
```
#### 4.7.2 å¢åŠ /ä¿®æ”¹/æ›¿æ¢åˆ—ä¿¡æ¯
##### 4.7.2.1 è¯­æ³•
###### 4.7.2.1.1 æ›´æ–°åˆ—
```
ALTER   TABLE   table_name   CHANGE   [COLUMN]   col_old_name   col_new_name column_type [COMMENT col_comment] [FIRST|AFTER column_name]
```
###### 4.7.2.1.2 å¢åŠ å’Œæ›¿æ¢åˆ—
```
ALTER    TABLE    table_name    ADD|REPLACE    COLUMNS    (col_name    data_type [COMMENT col_comment], ...)
```
> æ³¨ï¼šADDæ˜¯ä»£è¡¨æ–°å¢ä¸€å­—æ®µ,å­—æ®µä½ç½®åœ¨æ‰€æœ‰åˆ—åé¢(partitionåˆ—å‰),REPLACEåˆ™æ˜¯è¡¨ç¤ºæ›¿æ¢è¡¨ä¸­æ‰€æœ‰å­—æ®µ.

##### 4.7.2.2 å®æ“æ¡ˆä¾‹
###### 4.7.2.2.1 æŸ¥è¯¢è¡¨ç»“æ„
```
hive (default)> desc dept_partition;
OK
col_name        data_type       comment
deptno                  int                                         
dname                   string                                      
loc                     string                                      
month                   string                                      
                 
# Partition Information          
# col_name              data_type               comment             
                 
month                   string                                      
Time taken: 0.122 seconds, Fetched: 9 row(s)
hive (default)> 
```
###### 4.7.2.2.2 æ·»åŠ åˆ—
```
hive (default)> alter table dept_partition add columns(deptdesc string);
OK
Time taken: 0.133 seconds
hive (default)>
```
> æŸ¥è¯¢è¡¨ç»“æ„
```
hive (default)> desc dept_partition;
OK
col_name        data_type       comment
deptno                  int                                         
dname                   string                                      
loc                     string                                      
deptdesc                string                                      
month                   string                                      
                 
# Partition Information          
# col_name              data_type               comment             
                 
month                   string                                      
Time taken: 0.09 seconds, Fetched: 10 row(s)
hive (default)> 
```
###### 4.7.2.2.3 æ›´æ–°åˆ—
```
hive (default)> alter table dept_partition change column deptdesc desc int;
OK
Time taken: 0.113 seconds
hive (default)> 
```
> æŸ¥è¯¢è¡¨ç»“æ„
```
hive (default)> desc dept_partition;
OK
col_name        data_type       comment
deptno                  int                                         
dname                   string                                      
loc                     string                                      
desc                    int                                         
month                   string                                      
                 
# Partition Information          
# col_name              data_type               comment             
                 
month                   string                                      
Time taken: 0.093 seconds, Fetched: 10 row(s)
hive (default)> 
```
###### 4.7.2.2.4 æ›¿æ¢åˆ—
```
hive (default)> alter table dept_partition replace columns(deptno string,dname string,loc string);
OK
Time taken: 0.084 seconds
hive (default)> 
```
> æŸ¥è¯¢è¡¨ç»“æ„
```
hive (default)> desc dept_partition;
OK
col_name        data_type       comment
deptno                  string                                      
dname                   string                                      
loc                     string                                      
month                   string                                      
                 
# Partition Information          
# col_name              data_type               comment             
                 
month                   string                                      
Time taken: 0.094 seconds, Fetched: 9 row(s)
hive (default)> 
```
###### 4.7.2.2.5 åˆ é™¤è¡¨
```
hive (default)> drop table dept_partition003;
OK
Time taken: 0.343 seconds
hive (default)> 
```

## 5. DML æ•°æ®æ“ä½œ
> DML(Data Manipulation Language)æ•°æ®æ“çºµè¯­è¨€,è´Ÿè´£å¯¹æ•°æ®åº“å¯¹è±¡è¿è¡Œæ•°æ®è®¿é—®å·¥ä½œçš„æŒ‡ä»¤é›†.

### 5.1 æ•°æ®å¯¼å…¥
#### 5.1.1 (Load æ¨¡å¼)å‘è¡¨ä¸­è£…è½½æ•°æ®
##### 5.1.1.1 è¯­æ³•
```
load  data  [local]  inpath  'FilePath'  [overwrite]  into  table  TableName [partition (partcol1=val1,...)];
```
> 1.`load data`: è¡¨ç¤ºåŠ è½½æ•°æ®.
> 
> 2.`local`: è¡¨ç¤ºä»æœ¬åœ°åŠ è½½æ•°æ®åˆ°hiveè¡¨,å¦åˆ™ä»HDFSåŠ è½½æ•°æ®åˆ°hiveè¡¨.
> 
> 3.`inpath`: è¡¨ç¤ºåŠ è½½æ•°æ®çš„è·¯å¾„.
> 
> 4.`into table`: è¡¨ç¤ºåŠ è½½åˆ°å“ªå¼ æ•°æ®è¡¨.
> 
> 5.`TableName`: è¡¨ç¤ºå…·ä½“æ•°æ®è¡¨.
> 
> 6.`overwrite`: è¡¨ç¤ºè¦†ç›–è¡¨ä¸­å·²æœ‰æ•°æ®,å¦åˆ™è¡¨ç¤ºè¿½åŠ .
> 
> 7.`partition`: è¡¨ç¤ºä¸Šä¼ åˆ°æŒ‡å®šåˆ†åŒº.

##### 5.1.2.2 å®æ“æ¡ˆä¾‹
###### 5.1.2.2.1 åˆ›å»ºä¸€å¼ æ•°æ®è¡¨
```
hive (default)> create table test005(id string,name string)row format delimited fields terminated by '\t';
OK
Time taken: 0.081 seconds
hive (default)> 
```
###### 5.1.2.2.2 åŠ è½½æœ¬åœ°æ–‡ä»¶åˆ°hive
```
hive (default)> load data local inpath '/opt/module/datas/test.txt' into table test005;
Loading data to table default.test005
Table default.test005 stats: [numFiles=1, totalSize=56]
OK
Time taken: 0.322 seconds
hive (default)> 
```
###### 5.1.2.2.3 åŠ è½½HDFSæ–‡ä»¶åˆ°hiveä¸­
> ä¸Šä¼ æ–‡ä»¶åˆ°HDFS
```
hive (default)> dfs -mkdir -p /user/geekparkhub/hive;
hive (default)> dfs -put /opt/module/datas/test.txt /user/geekparkhub/hive/test.txt;
```
###### 5.1.2.2.4 åŠ è½½æ•°æ®è¦†ç›–è¡¨ä¸­å·²æœ‰çš„æ•°æ®
> åŠ è½½æ•°æ®è¦†ç›–è¡¨ä¸­å·²æœ‰çš„æ•°æ®
```
hive (default)> load data inpath '/user/geekparkhub/hive/test.txt' overwrite into table test005;
Loading data to table default.test005
Table default.test005 stats: [numFiles=1, numRows=0, totalSize=56, rawDataSize=0]
OK
Time taken: 0.21 seconds
hive (default)> 
```

#### 5.1.2 (Insert æ¨¡å¼) é€šè¿‡æŸ¥è¯¢è¯­å¥å‘è¡¨ä¸­æ’å…¥æ•°æ®
##### 5.1.2.1 åŸºæœ¬æ¨¡å¼æ’å…¥ (æ ¹æ®å•å¼ è¡¨æŸ¥è¯¢ç»“æœ)
```
hive (default)> insert overwrite table dept_partition002 partition(month='2020-00-11') select id, name from dept_partition where month='2020-00-12';
```
##### 5.1.2.2 å¤šæ’å…¥æ¨¡å¼ (æ ¹æ®å¤šå¼ è¡¨æŸ¥è¯¢ç»“æœ)
```
hive (default)> from dept_partition
insert overwrite table dept_partition002 partition(month='2020-00-13')
select id, name where month='2020-00-10'
insert overwrite table dept_partition002 partition(month='2020-00-14')
select id, name where month='2020-00-10';
```

#### 5.1.3 (As Select æ¨¡å¼) æŸ¥è¯¢è¯­å¥ä¸­åˆ›å»ºè¡¨å¹¶åŠ è½½æ•°æ®
> æ ¹æ®æŸ¥è¯¢ç»“æœåˆ›å»ºè¡¨ (æŸ¥è¯¢çš„ç»“æœä¼šæ·»åŠ åˆ°æ–°åˆ›å»ºçš„è¡¨ä¸­)
```
create table if not exists test006 as select * from test;
```
#### 5.1.4 åˆ›å»ºè¡¨æ—¶é€šè¿‡LocationæŒ‡å®šåŠ è½½æ•°æ®è·¯å¾„
##### 5.1.4.1 åˆ›å»ºè¡¨,å¹¶æŒ‡å®šåœ¨HDFSä¸Šçš„ä½ç½®
```
hive (default)> create table test007 like test;
OK
Time taken: 0.108 seconds
hive (default)>
```
##### 5.1.4.2 ä¸Šä¼ æ•°æ®åˆ°hdfsä¸Š
```
hive (default)> dfs -put /opt/module/datas/test.txt /user/hive/warehouse/test007;
```
##### 5.1.4.3 æŸ¥è¯¢æ•°æ®
```
hive (default)> select * from test007;
OK
test007.id      test007.name
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
Time taken: 0.087 seconds, Fetched: 4 row(s)
hive (default)> 
```

#### 5.1.5 Importæ•°æ®åˆ°æŒ‡å®šHiveè¡¨ä¸­
> å…ˆç”¨exportå¯¼å‡ºå,å†å°†æ•°æ®å¯¼å…¥.
```
hive (default)> import table test006 from
              > '/user/geekparkhub/export/test002';
Copying data from hdfs://systemhub511:9000/user/geekparkhub/export/test002/data
Copying file: hdfs://systemhub511:9000/user/geekparkhub/export/test002/data/test.txt
Loading data to table default.test006
OK
Time taken: 0.571 seconds
hive (default)> 
```

### 5.2 æ•°æ®å¯¼å‡º
#### 5.2.1 Insert å¯¼å‡º
##### 5.2.1 å°†æŸ¥è¯¢çš„ç»“æœå¯¼å‡ºåˆ°æœ¬åœ°
```
hive (default)> insert overwrite local directory '/opt/module/datas/export/test'
              > select * from test;
Query ID = root_20190328214019_01955e31-2364-4c10-8661-cafb4bd9bb38
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1553780256887_0003, Tracking URL = http://systemhub611:8088/proxy/application_1553780256887_0003/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553780256887_0003
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
Stage-1 map = 0%,  reduce = 0%
Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.35 sec
MapReduce Total cumulative CPU time: 1 seconds 350 msec
Ended Job = job_1553780256887_0003
Copying data to local directory /opt/module/datas/export/test
Copying data to local directory /opt/module/datas/export/test
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1   Cumulative CPU: 1.35 sec   HDFS Read: 2982 HDFS Write: 56 SUCCESS
Total MapReduce CPU Time Spent: 1 seconds 350 msec
OK
test.id test.name
Time taken: 24.917 seconds
hive (default)> 
```
```
[root@systemhub711 ~]# cat /opt/module/datas/export/test/000000_0
1TestUser001
2TestUser002
3TestUser003
4TestUser004
[root@systemhub711 ~]# 
```
##### 5.2.2 å°†æŸ¥è¯¢çš„ç»“æœæ ¼å¼åŒ–å¯¼å‡ºåˆ°æœ¬åœ°
```
hive (default)> insert overwrite local directory '/opt/module/datas/export/test001'
              > row format delimited fields terminated by '\t'
              > select * from test;
Query ID = root_20190328214116_2a678b33-dc52-4aef-97d4-7c4932d14dc2
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1553780256887_0004, Tracking URL = http://systemhub611:8088/proxy/application_1553780256887_0004/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553780256887_0004
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
Stage-1 map = 0%,  reduce = 0%
Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.32 sec
MapReduce Total cumulative CPU time: 1 seconds 320 msec
Ended Job = job_1553780256887_0004
Copying data to local directory /opt/module/datas/export/test001
Copying data to local directory /opt/module/datas/export/test001
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1   Cumulative CPU: 1.32 sec   HDFS Read: 2995 HDFS Write: 56 SUCCESS
Total MapReduce CPU Time Spent: 1 seconds 320 msec
OK
test.id test.name
Time taken: 24.856 seconds
hive (default)> 
```
```
[root@systemhub711 ~]# cat /opt/module/datas/export/test001/000000_0
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
[root@systemhub711 ~]# 
```
##### 5.2.3 å°†æŸ¥è¯¢çš„ç»“æœå¯¼å‡ºåˆ°HDFS
```
hive (default)> insert overwrite directory '/user/geekparkhub/export/test'
              > row format delimited fields terminated by '\t'
              > select * from test;
Query ID = root_20190328214749_261af019-2978-43a9-99be-4cce6bf63837
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1553780256887_0005, Tracking URL = http://systemhub611:8088/proxy/application_1553780256887_0005/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553780256887_0005
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0
Stage-1 map = 0%,  reduce = 0%
Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.3 sec
MapReduce Total cumulative CPU time: 1 seconds 300 msec
Ended Job = job_1553780256887_0005
Stage-3 is selected by condition resolver.
Stage-2 is filtered out by condition resolver.
Stage-4 is filtered out by condition resolver.
Moving data to: hdfs://systemhub511:9000/user/geekparkhub/export/test/.hive-staging_hive_2019-03-28_21-47-49_139_9022836247083242678-1/-ext-10000
Moving data to: /user/geekparkhub/export/test
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1   Cumulative CPU: 1.3 sec   HDFS Read: 2983 HDFS Write: 56 SUCCESS
Total MapReduce CPU Time Spent: 1 seconds 300 msec
OK
test.id test.name
Time taken: 24.801 seconds
hive (default)> 
```
```
hive (default)> dfs -cat /user/geekparkhub/export/test/*;
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
hive (default)> 
```

#### 5.2.2 HadoopæŒ‡ä»¤å¯¼å‡ºåˆ°æœ¬åœ°
```
hive (default)> dfs -get /user/hive/warehouse/dept_partition/month=2020-00-00/dept.txt /opt/module/datas/test002.txt;
hive (default)> 
```
#### 5.2.3 Hive ShellæŒ‡ä»¤å¯¼å‡º
```
[root@systemhub711 hive]# bin/hive -e 'select * from test;' > /opt/module/datas/test002.txt; 

Logging initialized using configuration in file:/opt/module/hive/conf/hive-log4j.properties
OK
Time taken: 2.32 seconds, Fetched: 4 row(s)
[root@systemhub711 hive]# 
```
#### 5.2.4 Exportå¯¼å‡ºåˆ°HDFSä¸Š
```
hive (default)> export table test to '/user/geekparkhub/export/test002';
Copying data from file:/tmp/root/16f13154-2779-4719-89d3-3453b1468948/hive_411_6501223345710054079-1/-local-10000/_metadata
Copying file: file:/tmp/root/16f13154-2779-4719-89d3-3453b1468948/hive_411_6501223345710054079-1/-local-10000/_metadata
Copying data from hdfs://systemhub511:9000/user/hive/warehouse/test
Copying file: hdfs://systemhub511:9000/user/hive/warehouse/test/test.txt
OK
Time taken: 0.458 seconds
hive (default)>
hive (default)> dfs -cat /user/geekparkhub/export/test002/data/test.txt;
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
hive (default)> 
```

### 5.3 æ¸…é™¤è¡¨ä¸­æ•°æ® (Truncate)
> æ³¨æ„: Truncateåªèƒ½åˆ é™¤ç®¡ç†è¡¨,ä¸èƒ½åˆ é™¤å¤–éƒ¨è¡¨ä¸­æ•°æ®
```
hive (default)> select * from test007;
OK
test007.id      test007.name
1       TestUser001
2       TestUser002
3       TestUser003
4       TestUser004
Time taken: 0.079 seconds, Fetched: 4 row(s)
hive (default)> truncate table test007;
OK
Time taken: 0.083 seconds
hive (default)> select * from test007;
OK
test007.id      test007.name
Time taken: 0.078 seconds
hive (default)> 
```

## 6. æŸ¥è¯¢
> æŸ¥è¯¢åŸºæœ¬è¯­æ³•
```
[WITH CommonTableExpression (, CommonTableExpression)*]
(Note: Only available starting with Hive0.13.0)
SELECT [ALL | DISTINCT] select_expr, select_expr, ...
FROM table_reference
[WHERE where_condition]
[GROUP BY col_list]
[ORDER BY col_list]
[CLUSTER BY col_list| [DISTRIBUTE BY col_list] [SORT BY col_list]]
[LIMIT number]
```

### 6.1 åŸºæœ¬æŸ¥è¯¢ (Select...From)
#### 6.1.1 å…¨è¡¨å’Œç‰¹å®šåˆ—æŸ¥è¯¢
> æ³¨æ„:
> 
> 1.SQL è¯­è¨€å¤§å°å†™ä¸æ•æ„Ÿ.
> 
> 2.SQL å¯ä»¥å†™åœ¨ä¸€è¡Œæˆ–è€…å¤šè¡Œ.
> 
> 3.å…³é”®å­—ä¸èƒ½è¢«ç¼©å†™ä¹Ÿä¸èƒ½åˆ†è¡Œ.
> 
> 4.å„å­å¥ä¸€èˆ¬è¦åˆ†è¡Œå†™.
> 
> 5.ä½¿ç”¨ç¼©è¿›æé«˜è¯­å¥çš„å¯è¯»æ€§.
##### 6.1.1.1 å…¨è¡¨æŸ¥è¯¢
```
hive (default)> select * from emp;
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7369    SMITH   CLERKSKLD       7902    1980-12-17      800.0   20.0    
7499    ALLTE   SALESMANS       7689    1987-02-23      1600.0  300.0   30
7521    WAROS   SJDHHJDJX       7869    1984-06-12      1250.18 500.0    
Time taken: 0.129 seconds, Fetched: 9 row(s)
hive (default)> 
```
##### 6.1.1.2 é€‰æ‹©ç‰¹å®šåˆ—æŸ¥è¯¢
```
hive (default)> select empno,ename from emp;
OK
empno   ename
7369    SMITH
7499    ALLTE
7521    WAROS
7566    JOSSS
7654    SOCTD
7698    ADAMS
7782    JAMSK
7788    FOESS
7939    KINGS
Time taken: 0.123 seconds, Fetched: 9 row(s)
hive (default)> 
```

#### 6.1.2 åˆ—åˆ«å
> åœ¨åˆ—åå’Œåˆ«åä¹‹é—´åŠ å…¥å…³é”®å­—`AS`
```
hive (default)> select empno as no,ename as name from emp;
OK
no      name
7369    SMITH
7499    ALLTE
7521    WAROS
7566    JOSSS
7654    SOCTD
7698    ADAMS
7782    JAMSK
7788    FOESS
7939    KINGS
Time taken: 0.078 seconds, Fetched: 9 row(s)
hive (default)> 
```
#### 6.1.3 ç®—æœ¯è¿ç®—ç¬¦

| è¿ç®—ç¬¦      |     æè¿° |
| :--------: | :--------:|
| A + B    |   Aå’ŒB ç›¸åŠ  |
| A - B   |   Aå‡B |
| A * B    |   Aå’ŒB ç›¸ä¹˜ |
| A / B    |   Aé™¤ä»¥B |
| A % B    |   Aå¯¹Bå–ä½™ |
| A & B    |   Aå’ŒBæŒ‰ä½å–ä¸ |
| AB    |   Aå’ŒBæŒ‰ä½å–æˆ– |
| A+B    |   Aå’ŒBæŒ‰ä½å–å¼‚æˆ– |
| ~A    |   AæŒ‰ä½å–å |

> æŸ¥è¯¢æ‰€å‘˜å·¥è–ªæ°´+1
```
hive (default)> select sal +1 as wage from emp;
OK
wage
801.0
1601.0
1251.18
2895.25
2853.3
25525.02
1101.0
951.0
3001.0
Time taken: 0.063 seconds, Fetched: 9 row(s)
hive (default)> 
```
#### 6.1.4 å¸¸ç”¨å‡½æ•°
#### 6.1.4.1 æ±‚æ€»è¡Œæ•° (count)
```
hive (default)> select count(*) cnt from emp;
Query ID = root_20190328225729_5783bab3-92a5-4a6c-b830-c0f8e7127225
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553780256887_0006, Tracking URL = http://systemhub611:8088/proxy/application_1553780256887_0006/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553780256887_0006
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
Stage-1 map = 0%,  reduce = 0%
Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.55 sec
Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.43 sec
MapReduce Total cumulative CPU time: 3 seconds 430 msec
Ended Job = job_1553780256887_0006
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.43 sec   HDFS Read: 7647 HDFS Write: 2 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 430 msec
OK
cnt
9
Time taken: 42.734 seconds, Fetched: 1 row(s)
hive (default)> 
```
#### 6.1.4.2 æ±‚å·¥èµ„çš„æœ€å¤§å€¼ (max)
```
hive (default)> select max(sal) max_wage from emp;
Query ID = root_20190328225946_778636eb-c34a-4a75-b8e5-68684633a0a3
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553780256887_0007, Tracking URL = http://systemhub611:8088/proxy/application_1553780256887_0007/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553780256887_0007
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
Stage-1 map = 0%,  reduce = 0%
Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.33 sec
Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.07 sec
MapReduce Total cumulative CPU time: 3 seconds 70 msec
Ended Job = job_1553780256887_0007
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.07 sec   HDFS Read: 7836 HDFS Write: 9 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 70 msec
OK
max_wage
25524.02
Time taken: 31.112 seconds, Fetched: 1 row(s)
hive (default)> 
```
#### 6.1.4.3 æ±‚å·¥èµ„çš„æœ€å°å€¼ (min)
```
hive (default)> select min(sal) min_wage from emp;
Query ID = root_20190328230109_5dbce45f-9887-44cc-b6fb-5aa64ac11a50
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553780256887_0008, Tracking URL = http://systemhub611:8088/proxy/application_1553780256887_0008/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553780256887_0008
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
Stage-1 map = 0%,  reduce = 0%
Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.52 sec
Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.42 sec
MapReduce Total cumulative CPU time: 3 seconds 420 msec
Ended Job = job_1553780256887_0008
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.42 sec   HDFS Read: 7836 HDFS Write: 6 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 420 msec
OK
min_wage
800.0
Time taken: 30.23 seconds, Fetched: 1 row(s)
hive (default)>
```
#### 6.1.4.4 æ±‚å·¥èµ„çš„æ€»å’Œ (sum)
```
hive (default)> select sum(sal) sum_wage from emp;
Query ID = root_20190328230304_600ecafd-b2a6-4b53-8ba8-fb9938c9f0c9
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553780256887_0010, Tracking URL = http://systemhub611:8088/proxy/application_1553780256887_0010/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553780256887_0010
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
Stage-1 map = 0%,  reduce = 0%
Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.36 sec
Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.13 sec
MapReduce Total cumulative CPU time: 3 seconds 130 msec
Ended Job = job_1553780256887_0010
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.13 sec   HDFS Read: 7830 HDFS Write: 9 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 130 msec
OK
sum_wage
39970.75
Time taken: 33.111 seconds, Fetched: 1 row(s)
hive (default)> 
```
#### 6.1.4.5 æ±‚å·¥èµ„çš„å¹³å‡å€¼ (avg)
```
hive (default)> select avg(sal) avg_wage from emp;
Query ID = root_20190328230301_15ba0d3a-130a-42a5-9b9a-a313f187e814
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553780256887_0009, Tracking URL = http://systemhub611:8088/proxy/application_1553780256887_0009/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553780256887_0009
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
Stage-1 map = 0%,  reduce = 0%
Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.21 sec
Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 2.96 sec
MapReduce Total cumulative CPU time: 2 seconds 960 msec
Ended Job = job_1553780256887_0009
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 2.96 sec   HDFS Read: 8011 HDFS Write: 18 SUCCESS
Total MapReduce CPU Time Spent: 2 seconds 960 msec
OK
avg_wage
4441.194444444444
Time taken: 67.764 seconds, Fetched: 1 row(s)
hive (default)> 
```

#### 6.1.5 Limitè¯­å¥
> å…¸å‹çš„æŸ¥è¯¢ä¼šè¿”å›å¤šè¡Œæ•°æ®,LIMITå­å¥ç”¨äºé™åˆ¶è¿”å›çš„è¡Œæ•°.
```
hive (default)> select * from emp limit 5;
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7369    SMITH   CLERKSKLD       7902    1980-12-17      800.0   20.0    NULL
7499    ALLTE   SALESMANS       7689    1987-02-23      1600.0  300.0   30
7521    WAROS   SJDHHJDJX       7869    1984-06-12      1250.18 500.0   30
7566    JOSSS   JDHYHDSDS       4545    1874-05-15      2894.25 20.0    NULL
7654    SOCTD   MANSJUSSD       4855    1996-02-14      2852.3  30.0    NULL
Time taken: 0.135 seconds, Fetched: 5 row(s)
hive (default)> 
```

### 6.2 Whereè¯­å¥
> 1.ä½¿ç”¨`WHERE`å­å¥,å°†ä¸æ»¡è¶³æ¡ä»¶çš„è¡Œè¿‡æ»¤æ‰.
> 2.`WHERE`å­å¥ç´§éš`FROM`å­å¥.
> 3.æ¡ˆä¾‹å®æ“
> æŸ¥è¯¢å‡ºè–ªæ°´å¤§äº1000çš„æ‰€æœ‰å‘˜å·¥.
```
hive (default)> select * from emp where sal > 1000;
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7499    ALLTE   SALESMANS       7689    1987-02-23      1600.0  300.0   30
7521    WAROS   SJDHHJDJX       7869    1984-06-12      1250.18 500.0   30
7566    JOSSS   JDHYHDSDS       4545    1874-05-15      2894.25 20.0    NULL
7654    SOCTD   MANSJUSSD       4855    1996-02-14      2852.3  30.0    NULL
7698    ADAMS   JUSHHWESD       4552    1985-05-16      25524.02        30.0    NULL
7782    JAMSK   KIHNGSEHN       7769    1991-06-23      1100.0  20.0    NULL
7939    KINGS   CLADDJHEW       7566    1993-07-12      3000.0  20.0    NULL
Time taken: 0.26 seconds, Fetched: 7 row(s)
hive (default)> 
```
#### 6.2.1 æ¯”è¾ƒè¿ç®—ç¬¦ (Between / In / Is Null)
> ä¸‹é¢è¡¨ä¸­æè¿°äº†è°“è¯æ“ä½œç¬¦,è¿™äº›æ“ä½œç¬¦åŒæ ·å¯ä»¥ç”¨äºJOIN...ONå’ŒHAVINGè¯­å¥ä¸­.
##### 6.2.1.1 æ¯”è¾ƒè¿ç®—ç¬¦å¯¹ç…§è¡¨
| æ“ä½œç¬¦      |     æ”¯æŒæ•°æ®ç±»å‹ |   æè¿°   |
| :--------: | :--------:| :------: |
| A=B    |   åŸºæœ¬æ•°æ®ç±»å‹ |  å¦‚æœAç­‰äºBåˆ™è¿”å›TRUE,åä¹‹è¿”å›FALSE.  |
| A<=>B    |   åŸºæœ¬æ•°æ®ç±»å‹ |  å¦‚æœAå’ŒBéƒ½ä¸ºNULL,åˆ™è¿”å›TRUE,å…¶ä»–çš„å’Œç­‰å·(=)æ“ä½œç¬¦çš„ç»“æœä¸€è‡´,å¦‚æœä»»ä¸€ä¸ºNULLåˆ™ç»“æœä¸ºNULL.  |
| A<>B, A!=B    |   åŸºæœ¬æ•°æ®ç±»å‹ |  Aæˆ–è€…Bä¸ºNULLåˆ™è¿”å›NULL,å¦‚æœAä¸ç­‰äºB,åˆ™è¿”å›TRUE,åä¹‹è¿”å›FALSE.  |
| A<B    |   åŸºæœ¬æ•°æ®ç±»å‹ |  Aæˆ–è€…Bä¸ºNULL,åˆ™è¿”å›NULL,å¦‚æœAå°äºB,åˆ™è¿”å›TRUE,åä¹‹è¿”å›FALSE.  |
| A<=B    |   åŸºæœ¬æ•°æ®ç±»å‹ |  Aæˆ–è€…Bä¸ºNULL,åˆ™è¿”å›NULL,å¦‚æœAå°äºç­‰äºB,åˆ™è¿”å›TRUE,åä¹‹è¿”å›FALSE.  |
| A>B    |   åŸºæœ¬æ•°æ®ç±»å‹ |  Aæˆ–è€…Bä¸ºNULL,åˆ™è¿”å›NULL,å¦‚æœAå¤§äºB,åˆ™è¿”å›TRUE,åä¹‹è¿”å›FALSE.  |
| A>=B    |   åŸºæœ¬æ•°æ®ç±»å‹ |  Aæˆ–è€…Bä¸ºNULL,åˆ™è¿”å›NULL,å¦‚æœAå¤§äºç­‰äºB,åˆ™è¿”å›TRUE,åä¹‹è¿”å›FALSE.  |
| A [NOT] BETWEEN B AND C    |   åŸºæœ¬æ•°æ®ç±»å‹ |  å¦‚æœA,Bæˆ–è€…Cä»»ä¸€ä¸ºNULL,åˆ™ç»“æœä¸ºNULL,å¦‚æœAçš„å€¼å¤§äºç­‰äºBè€Œä¸”å°äºæˆ–ç­‰äºC,åˆ™ç»“æœä¸ºTRUE,åä¹‹ä¸ºFALSE,å¦‚æœä½¿ç”¨NOTå…³é”®å­—åˆ™å¯è¾¾åˆ°ç›¸åçš„æ•ˆæœ.  |
| A IS NULL    |   æ‰€æœ‰æ•°æ®ç±»å‹ |  å¦‚æœAç­‰äºNULL,åˆ™è¿”å›TRUE,åä¹‹è¿”å›FALSE.  |
| A IS NOT NULL    |   æ‰€æœ‰æ•°æ®ç±»å‹ |  å¦‚æœAä¸ç­‰äºNULL,åˆ™è¿”å›TRUE,åä¹‹è¿”å›FALSE. |
| IN(Num1,Num2)    |   æ‰€æœ‰æ•°æ®ç±»å‹ |  ä½¿ç”¨INè¿ç®—æ˜¾ç¤ºåˆ—è¡¨ä¸­çš„å€¼.  |
| A [NOT] LIKE B    |   STRING ç±»å‹ |  Bæ˜¯ä¸€ä¸ªSQLä¸‹çš„ç®€å•æ­£åˆ™è¡¨è¾¾å¼,å¦‚æœAä¸å…¶åŒ¹é…çš„è¯,åˆ™è¿”å›TRUE,åä¹‹è¿”å›FALSE,Bçš„è¡¨è¾¾å¼è¯´æ˜å¦‚ä¸‹:â€˜x%â€™è¡¨ç¤ºAå¿…é¡»ä»¥å­—æ¯â€˜xâ€™å¼€å¤´,â€˜%xâ€™è¡¨ç¤ºAå¿…é¡»ä»¥å­—æ¯â€™xâ€™ç»“å°¾,è€Œâ€˜%x%â€™è¡¨ç¤ºAåŒ…å«æœ‰å­—æ¯â€™xâ€™,å¯ä»¥ä½äºå¼€å¤´,ç»“å°¾æˆ–è€…å­—ç¬¦ä¸²ä¸­é—´,å¦‚æœä½¿ç”¨NOT,å…³é”®å­—åˆ™å¯è¾¾åˆ°ç›¸åçš„æ•ˆæœ.  |
| A RLIKE B,A REGEXP B    |   STRING ç±»å‹ |  Bæ˜¯ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼,å¦‚æœAä¸å…¶åŒ¹é…ï¼Œåˆ™è¿”å›TRUE,åä¹‹è¿”å›FALSE,åŒ¹é…ä½¿ç”¨çš„æ˜¯JDKä¸­çš„æ­£åˆ™è¡¨è¾¾å¼æ¥å£å®ç°çš„,å› ä¸ºæ­£åˆ™ä¹Ÿä¾æ®å…¶ä¸­çš„è§„åˆ™,ä¾‹å¦‚,æ­£åˆ™è¡¨è¾¾å¼å¿…é¡»å’Œæ•´ä¸ªå­—ç¬¦ä¸²Aç›¸åŒ¹é…,è€Œä¸æ˜¯åªéœ€ä¸å…¶å­—ç¬¦ä¸²åŒ¹é….  |

##### 6.2.1.2 æ¡ˆä¾‹å®æ“
###### 6.2.1.2.1 æŸ¥è¯¢è–ªæ°´ç­‰äº3000çš„æ‰€æœ‰å‘˜å·¥
```
hive (default)> select * from emp where sal = 3000;
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7939    KINGS   CLADDJHEW       7566    1993-07-12      3000.0  20.0    NULL
Time taken: 0.063 seconds, Fetched: 1 row(s)
hive (default)> 
```
###### 6.2.1.2.2 æŸ¥è¯¢å·¥èµ„åœ¨500åˆ°1000çš„å‘˜å·¥ä¿¡æ¯
```
hive (default)> select * from emp where sal between 500 and 1000;
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7369    SMITH   CLERKSKLD       7902    1980-12-17      800.0   20.0    NULL
7788    FOESS   CLAEDFDFD       7698    1994-09-17      950.0   30.0    NULL
Time taken: 0.086 seconds, Fetched: 2 row(s)
hive (default)> 
```
###### 6.2.1.2.3 æŸ¥è¯¢commä¸ºç©ºçš„æ‰€æœ‰å‘˜å·¥ä¿¡æ¯
```
hive (default)> select * from emp where comm is null;
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
Time taken: 0.077 seconds
hive (default)> 
```
###### 6.2.1.2.4 æŸ¥è¯¢å·¥èµ„æ˜¯1500å’Œ3000çš„å‘˜å·¥ä¿¡æ¯
```
hive (default)> select * from emp where sal IN(1500,3000);
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7939    KINGS   CLADDJHEW       7566    1993-07-12      3000.0  20.0    NULL
Time taken: 0.117 seconds, Fetched: 1 row(s)
hive (default)> 
```


#### 6.2.2 Likeå’ŒRLike
> 1.ä½¿ç”¨`LIKE`è¿ç®—é€‰æ‹©ç±»ä¼¼çš„å€¼.
> 
> 2.é€‰æ‹©æ¡ä»¶å¯ä»¥åŒ…å«å­—ç¬¦æˆ–æ•°å­—:
> `%` ä»£è¡¨é›¶ä¸ªæˆ–å¤šä¸ªå­—ç¬¦(ä»»æ„ä¸ªå­—ç¬¦)
> `_` ä»£è¡¨ä¸€ä¸ªå­—ç¬¦
> 
> 3.`RLIKE`å­å¥æ˜¯Hiveä¸­è¿™ä¸ªåŠŸèƒ½çš„ä¸€ä¸ªæ‰©å±•,å…¶å¯ä»¥é€šè¿‡Javaçš„æ­£åˆ™è¡¨è¾¾å¼è¿™ä¸ªæ›´å¼ºå¤§çš„è¯­è¨€æ¥æŒ‡å®šåŒ¹é…æ¡ä»¶.
##### 6.2.2.1 æ¡ˆä¾‹å®æ“
###### 6.2.2.1.1 æŸ¥æ‰¾ä»¥2å¼€å¤´è–ªæ°´çš„å‘˜å·¥ä¿¡æ¯
```
hive (default)> select * from emp where sal LIKE '2%';
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7566    JOSSS   JDHYHDSDS       4545    1874-05-15      2894.25 20.0    NULL
7654    SOCTD   MANSJUSSD       4855    1996-02-14      2852.3  30.0    NULL
7698    ADAMS   JUSHHWESD       4552    1985-05-16      25524.02        30.0    NULL
Time taken: 0.134 seconds, Fetched: 3 row(s)
hive (default)> 
```
###### 6.2.2.1.2 æŸ¥æ‰¾ç¬¬äºŒä¸ªæ•°å€¼ä¸º2è–ªæ°´çš„å‘˜å·¥ä¿¡æ¯
```
hive (default)> select * from emp where sal LIKE '_2%';
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7521    WAROS   SJDHHJDJX       7869    1984-06-12      1250.18 500.0   30
Time taken: 0.075 seconds, Fetched: 1 row(s)
hive (default)> 
```
###### 6.2.2.1.3 æŸ¥æ‰¾è–ªæ°´ä¸­å«æœ‰2çš„å‘˜å·¥ä¿¡æ¯
```
hive (default)> select * from emp where sal RLIKE '[2]';
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7521    WAROS   SJDHHJDJX       7869    1984-06-12      1250.18 500.0   30
7566    JOSSS   JDHYHDSDS       4545    1874-05-15      2894.25 20.0    NULL
7654    SOCTD   MANSJUSSD       4855    1996-02-14      2852.3  30.0    NULL
7698    ADAMS   JUSHHWESD       4552    1985-05-16      25524.02        30.0    NULL
Time taken: 0.088 seconds, Fetched: 4 row(s)
hive (default)> 
```

#### 6.2.3 é€»è¾‘è¿ç®—ç¬¦ (And / Or / Not)

| æ“ä½œç¬¦      |     å«ä¹‰ |
| :--------: | :--------:|
| AND    |   é€»è¾‘å¹¶ |
| OR    |   é€»è¾‘æˆ– |
| NOT    |   é€»è¾‘å¦ |
##### 6.2.3.1 æ¡ˆä¾‹å®æ“
###### 6.2.3.1.1 æŸ¥è¯¢è–ªæ°´å¤§äº1000,éƒ¨é—¨æ˜¯30
```
hive (default)> select * from emp where sal > 1000 AND deptno = 30;
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7499    ALLTE   SALESMANS       7689    1987-02-23      1600.0  300.0   30
7521    WAROS   SJDHHJDJX       7869    1984-06-12      1250.18 500.0   30
Time taken: 0.107 seconds, Fetched: 2 row(s)
hive (default)> 
```
###### 6.2.3.1.2 æŸ¥è¯¢è–ªæ°´å¤§äº1000,æˆ–è€…éƒ¨é—¨æ˜¯30
```
hive (default)> select * from emp where sal > 1000 or deptno = 30;
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7499    ALLTE   SALESMANS       7689    1987-02-23      1600.0  300.0   30
7521    WAROS   SJDHHJDJX       7869    1984-06-12      1250.18 500.0   30
7566    JOSSS   JDHYHDSDS       4545    1874-05-15      2894.25 20.0    NULL
7654    SOCTD   MANSJUSSD       4855    1996-02-14      2852.3  30.0    NULL
7698    ADAMS   JUSHHWESD       4552    1985-05-16      25524.02        30.0    NULL
7782    JAMSK   KIHNGSEHN       7769    1991-06-23      1100.0  20.0    NULL
7939    KINGS   CLADDJHEW       7566    1993-07-12      3000.0  20.0    NULL
Time taken: 0.088 seconds, Fetched: 7 row(s)
hive (default)> 
```
###### 6.2.3.1.3 æŸ¥è¯¢é™¤äº†20éƒ¨é—¨å’Œ30éƒ¨é—¨ä»¥å¤–çš„å‘˜å·¥ä¿¡æ¯
```
hive (default)> select * from emp where deptno not IN(30,20);
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
Time taken: 0.067 seconds
hive (default)> 
```

### 6.3 åˆ†ç»„
#### 6.3.1 Group By è¯­å¥
> `GROUP  BY`è¯­å¥é€šå¸¸ä¼šå’Œèšåˆå‡½æ•°ä¸€èµ·ä½¿ç”¨,æŒ‰ç…§ä¸€ä¸ªæˆ–è€…å¤šä¸ªåˆ—é˜Ÿç»“æœè¿›è¡Œåˆ†ç»„,ç„¶åå¯¹æ¯ä¸ªç»„æ‰§è¡Œèšåˆæ“ä½œ.
> 
> 1.è®¡ç®—empè¡¨æ¯ä¸ªéƒ¨é—¨çš„å¹³å‡å·¥èµ„.
```
hive (default)> select avg(sal) avg_sal from emp
              > group by deptno;
Query ID = root_20190329100652_589ff409-e520-40bc-9cb4-4637d9775441
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553824894278_0001, Tracking URL = http://systemhub611:8088/proxy/application_1553824894278_0001/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553824894278_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
Stage-1 map = 0%,  reduce = 0%
Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.72 sec
Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.55 sec
MapReduce Total cumulative CPU time: 3 seconds 550 msec
Ended Job = job_1553824894278_0001
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.55 sec   HDFS Read: 8446 HDFS Write: 37 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 550 msec
OK
avg_sal
5302.938571428572
1425.0900000000001
Time taken: 39.062 seconds, Fetched: 2 row(s)
hive (default)> 
```
> 2.è®¡ç®—empæ¯ä¸ªéƒ¨é—¨ä¸­æ¯ä¸ªå²—ä½çš„æœ€é«˜è–ªæ°´.
```
hive (default)> select deptno,job,avg(sal) avg_sal from emp
              > group by deptno,job;
Query ID = root_20190329101147_338b3ac5-d29e-46eb-abae-d4d2a3bcc3ae
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553824894278_0002, Tracking URL = http://systemhub611:8088/proxy/application_1553824894278_0002/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553824894278_0002
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
Stage-1 map = 0%,  reduce = 0%
Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.21 sec
Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 2.97 sec
MapReduce Total cumulative CPU time: 2 seconds 970 msec
Ended Job = job_1553824894278_0002
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 2.97 sec   HDFS Read: 8904 HDFS Write: 182 SUCCESS
Total MapReduce CPU Time Spent: 2 seconds 970 msec
OK
deptno  job     avg_sal
NULL    CLADDJHEW       3000.0
NULL    CLAEDFDFD       950.0
NULL    CLERKSKLD       800.0
NULL    JDHYHDSDS       2894.25
NULL    JUSHHWESD       25524.02
NULL    KIHNGSEHN       1100.0
NULL    MANSJUSSD       2852.3
30      SALESMANS       1600.0
30      SJDHHJDJX       1250.18
Time taken: 28.517 seconds, Fetched: 9 row(s)
hive (default)> 
```

#### 6.3.2 Having è¯­å¥
> havingä¸whereä¸åŒç‚¹
> 
> whereé’ˆå¯¹è¡¨ä¸­çš„åˆ—å‘æŒ¥ä½œç”¨,æŸ¥è¯¢æ•°æ®.
> havingé’ˆå¯¹æŸ¥è¯¢ç»“æœä¸­çš„åˆ—å‘æŒ¥ä½œç”¨,ç­›é€‰æ•°æ®.
> whereåé¢ä¸èƒ½å†™åˆ†ç»„å‡½æ•°,è€Œhavingåé¢å¯ä»¥ä½¿ç”¨åˆ†ç»„å‡½æ•°.
> havingåªç”¨äºgroup byåˆ†ç»„ç»Ÿè®¡è¯­å¥.

> æ±‚æ¯ä¸ªéƒ¨é—¨çš„å¹³å‡è–ªæ°´å¤§äº2000çš„éƒ¨é—¨
```
hive (default)> select deptno,avg(sal) avg_sal from emp
              > group by deptno
              > having avg_sal > 2000;
Query ID = root_20190329102456_d4f50a80-3441-421c-9e89-acf8665d98aa
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1553824894278_0003, Tracking URL = http://systemhub611:8088/proxy/application_1553824894278_0003/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553824894278_0003
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
Stage-1 map = 0%,  reduce = 0%
Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.2 sec
Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.65 sec
MapReduce Total cumulative CPU time: 3 seconds 650 msec
Ended Job = job_1553824894278_0003
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.65 sec   HDFS Read: 8985 HDFS Write: 21 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 650 msec
OK
deptno  avg_sal
NULL    5302.938571428572
Time taken: 29.14 seconds, Fetched: 1 row(s)
hive (default)> 
```

### 6.4 Joinè¯­å¥
#### 6.4.1 ç­‰å€¼Join
> Hiveæ”¯æŒé€šå¸¸çš„`SQL JOIN`è¯­å¥,ä½†æ˜¯åªæ”¯æŒç­‰å€¼è¿æ¥,ä¸æ”¯æŒéç­‰å€¼è¿æ¥.
```
hive (default)> select e.empno,e.ename,d.dname
              > from emp e join dept d
              > on e.deptno=d.deptid;
Query ID = root_d5dfa88a-b9a2-4377-aebe-1328cf0b6653
Total jobs = 1
WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Execution log at: /tmp/root/aebe-1328cf0b6653.log
Starting to launch local task to process map join;      maximum memory = 518979584
Dump the side-table for tag: 1 with group count: 4 into file: file:/tmp/root/c9582a8b-1e8f-446e-b899-f5114533b280/-local-10003/HashTable-Stage-3/MapJoin-mapfile01--.hashtable
Uploaded 1 File to: file:/tmp/root/c9582a8b-1e8f-446e-b899-f5114533b280/hive_2019-03-29_11-02-28_999_8089713357386975442-1/-local-10003/HashTable-Stage-3/MapJoin-mapfile01--.hashtable (373 bytes)
End of local task; Time Taken: 1.969 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1553824894278_0004, Tracking URL = http://systemhub611:8088/proxy/application_1553824894278_0004/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553824894278_0004
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0
Stage-3 map = 0%,  reduce = 0%
Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.81 sec
MapReduce Total cumulative CPU time: 1 seconds 810 msec
Ended Job = job_1553824894278_0004
MapReduce Jobs Launched: 
Stage-Stage-3: Map: 1   Cumulative CPU: 1.81 sec   HDFS Read: 7157 HDFS Write: 0 SUCCESS
Total MapReduce CPU Time Spent: 1 seconds 810 msec
OK
e.empno e.ename d.dname
Time taken: 29.819 seconds
hive (default)> 
```
#### 6.4.2 è¡¨åˆ«å
> 1.å¥½å¤„:
> ä½¿ç”¨åˆ«åå¯ä»¥ç®€åŒ–æŸ¥è¯¢.
> ä½¿ç”¨è¡¨åå‰ç¼€å¯ä»¥æé«˜æ‰§è¡Œæ•ˆç‡.
> 
> æ¡ˆä¾‹å®æ“
```
hive (default)> select e.empno,e.ename,d.dname
              > from emp e join dept d
              > on e.deptno=d.deptid;
```
#### 6.4.3 å†…è¿æ¥
> å†…è¿æ¥: åªæœ‰è¿›è¡Œè¿æ¥çš„ä¸¤ä¸ªè¡¨ä¸­éƒ½å­˜åœ¨ä¸è¿æ¥æ¡ä»¶ç›¸åŒ¹é…çš„æ•°æ®æ‰ä¼šè¢«ä¿ç•™ä¸‹.
#### 6.4.4 å·¦å¤–è¿æ¥
> å·¦å¤–è¿æ¥: JOINæ“ä½œç¬¦å·¦è¾¹è¡¨ä¸­ç¬¦åˆWHEREå­å¥çš„æ‰€æœ‰è®°å½•å°†ä¼šè¢«è¿”å›.
```
hive (default)> select e.empno,e.ename,d.dname
              > from emp e left join dept d
              > on e.deptno=d.deptid;
Query ID = root_20190329112652_1446145a-1749-4a6f-85ad-b4576ee31e0f
Total jobs = 1
WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Execution log at: /tmp/root/root_20190329112652_1446145a-1749-4a6f-85ad-b4576ee31e0f.log
Starting to launch local task to process map join;      maximum memory = 518979584
2019-03-29 11:26:59     Dump the side-table for tag: 1 with group count: 4 into file: file:/tmp/root/c9582a8b-1e8f-446e-b899-f5114533b280/hive_2019-03-29_11-26-52_365_8094669471916599336-1/-local-10003/HashTable-Stage-3/MapJoin-mapfile11--.hashtable
2019-03-29 11:26:59     Uploaded 1 File to: file:/tmp/root/c9582a8b-1e8f-446e-b899-f5114533b280/hive_2019-03-29_11-26-52_365_8094669471916599336-1/-local-10003/HashTable-Stage-3/MapJoin-mapfile11--.hashtable (373 bytes)
End of local task; Time Taken: 1.522 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1553824894278_0005, Tracking URL = http://systemhub611:8088/proxy/application_1553824894278_0005/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553824894278_0005
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0
Stage-3 map = 0%,  reduce = 0%
Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.44 sec
MapReduce Total cumulative CPU time: 1 seconds 440 msec
Ended Job = job_1553824894278_0005
MapReduce Jobs Launched: 
Stage-Stage-3: Map: 1   Cumulative CPU: 1.44 sec   HDFS Read: 7035 HDFS Write: 126 SUCCESS
Total MapReduce CPU Time Spent: 1 seconds 440 msec
OK
e.empno e.ename d.dname
7369    SMITH   NULL
7499    ALLTE   NULL
7521    WAROS   NULL
7566    JOSSS   NULL
7654    SOCTD   NULL
7698    ADAMS   NULL
7782    JAMSK   NULL
7788    FOESS   NULL
7939    KINGS   NULL
Time taken: 32.565 seconds, Fetched: 9 row(s)
hive (default)> 
```
#### 6.4.5 å³å¤–è¿æ¥
> å³å¤–è¿æ¥: JOINæ“ä½œç¬¦å³è¾¹è¡¨ä¸­ç¬¦åˆWHEREå­å¥çš„æ‰€æœ‰è®°å½•å°†ä¼šè¢«è¿”å›.
```
hive (default)> select e.empno,e.ename,d.dname
              > from emp e right join dept d
              > on e.deptno=d.deptid;
Query ID = root_20190329115001_8d324711-c545-4ea3-bef5-28cc14a11989
Total jobs = 1
19/03/29 11:50:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Execution log at: /tmp/root/root_20190329115001_8d324711-c545-4ea3-bef5-28cc14a11989.log
Starting to launch local task to process map join;      maximum memory = 518979584
2019-03-29 11:50:08     Dump the side-table for tag: 0 with group count: 2 into file: file:/tmp/root/c9582a8b-1e8f-446e-b899-f5114533b280/hive_2019-03-29_11-50-01_720_5879451311571173295-1/-local-10003/HashTable-Stage-3/MapJoin-mapfile20--.hashtable
2019-03-29 11:50:09     Uploaded 1 File to: file:/tmp/root/c9582a8b-1e8f-446e-b899-f5114533b280/hive_2019-03-29_11-50-01_720_5879451311571173295-1/-local-10003/HashTable-Stage-3/MapJoin-mapfile20--.hashtable (413 bytes)
End of local task; Time Taken: 1.56 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1553824894278_0006, Tracking URL = http://systemhub611:8088/proxy/application_1553824894278_0006/
Kill Command = /opt/module/hadoop/bin/hadoop job  -kill job_1553824894278_0006
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0
Stage-3 map = 0%,  reduce = 0%
Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 1.42 sec
MapReduce Total cumulative CPU time: 1 seconds 420 msec
Ended Job = job_1553824894278_0006
MapReduce Jobs Launched: 
Stage-Stage-3: Map: 1   Cumulative CPU: 1.42 sec   HDFS Read: 6640 HDFS Write: 61 SUCCESS
Total MapReduce CPU Time Spent: 1 seconds 420 msec
OK
e.empno e.ename d.dname
NULL    NULL    ACCOUNTING
NULL    NULL    RESEARCH
NULL    NULL    SALES
NULL    NULL    OPERATIONS
Time taken: 29.374 seconds, Fetched: 4 row(s)
hive (default)> 
```

#### 6.4.6 æ»¡å¤–è¿æ¥
> æ»¡å¤–è¿æ¥: å°†ä¼šè¿”å›æ‰€æœ‰è¡¨ä¸­ç¬¦åˆWHEREè¯­å¥æ¡ä»¶çš„æ‰€æœ‰è®°å½•,å¦‚æœä»»ä¸€è¡¨çš„æŒ‡å®šå­—æ®µæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å€¼çš„è¯,é‚£ä¹ˆå°±ä½¿ç”¨NULLå€¼æ›¿ä»£.
```
hive (default)> select e.empno,e.ename,d.dname
              > from emp e full join dept d
              > on e.deptno=d.deptid;
Stage-Stage-1: Map: 2  Reduce: 1   Cumulative CPU: 5.24 sec   HDFS Read: 13887 HDFS Write: 187 SUCCESS
Total MapReduce CPU Time Spent: 5 seconds 240 msec
OK
e.empno e.ename d.dname
7939    KINGS   NULL
7788    FOESS   NULL
7782    JAMSK   NULL
7698    ADAMS   NULL
7654    SOCTD   NULL
7566    JOSSS   NULL
7369    SMITH   NULL
7521    WAROS   NULL
7499    ALLTE   NULL
NULL    NULL    ACCOUNTING
NULL    NULL    RESEARCH
NULL    NULL    SALES
NULL    NULL    OPERATIONS
Time taken: 35.59 seconds, Fetched: 13 row(s)
hive (default)> 
```

#### 6.4.7 å¤šè¡¨è¿æ¥
> æ³¨æ„: è¿æ¥nä¸ªè¡¨,è‡³å°‘éœ€è¦n-1ä¸ªè¿æ¥æ¡ä»¶.
> ä¾‹å¦‚: è¿æ¥ä¸‰ä¸ªè¡¨,è‡³å°‘éœ€è¦ä¸¤ä¸ªè¿æ¥æ¡ä»¶.
> 0.æ•°æ®å‡†å¤‡
```
[root@systemhub711 ~]# cd /opt/module/datas/
[root@systemhub711 datas]# vim location.txt
```
```
1700    Beijing
1800    London
1900    Tokyo
```
> 1.åˆ›å»ºä½ç½®è¡¨
```
hive (default)> create table if not exists default.location(loc int,loc_name string)row format delimited fields terminated by '\t';
OK
Time taken: 0.328 seconds
hive (default)> 
```
> 2.å¯¼å…¥æ•°æ®
```
hive (default)> load data local inpath '/opt/module/datas/location.txt' into table location;
Loading data to table default.location
Table default.location stats: [numFiles=1, totalSize=36]
OK
Time taken: 0.386 seconds
hive (default)> select * from location;
OK
location.loc    location.loc_name
1700    Beijing
1800    London
1900    Tokyo
Time taken: 0.077 seconds, Fetched: 3 row(s)
hive (default)> 
```
> 3.å¤šè¡¨è¿æ¥æŸ¥è¯¢
```
hive (default)> select e.ename,d.dname,l.loc_name
              > from emp e join dept d
              > on e.deptno=d.deptid
              > join location l
              > on d.loc=l.loc;
```
> å¤§å¤šæ•°æƒ…å†µä¸‹,Hiveä¼šå¯¹æ¯å¯¹JOINè¿æ¥å¯¹è±¡å¯åŠ¨ä¸€ä¸ªMapReduceä»»åŠ¡.
> 
> æœ¬ä¾‹ä¸­ä¼šé¦–å…ˆå¯åŠ¨ä¸€ä¸ªMapReduce jobå¯¹è¡¨eå’Œè¡¨dè¿›è¡Œè¿æ¥æ“ä½œ,ç„¶åä¼šå†å¯åŠ¨ä¸€ä¸ªMapReduce jobå°†ç¬¬ä¸€ä¸ªMapReduce jobçš„è¾“å‡ºå’Œè¡¨l;è¿›è¡Œè¿æ¥æ“ä½œ.
> 
> æ³¨æ„: ä¸ºä»€ä¹ˆä¸æ˜¯è¡¨då’Œè¡¨lå…ˆè¿›è¡Œè¿æ¥æ“ä½œå‘¢? è¿™æ˜¯å› ä¸ºHiveæ€»æ˜¯æŒ‰ç…§ä»å·¦åˆ°å³çš„é¡ºåºæ‰§è¡Œçš„.

#### 6.4.8 ç¬›å¡å°”ç§¯
> 1.ç¬›å¡å°”é›†ä¼šåœ¨ä¸‹é¢æ¡ä»¶ä¸‹äº§ç”Ÿ:
> 
> çœç•¥è¿æ¥æ¡ä»¶.
> 
> è¿æ¥æ¡ä»¶æ— æ•ˆ.
> 
> æ‰€æœ‰è¡¨ä¸­çš„æ‰€æœ‰è¡Œäº’ç›¸è¿æ¥.
> 
> æ¡ˆä¾‹å®æ“
```
hive (default)> select empno, deptno from emp, dept;
Warning: Map Join MAPJOIN[7][bigTable=emp] in task 'Stage-3:MAPRED' is a cross product
Query ID = root_20190329124854_dc330707-1941-4608-8244-1d5bd9214e38
Total jobs = 1
Total MapReduce CPU Time Spent: 1 seconds 470 msec
OK
empno   deptno
7369    NULL
7369    NULL
7369    NULL
7369    NULL
7499    30
7499    30
7499    30
7499    30
7521    30
```
#### 6.4.9 è¿æ¥è°“è¯ä¸­ä¸æ”¯æŒor
> é”™è¯¯ç¤ºèŒƒ
```
hive (default)> select e.empno,e.ename,d.deptno from emp e join dept d on e.deptno=d.deptno or e.ename=d.ename;

FAILED: SemanticException [Error 10019]: Line 1:58 OR not supported in JOIN currently 'ename'
hive (default)> 
```

### 6.5 æ’åº
#### 6.5.1 å…¨å±€æ’åº (Order By)
> Order By: å…¨å±€æ’åº,ä¸€ä¸ªMapReduce
##### 6.5.1.1 ä½¿ç”¨`ORDER BY` å­å¥æ’åº
> ASC (ascend) å‡åº (é»˜è®¤)
> DESC (descend) é™åº
##### 6.5.1.2 `ORDER BY` å­å¥åœ¨`SELECT`è¯­å¥ç»“å°¾
##### 6.5.1.3 æ¡ˆä¾‹å®æ“
###### 6.5.1.3.1 æŸ¥è¯¢å‘˜å·¥ä¿¡æ¯æŒ‰å·¥èµ„å‡åºæ’åˆ—
```
hive (default)> select * from emp order by sal;
Query ID = root_20190329130738_e22bdd23-0e80-43cb-8667-dde41851efa4
Total jobs = 1
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.13 sec   HDFS Read: 8460 HDFS Write: 472 SUCCESS
Total MapReduce CPU Time Spent: 3 seconds 130 msec
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7369    SMITH   CLERKSKLD       7902    1980-12-17      800.0   20.0    NULL
7788    FOESS   CLAEDFDFD       7698    1994-09-17      950.0   30.0    NULL
7782    JAMSK   KIHNGSEHN       7769    1991-06-23      1100.0  20.0    NULL
7521    WAROS   SJDHHJDJX       7869    1984-06-12      1250.18 500.0   30
7499    ALLTE   SALESMANS       7689    1987-02-23      1600.0  300.0   30
7654    SOCTD   MANSJUSSD       4855    1996-02-14      2852.3  30.0    NULL
7566    JOSSS   JDHYHDSDS       4545    1874-05-15      2894.25 20.0    NULL
7939    KINGS   CLADDJHEW       7566    1993-07-12      3000.0  20.0    NULL
7698    ADAMS   JUSHHWESD       4552    1985-05-16      25524.02        30.0    NULL
Time taken: 29.233 seconds, Fetched: 9 row(s)
hive (default)>
```
###### 6.5.1.3.2 æŸ¥è¯¢å‘˜å·¥ä¿¡æ¯æŒ‰å·¥èµ„é™åºæ’åˆ—
```
hive (default)> select * from emp order by sal desc;
Query ID = root_20190329131750_d47ccdca-56fa-4b3f-aac1-e9d35e5e44e3
Total MapReduce CPU Time Spent: 3 seconds 450 msec
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7698    ADAMS   JUSHHWESD       4552    1985-05-16      25524.02        30.0    NULL
7939    KINGS   CLADDJHEW       7566    1993-07-12      3000.0  20.0    NULL
7566    JOSSS   JDHYHDSDS       4545    1874-05-15      2894.25 20.0    NULL
7654    SOCTD   MANSJUSSD       4855    1996-02-14      2852.3  30.0    NULL
7499    ALLTE   SALESMANS       7689    1987-02-23      1600.0  300.0   30
7521    WAROS   SJDHHJDJX       7869    1984-06-12      1250.18 500.0   30
7782    JAMSK   KIHNGSEHN       7769    1991-06-23      1100.0  20.0    NULL
7788    FOESS   CLAEDFDFD       7698    1994-09-17      950.0   30.0    NULL
7369    SMITH   CLERKSKLD       7902    1980-12-17      800.0   20.0    NULL
```

#### 6.5.2 æŒ‰ç…§åˆ«åæ’åº
> æŒ‰ç…§å‘˜å·¥è–ªæ°´çš„2å€æ’åº
```
hive (default)> select ename,sal*2 twosal from emp order by twosal;
Query ID = root_20190329132035_8bf552a3-03b8-4e33-835b-56f26c8a5a12
Total MapReduce CPU Time Spent: 3 seconds 490 msec
OK
ename   twosal
SMITH   1600.0
FOESS   1900.0
JAMSK   2200.0
WAROS   2500.36
ALLTE   3200.0
SOCTD   5704.6
JOSSS   5788.5
KINGS   6000.0
ADAMS   51048.04
Time taken: 31.107 seconds, Fetched: 9 row(s)
hive (default)> 
```

#### 6.5.3 å¤šåˆ—æ’åº
> æŒ‰ç…§éƒ¨é—¨å’Œå·¥èµ„å‡åºæ’åº
```
hive (default)> select ename,deptno,sal from emp order by deptno,sal;
Query ID = root_20190329132255_7a5c8581-0c60-4a17-a726-5f8c1f8d8b36
Total MapReduce CPU Time Spent: 2 seconds 770 msec
OK
ename   deptno  sal
SMITH   NULL    800.0
FOESS   NULL    950.0
JAMSK   NULL    1100.0
SOCTD   NULL    2852.3
JOSSS   NULL    2894.25
KINGS   NULL    3000.0
ADAMS   NULL    25524.02
WAROS   30      1250.18
ALLTE   30      1600.0
Time taken: 28.476 seconds, Fetched: 9 row(s)
hive (default)> 
```
#### 6.5.4 MapReduceå†…éƒ¨æ’åº (Sort By)
> Sort By: æ¯ä¸ªMapReduceå†…éƒ¨è¿›è¡Œæ’åº,å¯¹å…¨å±€ç»“æœé›†æ¥è¯´ä¸æ˜¯æ’åº.
> 
> 1.è®¾ç½®reduceä¸ªæ•°.
```
hive (default)> set mapreduce.job.reduces=3;
```
> 
> 2.æŸ¥çœ‹è®¾ç½®reduceä¸ªæ•°.
```
hive (default)> set mapreduce.job.reduces;
mapreduce.job.reduces=3
hive (default)> 
```
> 
> 3.æ ¹æ®éƒ¨é—¨ç¼–å·é™åºæŸ¥çœ‹å‘˜å·¥ä¿¡æ¯.
```
hive (default)> select * from emp sort by empno desc;
Query ID = root_20190329133608_60e6d25c-1197-4a09-8c96-df4fdbb35628
Stage-Stage-1: Map: 1  Reduce: 3   Cumulative CPU: 7.96 sec   HDFS Read: 16132 HDFS Write: 472 SUCCESS
Total MapReduce CPU Time Spent: 7 seconds 960 msec
OK
emp.empno       emp.ename       emp.job emp.mgr emp.hiredate    emp.sal emp.comm        emp.deptno
7939    KINGS   CLADDJHEW       7566    1993-07-12      3000.0  20.0    NULL
7788    FOESS   CLAEDFDFD       7698    1994-09-17      950.0   30.0    NULL
7782    JAMSK   KIHNGSEHN       7769    1991-06-23      1100.0  20.0    NULL
7698    ADAMS   JUSHHWESD       4552    1985-05-16      25524.02        30.0    NULL
7654    SOCTD   MANSJUSSD       4855    1996-02-14      2852.3  30.0    NULL
7566    JOSSS   JDHYHDSDS       4545    1874-05-15      2894.25 20.0    NULL
7521    WAROS   SJDHHJDJX       7869    1984-06-12      1250.18 500.0   30
7499    ALLTE   SALESMANS       7689    1987-02-23      1600.0  300.0   30
7369    SMITH   CLERKSKLD       7902    1980-12-17      800.0   20.0    NULL
Time taken: 32.412 seconds, Fetched: 9 row(s)
hive (default)> 
```

#### 6.5.5 åˆ†åŒºæ’åº (Distribute By)
> Distribute By: ç±»ä¼¼MRä¸­partition,è¿›è¡Œåˆ†åŒº,ç»“åˆ`sort by`ä½¿ç”¨.
> æ³¨æ„,Hiveè¦æ±‚`DISTRIBUTE BY`è¯­å¥è¦å†™åœ¨`SORT BY`è¯­å¥ä¹‹å‰.
> å¯¹äº`distribute by`è¿›è¡Œæµ‹è¯•,ä¸€å®šè¦åˆ†é…å¤šreduceè¿›è¡Œå¤„ç†,å¦åˆ™æ— æ³•çœ‹åˆ°`distribute by`çš„æ•ˆæœ.
> 

#### 6.5.6 Cluster By
> å½“`distribute by`å’Œ`sorts by`å­—æ®µç›¸åŒæ—¶,å¯ä»¥ä½¿ç”¨`cluster by`æ–¹å¼.
> 
> `cluster by`é™¤äº†å…·æœ‰`distribute by`çš„åŠŸèƒ½å¤–è¿˜å…¼å…·`sort by`çš„åŠŸèƒ½,ä½†æ˜¯æ’åºåªèƒ½æ˜¯å€’åºæ’åº,ä¸èƒ½æŒ‡å®šæ’åºè§„åˆ™ä¸º`ASC`æˆ–è€…`DESC`.
> 1.ä»¥ä¸‹ä¸¤ç§å†™æ³•ç­‰ä»·
```
hive (default)> select * from emp cluster by deptno;

hive (default)> select * from emp distribute by deptno sort by deptno;
```
> æ³¨æ„: æŒ‰ç…§éƒ¨é—¨ç¼–å·åˆ†åŒº,ä¸ä¸€å®šå°±æ˜¯å›ºå®šæ­»çš„æ•°å€¼,å¯ä»¥æ˜¯20å·å’Œ30å·éƒ¨é—¨åˆ†åˆ°ä¸€ä¸ªåˆ†åŒºé‡Œé¢å».

### 6.6 åˆ†æ¡¶åŠæŠ½æ ·æŸ¥è¯¢
#### 6.6.1 åˆ†æ¡¶è¡¨æ•°æ®å­˜å‚¨
> åˆ†åŒºé’ˆå¯¹çš„æ˜¯æ•°æ®çš„å­˜å‚¨è·¯å¾„,åˆ†æ¡¶é’ˆå¯¹çš„æ˜¯æ•°æ®æ–‡ä»¶.
> 
> åˆ†åŒºæä¾›ä¸€ä¸ªéš”ç¦»æ•°æ®å’Œä¼˜åŒ–æŸ¥è¯¢çš„ä¾¿åˆ©æ–¹å¼,ä¸è¿‡å¹¶éæ‰€æœ‰çš„æ•°æ®é›†éƒ½å¯å½¢æˆåˆç†çš„åˆ†åŒº,ç‰¹åˆ«æ˜¯ä¹‹å‰æ‰€æåˆ°è¿‡çš„è¦ç¡®å®šåˆé€‚çš„åˆ’åˆ†å¤§å°è¿™ä¸ªç–‘è™‘.
> 
> åˆ†æ¡¶æ˜¯å°†æ•°æ®é›†åˆ†è§£æˆæ›´å®¹æ˜“ç®¡ç†çš„è‹¥å¹²éƒ¨åˆ†çš„å¦ä¸€ä¸ªæŠ€æœ¯.
> 
##### 6.6.1.1 å…ˆåˆ›å»ºåˆ†æ¡¶è¡¨,é€šè¿‡ç›´æ¥å¯¼å…¥æ•°æ®æ–‡ä»¶çš„æ–¹å¼
###### 6.6.1.1.1 æ•°æ®å‡†å¤‡
```
[root@systemhub711 datas]# vim test_bucket.txt
```
```
1001    101
1002    102
1003    103
1004    104
1005    105
1006    106
1007    107
1008    108
1009    109
1010    110
1011    111
1012    112
1013    113
1014    114
1015    115
1016    116
```
###### 6.6.1.1.2 åˆ›å»ºåˆ†æ¡¶è¡¨
```
hive (default)> create table test_bucket(id int,name string)
              > clustered by (id)
              > into 4 buckets
              > row format delimited fields terminated by '\t';
OK
Time taken: 0.138 seconds
hive (default)> 
```
###### 6.6.1.1.3 æŸ¥çœ‹è¡¨ç»“æ„
```
hive (default)> desc formatted test_bucket;
OK
col_name        data_type       comment
# col_name              data_type               comment             
                 
id                      int                                         
name                    string                                      
                 
# Detailed Table Information             
Database:               default                  
Owner:                  root                       
LastAccessTime:         UNKNOWN                  
Protect Mode:           None                     
Retention:              0                        
Location:               hdfs://systemhub511:9000/user/hive/warehouse/test_bucket         
Table Type:             MANAGED_TABLE            
Table Parameters:                
        transient_lastDdlTime   1553865393          
                 
# Storage Information            
SerDe Library:          org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe       
InputFormat:            org.apache.hadoop.mapred.TextInputFormat         
OutputFormat:           org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat       
Compressed:             No                       
Num Buckets:            4                        
Bucket Columns:         [id]                     
Sort Columns:           []                       
Storage Desc Params:             
        field.delim             \t                  
        serialization.format    \t                  
Time taken: 0.123 seconds, Fetched: 28 row(s)
hive (default)> 
```
###### 6.6.1.1.4 å¯¼å…¥æ•°æ®åˆ°åˆ†æ¡¶è¡¨ä¸­
```
hive (default)> load data local inpath '/opt/module/datas/test_bucket.txt' into table test_bucket;
Loading data to table default.test_bucket
Table default.test_bucket stats: [numFiles=1, totalSize=144]
OK
Time taken: 0.345 seconds
hive (default)> 
```
###### 6.6.1.1.5 æŸ¥çœ‹åˆ›å»ºçš„åˆ†æ¡¶è¡¨ä¸­æ˜¯å¦åˆ†æˆ4ä¸ªæ¡¶
> å‘ç°å¹¶æ²¡æœ‰åˆ†æˆ4ä¸ªæ¡¶,æ˜¯ä»€ä¹ˆåŸå› å‘¢
```
hive (default)> dfs -cat /user/hive/warehouse/test_bucket/*;
1001    101
1002    102
1003    103
1004    104
1005    105
1006    106
1007    107
1008    108
1009    109
1010    110
1011    111
1012    112
1013    113
1014    114
1015    115
1016    116
hive (default)> 
```

##### 6.6.1.2 åˆ›å»ºåˆ†æ¡¶è¡¨æ—¶,æ•°æ®é€šè¿‡å­æŸ¥è¯¢çš„æ–¹å¼å¯¼å…¥
###### 6.6.1.2.1 æ–°å»ºä¸€ä¸ªæ™®é€štest_buckè¡¨
```
hive (default)> create table test_buck(id int,name string)
              > row format delimited fields terminated by '\t';
OK
Time taken: 0.084 seconds
hive (default)> 
```
###### 6.6.1.2.2 å‘æ™®é€štest_buckè¡¨ä¸­å¯¼å…¥æ•°æ®
```
hive (default)> load data local inpath '/opt/module/datas/test_bucket.txt' into table test_buck;
Loading data to table default.test_buck
Table default.test_buck stats: [numFiles=1, totalSize=144]
OK
Time taken: 0.239 seconds
hive (default)> 
```
###### 6.6.1.2.3 æ¸…ç©ºtest_bucketè¡¨ä¸­æ•°æ®
```
hive (default)> truncate table test_bucket;
OK
Time taken: 0.151 seconds
hive (default)> 
```
###### 6.6.1.2.4 é€šè¿‡å­æŸ¥è¯¢çš„æ–¹å¼,å¯¼å…¥æ•°æ®åˆ°åˆ†æ¡¶è¡¨
```
hive (default)> insert into table test_bucket
              > select * from test_buck;
Query ID = root_20190329213846_8d66d5f4-e16d-4725-9231-e9b9dd84c1de
Loading data to table default.test_bucket
Table default.test_bucket stats: [numFiles=1, numRows=16, totalSize=144, rawDataSize=128]
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1   Cumulative CPU: 1.29 sec   HDFS Read: 3550 HDFS Write: 220 SUCCESS
Total MapReduce CPU Time Spent: 1 seconds 290 msec
OK
test_buck.id    test_buck.name
Time taken: 20.851 seconds
hive (default)> 
```
###### 6.6.1.2.5 å‘ç°è¿˜æ˜¯åªæœ‰ä¸€ä¸ªåˆ†æ¡¶
```
hive (default)> dfs -cat /user/hive/warehouse/test_bucket/*;
1001    101
1002    102
1003    103
1004    104
1005    105
1006    106
1007    107
1008    108
1009    109
1010    110
1011    111
1012    112
1013    113
1014    114
1015    115
1016    116
hive (default)> 
```
###### 6.6.1.2.6 è®¾ç½®åˆ†æ¡¶å±æ€§
```
hive (default)> set hive.enforce.bucketing=true;
hive (default)> set mapreduce.job.reduces=-1;
hive (default)> insert into table test_bucket
              > select id,name from test_buck cluster by(id);
Loading data to table default.test_bucket
Table default.test_bucket stats: [numFiles=5, numRows=32, totalSize=288, rawDataSize=256]
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 4   Cumulative CPU: 9.76 sec   HDFS Read: 15857 HDFS Write: 444 SUCCESS
Total MapReduce CPU Time Spent: 9 seconds 760 msec
OK
id      name
Time taken: 37.969 seconds
hive (default)> 
```
###### 6.6.1.2.7 æŸ¥è¯¢åˆ†æ¡¶æ•°æ®
> æŸ¥çœ‹åˆ†æ¡¶æ–‡ä»¶
```
hive (default)> dfs -ls /user/hive/warehouse/test_bucket/*;
-rwxrwxrwx 3 root supergroup 14 /user/hive/warehouse/test_bucket/000000_0
-rwxrwxrwx 3 root supergroup 36 /user/hive/warehouse/test_bucket/000001_0
-rwxrwxrwx 3 root supergroup 36 /user/hive/warehouse/test_bucket/000002_0
-rwxrwxrwx 3 root supergroup 36 /user/hive/warehouse/test_bucket/000003_0
hive (default)> 
```
> æŸ¥çœ‹åˆ†æ¡¶æ•°æ®
```
hive (default)> select * from test_bucket;
OK
test_bucket.id  test_bucket.name
1001    101
1002    102
1003    103
1004    104
1005    105
1006    106
1007    107
1008    108
1009    109
1010    110
1011    111
1012    112
1013    113
1014    114
1015    115
1016    116
1004    104
1008    108
1012    112
1016    116
1001    101
1005    105
1009    109
1013    113
1002    102
1006    106
1010    110
1014    114
1003    103
1007    107
1011    111
1015    115
Time taken: 0.081 seconds, Fetched: 32 row(s)
hive (default)> 
```


#### 6.6.2 åˆ†æ¡¶æŠ½æ ·æŸ¥è¯¢
> å¯¹äºéå¸¸å¤§çš„æ•°æ®é›†,æœ‰æ—¶å¼€å‘è€…éœ€è¦ä½¿ç”¨çš„æ˜¯ä¸€ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„æŸ¥è¯¢ç»“æœè€Œä¸æ˜¯å…¨éƒ¨ç»“æœ,Hiveå¯ä»¥é€šè¿‡å¯¹è¡¨è¿›è¡ŒæŠ½æ ·æ¥æ»¡è¶³è¿™ä¸ªéœ€æ±‚.
> 
#### 6.6.2.1 æŸ¥è¯¢test_bucketè¡¨ä¸­çš„æ•°æ®
```
hive (default)> select * from test_bucket tablesample(bucket 1 out of 4 on id);
OK
test_bucket.id  test_bucket.name
1004    104
1008    108
1012    112
1016    116
1004    104
1008    108
1012    112
1016    116
Time taken: 0.127 seconds, Fetched: 8 row(s)
hive (default)> 
```
> æ³¨: `tablesample`æ˜¯æŠ½æ ·è¯­å¥,è¯­æ³•: `TABLESAMPLE(BUCKET x OUT OF y)`
> 
> `x`è¡¨ç¤ºä»å“ªä¸ªbucketå¼€å§‹æŠ½å–,ä¾‹å¦‚,tableæ€»bucketæ•°ä¸º4,tablesample(bucket 4 out of 4),è¡¨ç¤ºæ€»å…±æŠ½å–(4/4=)ä¸ªbucketçš„æ•°æ®,æŠ½å–ç¬¬4ä¸ªbucketæ•°æ®.
> 
> `y`å¿…é¡»æ˜¯tableæ€»bucketæ•°çš„å€æ•°æˆ–è€…å› å­,hiveæ ¹æ®yçš„å¤§å°,å†³å®šæŠ½æ ·çš„æ¯”ä¾‹,ä¾‹å¦‚tableæ€»å…±åˆ†äº†4ä»½,å½“y=2æ—¶,æŠ½å–(4/2=)2ä¸ªbucketæ•°æ®,å½“y=8æ—¶,æŠ½å–(4/8=)1/2ä¸ªbucketæ•°æ®.
> 
> æ³¨æ„: xçš„å€¼å¿…é¡»å°äºç­‰äºyçš„å€¼,å¦åˆ™
```
FAILED:   SemanticException   [Error   10061]:   Numerator   should   not   be   bigger   than denominator in sample clause for table test_bucket
```

#### 6.6.3 æ•°æ®å—æŠ½æ ·
> Hiveæä¾›äº†å¦å¤–ä¸€ç§æŒ‰ç…§ç™¾åˆ†æ¯”è¿›è¡ŒæŠ½æ ·çš„æ–¹å¼,è¿™ç§æ˜¯åŸºäºè¡Œæ•°çš„,æŒ‰ç…§è¾“å…¥è·¯å¾„ä¸‹çš„æ•°æ®å—ç™¾åˆ†æ¯”è¿›è¡Œçš„æŠ½æ ·.
```
hive (default)> select * from test_buck tablesample(0.1 percent);
OK
test_buck.id    test_buck.name
1001    101
1002    102
1003    103
1004    104
1005    105
1006    106
1007    107
1008    108
1009    109
1010    110
1011    111
1012    112
1013    113
1014    114
1015    115
1016    116
Time taken: 0.115 seconds, Fetched: 16 row(s)
hive (default)> 
```
> æç¤º: è¿™ç§æŠ½æ ·æ–¹å¼ä¸ä¸€å®šé€‚ç”¨äºæ‰€æœ‰çš„æ–‡ä»¶æ ¼å¼,å¦å¤–è¿™ç§æŠ½æ ·çš„æœ€å°æŠ½æ ·å•å…ƒæ˜¯ä¸€ä¸ªHDFSæ•°æ®å—,å› æ­¤,å¦‚æœè¡¨çš„æ•°æ®å¤§å°å°äºæ™®é€šçš„å—å¤§å°128Mçš„è¯,é‚£ä¹ˆå°†ä¼šè¿”å›æ‰€æœ‰è¡Œ.

### 6.7 å…¶ä»–å¸¸ç”¨æŸ¥è¯¢å‡½æ•°
#### 6.7.1 ç©ºå­—æ®µèµ‹å€¼
##### 6.7.1.1 å‡½æ•°è¯´æ˜
> NVL:ç»™å€¼ä¸ºNULLçš„æ•°æ®èµ‹å€¼,æ ¼å¼æ˜¯`NVL(string1,replace_with)`.
> 
> å®ƒçš„åŠŸèƒ½æ˜¯å¦‚æœstring1ä¸ºNULL,åˆ™NVLå‡½æ•°è¿”å›replace_withçš„å€¼,å¦åˆ™è¿”å›string1çš„å€¼,å¦‚æœä¸¤ä¸ªå‚æ•°ä¸ºNULL,åˆ™è¿”å›NULL.
##### 6.7.1.2 æ•°æ®å‡†å¤‡ é‡‡ç”¨empæ•°æ®è¡¨
##### 6.7.1.3 æŸ¥è¯¢deptnoå­—æ®µä¸ºNULL,åˆ™ç”¨-1ä»£æ›¿
```
hive (default)> select empno,nvl(deptno,-1) from emp;
OK
empno   _c1
7369    -1
7499    30
7521    30
7566    -1
7654    -1
7698    -1
7782    -1
7788    -1
7939    -1
Time taken: 0.066 seconds, Fetched: 9 row(s)
hive (default)> 
```

#### 6.7.2 CASE WHEN
##### 6.7.2.1 æ•°æ®å‡†å¤‡
> userè¡¨ç¤ºç”¨æˆ·å, a&bè¡¨ç¤ºéƒ¨é—¨,ç”·å¥³è¡¨ç¤ºæ€§åˆ«
```
user001 A Male
user002 A Male
user003 B Female
user004 A Female
user005 B Female
user006 B Female
```
##### 6.7.2.2 éœ€æ±‚
> è®¡ç®—å‡ºä¸åŒéƒ¨åˆ†å‘˜å·¥æ€§åˆ«æœ‰å¤šå°‘

##### 6.7.2.3 åˆ›å»ºæœ¬åœ°æ–‡ä»¶å¹¶å¯¼å…¥æ•°æ®
```
[root@systemhub711 datas]# vim emp_sex.txt
```

##### 6.7.2.4 åˆ›å»ºè¡¨å¹¶å¯¼å…¥æ•°æ®
```
hive (default)> create table emp_sex(name string,dept_id string,sex string) row format delimited fields terminated by ' ';
OK
Time taken: 0.11 seconds
hive (default)> load data local inpath '/opt/module/datas/emp_sex.txt' into table emp_sex;
Loading data to table default.emp_sex
Table default.emp_sex stats: [numFiles=1, totalSize=84]
OK
Time taken: 0.255 seconds
hive (default)> 
```
##### 6.7.2.5 æŒ‰ç…§éœ€æ±‚æŸ¥è¯¢æ•°æ®
```
hive (default)>  select dept_id,
              > sum(case sex when 'Male' then 1 else 0 end) male_count,
              > sum(case sex when 'Female' then 1 else 0 end) female_count
              > from emp_sex
              > group by dept_id;
Query ID = root_20190329235632_478f9985-3a7f-4c56-8648-fc0c2a760985
Total MapReduce CPU Time Spent: 3 seconds 320 msec
OK
dept_id male_count female_count
A       2       	1
B       1       	2
```



## ğŸ”’ å°šæœªè§£é” æ­£åœ¨å­¦ä¹ æ¢ç´¢ä¸­... å°½æƒ…æœŸå¾… Blogæ›´æ–°! ğŸ”’


#### 6.7.3 è¡Œè½¬åˆ—
#### 6.7.4 åˆ—è½¬è¡Œ
#### 6.7.5 çª—å£å‡½æ•°
#### 6.7.6 Rnak


## 7. å‡½æ•°
### 7.1 ç³»ç»Ÿå‡½æ•°
### 7.2 è‡ªå®šä¹‰å‡½æ•°
### 7.3 è‡ªå®šä¹‰UDFå‡½æ•°

## 8. å‹ç¼© & å­˜å‚¨
### 8.1 Hadoopæºç ç¼–è¯‘æ”¯æŒSnappyå‹ç¼©
### 8.2 Hadoopå‹ç¼©é…ç½®
### 8.3 å¼€å¯Mapè¾“å‡ºé˜¶æ®µå‹ç¼©
### 8.4 å¼€å¯Reduceè¾“å‡ºé˜¶æ®µå‹ç¼©
### 8.5 æ–‡ä»¶å­˜å‚¨æ ¼å¼
### 8.6 å­˜å‚¨å’Œå‹ç¼©ç»“åˆ

## 9. ä¼ä¸šçº§è°ƒä¼˜
### 9.1 FetchæŠ“å–
### 9.2 æœ¬åœ°æ¨¡å¼
### 9.3 è¡¨çš„ä¼˜åŒ–
### 9.4 æ•°æ®å€¾æ–œ
### 9.5 å¹¶è¡Œæ‰§è¡Œ
### 9.6 ä¸¥æ ¼æ¨¡å¼
### 9.7 JVMé‡ç”¨
### 9.8 æ¨æµ‹æ‰§è¡Œ
### 9.10 æ‰§è¡Œè®¡åˆ’ (Explain)

## 10. ä¿®ä»™ä¹‹é“ æŠ€æœ¯æ¶æ„è¿­ä»£ ç™»å³°é€ æä¹‹åŠ¿
![Alt text](https://raw.githubusercontent.com/geekparkhub/geekparkhub.github.io/master/technical_guide/assets/media/main/technical_framework.jpg)


-----

## ğŸ’¡å¦‚ä½•å¯¹è¯¥å¼€æºæ–‡æ¡£è¿›è¡Œè´¡çŒ®ğŸ’¡

1. Blogå†…å®¹å¤§å¤šæ˜¯æ‰‹æ•²,æ‰€ä»¥éš¾å…ä¼šæœ‰ç¬”è¯¯,ä½ å¯ä»¥å¸®æˆ‘æ‰¾é”™åˆ«å­—ã€‚
2. å¾ˆå¤šçŸ¥è¯†ç‚¹æˆ‘å¯èƒ½æ²¡æœ‰æ¶‰åŠåˆ°,æ‰€ä»¥ä½ å¯ä»¥å¯¹å…¶ä»–çŸ¥è¯†ç‚¹è¿›è¡Œè¡¥å……ã€‚
3. ç°æœ‰çš„çŸ¥è¯†ç‚¹éš¾å…å­˜åœ¨ä¸å®Œå–„æˆ–è€…é”™è¯¯,æ‰€ä»¥ä½ å¯ä»¥å¯¹å·²æœ‰çŸ¥è¯†ç‚¹çš„ä¿®æ”¹/è¡¥å……ã€‚
4. ğŸ’¡æ¬¢è¿è´¡çŒ®`å„é¢†åŸŸå¼€æºé‡ç”ŸBlog`&`ç¬”è®°`&`æ–‡ç« `&`ç‰‡æ®µ`&`åˆ†äº«`&`åˆ›æƒ³`&`OpenSource Project`&`Code`&`Code Review`
5. ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ issues: [geekparkhub.github.io/issues](https://github.com/geekparkhub/geekparkhub.github.io/issues) ğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆğŸ™ˆ

### å¸Œæœ›æ¯ä¸€ç¯‡æ–‡ç« éƒ½èƒ½å¤Ÿå¯¹è¯»è€…ä»¬æä¾›å¸®åŠ©ä¸æå‡,è¿™ä¹ƒæ˜¯æ¯ä¸€ä½ç¬”è€…çš„åˆè¡·                          


-----


## ğŸ’Œæ„Ÿè°¢æ‚¨çš„é˜…è¯» æ¬¢è¿æ‚¨çš„ç•™è¨€ä¸å»ºè®®ğŸ’Œ

- FaceBookï¼š[JEEP SevenEleven](https://www.facebook.com/profile.php?id=100018099483403)
- Twitterï¼š[@JEEP7ll](https://twitter.com/JEEP7ll)
- Sina Weibo: [@JEEP-711](https://weibo.com/JEEP511)
- GeekParkHub GithubHomeï¼š<https://github.com/geekparkhub>
- GeekParkHub GiteeHomeï¼š<https://gitee.com/geekparkhub>
- Blog GardenHomeï¼š<http://www.cnblogs.com/JEEP711/>
- W3C/BlogHomeï¼š<https://www.w3cschool.cn/jeep711blog/>
- CSDN/BlogHomeï¼š<http://blog.csdn.net/jeep911>
- 51CTO/BlogHomeï¼š<http://jeep711.blog.51cto.com/>
- **`Official Public Email`**
- Group Emailï¼š<geekparkhub@outlook.com> â€”â€” <hackerparkhub@outlook.com> â€”â€” <hackerpark@hotmail.com>
- User Emailï¼š<jeep711.home.@gmail.com> â€”â€” <jeep-711@outlook.com>
- System Emailï¼š<systemhub-711@outlook.com>
- Service Emailï¼š<servicehub-711@outlook.com>



### æåŠ© é¡¹ç›®çš„å‘å±•ç¦»ä¸å¼€ä½ çš„æ”¯æŒ,è¯·å¼€å‘è€…å–æ¯â˜•Coffeeâ˜•å§!
![enter image description here](https://www.geekparkhub.com/docs/images/pay.jpg)

#### `è‡´è°¢`ï¼š
**æåŠ©æ—¶è¯·å¤‡æ³¨ UserName**
| ID| UserName | Donation | Money | Consume |
|:-| :-------- | --------:| :--: |:--: |
|1 | Object | WeChatPay |  5RMB | ä¸€æ¯å¯ä¹ | 
|2| æ³°è¿ªç†Šçœ‹æœˆäº®  | AliPay |  20RMB  | ä¸€æ¯å’–å•¡ | 
|3| ä¿®ä»™é“é•¿  | WeChatPay |  10RMB | ä¸¤æ¯å¯ä¹ | 


## License å¼€æºåè®®
[Apache License Version 2.0](https://github.com/geekparkhub/geekparkhub.github.io/blob/master/LICENSE)

---------